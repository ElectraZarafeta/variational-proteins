{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proteins.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TtPNnZtEocpp",
        "tgIWxOM2osDp",
        "z0uDRhoyo0LZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eehyHK7rpfV5",
        "outputId": "c6ce0307-2dde-41e8-9a0d-d144a250f2e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2sfVuespkad"
      },
      "source": [
        "data_path = '/content/gdrive/MyDrive/data/BLAT_ECOLX_hmmerbit_plmc_n5_m30_f50_t0.2_r24-286_id100_b105.a2m'\n",
        "labels_path = '/content/gdrive/MyDrive/data/BLAT_ECOLX_hmmerbit_plmc_n5_m30_f50_t0.2_r24-286_id100_b105_LABELS.a2m'\n",
        "mutations_path = '/content/gdrive/MyDrive/data/BLAT_ECOLX_Ranganathan2015.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXTtA-CYVkKG"
      },
      "source": [
        "data_path_weights = '/content/gdrive/MyDrive/AML/WEIGHTS2.txt'\n",
        "with open(data_path_weights, 'r') as testwritefile:\n",
        "    new_weights=testwritefile.read()\n",
        "content_list = open(data_path_weights, 'r').readlines()\n",
        "my_list = content_list[0].split(\",\")\n",
        "weights = [float(my_list[i]) for i in range(len(my_list)-1)]\n",
        "Neff = 2780.0254087972826"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtPNnZtEocpp"
      },
      "source": [
        "# misc.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqr2Zm0OoTj7"
      },
      "source": [
        "# This module loads and prepares the data\n",
        "\n",
        "import torch, time, sys, re\n",
        "import pandas as pd\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "ALPHABET = 'ACDEFGHIKLMNPQRSTVWXYZ-'\n",
        "SEQ2IDX = dict(map(reversed, enumerate(ALPHABET)))\n",
        "\n",
        "\n",
        "def fasta(file_path):\n",
        "    \"\"\"This function parses a subset of the FASTA format\n",
        "    https://en.wikipedia.org/wiki/FASTA_format\"\"\"\n",
        "\n",
        "    print(f\"Parsing fasta '{file_path}'\")\n",
        "    data = {\n",
        "        'ur_up_': [], 'accession': [],\n",
        "        'entry_name': [], 'offset': [],\n",
        "        'taxonomy': [], 'sequence': []\n",
        "    }\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            line = line.strip()\n",
        "\n",
        "            if line[0] == '>':\n",
        "                key = line[1:]\n",
        "\n",
        "                if i == 0:\n",
        "                    name, offset = key.split(\"/\")\n",
        "                    ur_up_, acc = None, None\n",
        "                else:\n",
        "                    ur_up_, acc, name_offset = key.split(\"|\")\n",
        "                    name, offset = name_offset.split('/')\n",
        "\n",
        "                data['ur_up_'].append(ur_up_)\n",
        "                data['accession'].append(acc)\n",
        "                data['entry_name'].append(name)\n",
        "                data['offset'].append(offset)\n",
        "                data['sequence'].append('')\n",
        "                data['taxonomy'].append(name.split('_')[1])\n",
        "            else:\n",
        "                data['sequence'][-1] += line\n",
        "\n",
        "            if i and (i % 50000 == 0):\n",
        "                print(f\"Reached: {i}\")\n",
        "\n",
        "    return pd.DataFrame(data=data)\n",
        "\n",
        "\n",
        "def labels(labels_file, labels=[]):\n",
        "    \"\"\"Parses the labels file\"\"\"\n",
        "\n",
        "    print(f\"Parsing labels '{labels_file}'\")\n",
        "    with open(labels_file, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            labels.append(line.split(':')[-1].strip())\n",
        "    return pd.Series(labels)\n",
        "\n",
        "\n",
        "def trim(full_sequences, focus_columns, sequences=[]):\n",
        "    \"\"\"Trims the sequences according to the focus columns\"\"\"\n",
        "\n",
        "    for seq in full_sequences:\n",
        "        seq = seq.replace('.', '-')\n",
        "        trimmed = [seq[idx].upper() for idx in focus_columns]\n",
        "        sequences.append(''.join(trimmed))\n",
        "    return pd.Series(sequences)\n",
        "\n",
        "\n",
        "def encode(sequences):\n",
        "    t0 = time.time()\n",
        "    print(f\"Generating {len(sequences)} 1-hot encodings\")\n",
        "    tensors, l = [], len(ALPHABET)\n",
        "    for seq in sequences:\n",
        "        idxseq = [SEQ2IDX[s] for s in seq]\n",
        "        tensor = F.one_hot(torch.tensor(idxseq), l).t().float()\n",
        "        tensors.append(tensor)\n",
        "    r = torch.stack(tensors)\n",
        "    print(f\"Generating {len(sequences)} 1-hot encodings. Took {round(time.time() - t0, 3)}s\", r.shape)\n",
        "    return r\n",
        "\n",
        "\n",
        "def mutants(df):\n",
        "    global mdf, offset, wt_full\n",
        "\n",
        "    col = '2500'  # name of the column of our interest.\n",
        "    mdf = pd.read_csv(mutations_path)\n",
        "    mdf = pd.DataFrame(data={'value': mdf[col].values}, index=mdf['mutant'].values)\n",
        "    wt_row = df.iloc[0]  # wildtype row in df\n",
        "    wt_off = wt_row['offset']  # wildtype offset (24-286)\n",
        "    offset = int(wt_off.split('-')[0])  # left-side offset: 24\n",
        "    wt_full = wt_row['sequence']\n",
        "    focus_columns = [idx for idx, char in enumerate(wt_full) if char.isupper()]\n",
        "\n",
        "    reg_co = re.compile(\"([a-zA-Z]+)([0-9]+)([a-zA-Z]+)\")\n",
        "    mutants = {'mutation': [], 'sequence': [], 'value': []}\n",
        "\n",
        "    for i, (k, v) in enumerate(mdf.iterrows()):\n",
        "        v = v['value']\n",
        "        _from, _index, _to = reg_co.match(k).groups()\n",
        "        _index = int(_index) - offset\n",
        "\n",
        "        if wt_full[_index].islower():\n",
        "            continue  # we skip the lowercase residues\n",
        "\n",
        "        if wt_full[_index] != _from:\n",
        "            print(\"WARNING: Mutation sequence mismatch:\", k, \"full wt index:\", _index)\n",
        "\n",
        "        mutant = wt_full[:_index] + _to + wt_full[_index + 1:]\n",
        "        mutant_trimmed = [mutant[idx] for idx in focus_columns]\n",
        "\n",
        "        mutants['mutation'].append(k)\n",
        "        mutants['sequence'].append(''.join(mutant_trimmed))\n",
        "        mutants['value'].append(v)\n",
        "    return pd.DataFrame(data=mutants)\n",
        "\n",
        "\n",
        "def hamming_distance(a, b):\n",
        "    result = 0\n",
        "    for x, (i, j) in enumerate(zip(a, b)):\n",
        "        if i != j:\n",
        "            #print(f'char not math{i, j}in {x}')\n",
        "            result += 1\n",
        "    return result\n",
        "\n",
        "def normalize(v): \n",
        "  norm = np.linalg.norm(v) \n",
        "  if norm == 0: \n",
        "    return v \n",
        "\n",
        "  return v / norm\n",
        "\n",
        "def min_max(v):\n",
        "  norm = (v-np.min(v))/(np.max(v)-np.min(v))\n",
        "\n",
        "  return norm\n",
        "\n",
        "def stand(v):\n",
        "  return (v - np.average(v)) / (np.std(v))\n",
        "\n",
        "def seq_weights(df, theta):\n",
        "  weights = []\n",
        "\n",
        "  for i in range(df.shape[0]):\n",
        "      hamming_dist = []\n",
        "      for j in range(df.shape[0]):\n",
        "          hamming_dist.append(hamming_distance(df['trimmed'][i], df['trimmed'][j]))\n",
        "\n",
        "      norm_dist = min_max(hamming_dist) #stand(hamming_dist) #normalize(hamming_dist)\n",
        "\n",
        "      weights.append(1/sum([1 for norm in norm_dist if norm < theta]))\n",
        "\n",
        "  n_eff = sum(weights)\n",
        "  p_s = [w/n_eff for w in weights]\n",
        "\n",
        "  return p_s\n",
        "\n",
        "def data(batch_size=128, device='cpu'):\n",
        "    df = fasta(data_path)\n",
        "    df['label'] = labels(labels_path)\n",
        "\n",
        "    # First sequence in the dataframe/fasta file is our wildtype.\n",
        "    wildtype_seq = df.sequence[0]\n",
        "\n",
        "    # What wildtype column-positions are we confident about (uppercased chars)\n",
        "    focus_columns = [idx for idx, char in enumerate(wildtype_seq) if char.isupper()]\n",
        "\n",
        "    # Trim the full sequences according to the columns we are confident at\n",
        "    df['trimmed'] = trim(df.sequence, focus_columns)\n",
        "\n",
        "    # Unique aminoacids are are:\n",
        "    # ''.join(set(''.join(df.trimmed.to_list())))\n",
        "\n",
        "    dataset = encode(df.trimmed).to(device)\n",
        "\n",
        "    #weights = seq_weights(df, theta=0.2)\n",
        "    \n",
        "    sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights)) \n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
        "\n",
        "    mutants_df = mutants(df)\n",
        "    mutants_tensor = encode(mutants_df.sequence)\n",
        "\n",
        "    return dataloader, df, mutants_tensor, mutants_df\n",
        "\n",
        "\n",
        "# nice colors for the terminal\n",
        "class c:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "#    dataloader, df, mutants_tensor, mutants_df = data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIWxOM2osDp"
      },
      "source": [
        "# vae.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ_DYJSIoyP9"
      },
      "source": [
        "# This VAE is as vanilla as it can be.\n",
        "import torch\n",
        "\n",
        "class VAE(torch.nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(VAE, self).__init__()\n",
        "        self.hidden_size   = 64\n",
        "        self.latent_size   = 2\n",
        "        self.alphabet_size = kwargs['alphabet_size']\n",
        "        self.seq_len       = kwargs['seq_len']\n",
        "        self.input_size    = self.alphabet_size * self.seq_len\n",
        "\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.input_size, self.hidden_size),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Latent space `mu` and `var`\n",
        "        self.fc21 = torch.nn.Linear(self.hidden_size, self.latent_size)\n",
        "        self.fc22 = torch.nn.Linear(self.hidden_size, self.latent_size)\n",
        "\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.latent_size, self.hidden_size),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(self.hidden_size, self.input_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, rep=True):\n",
        "        x = x.view(-1, self.input_size)                    # flatten\n",
        "        x = self.encoder(x)                                # encode\n",
        "        mu, logvar = self.fc21(x), self.fc22(x)            # branch mu, var\n",
        "\n",
        "        if rep:                                            # reparameterize\n",
        "            x = mu + torch.randn_like(mu) * (0.5*logvar).exp() \n",
        "        else:                                              # or don't \n",
        "            x = mu                                         \n",
        "\n",
        "        x = self.decoder(x)                                # decode\n",
        "        x = x.view(-1, self.alphabet_size, self.seq_len)   # squeeze back\n",
        "        x = x.log_softmax(dim=1)                           # softmax\n",
        "\n",
        "        return x, mu, logvar\n",
        "    \n",
        "    def loss(self, x_hat, true_x, mu, logvar, beta=0.5):\n",
        "        RL = -(x_hat*true_x).sum(-1).sum(-1)                    # reconst. loss\n",
        "        KL = -0.5 * (1 + logvar - mu**2 - logvar.exp()).sum(-1) # KL loss\n",
        "        return RL + beta*KL, RL, KL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0uDRhoyo0LZ"
      },
      "source": [
        "# train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJEVChGdo1o9",
        "outputId": "c84f55c6-851a-457d-bb4f-182178c01b88"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "#from misc import data, c\n",
        "from torch import optim\n",
        "from scipy.stats import spearmanr\n",
        "#from vae import VAE\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataloader, df, mutants_tensor, mutants_df = data(batch_size = 64)\n",
        "\n",
        "wildtype   = dataloader.dataset[0] # one-hot-encoded wildtype \n",
        "eval_batch = torch.cat([wildtype.unsqueeze(0), mutants_tensor])\n",
        "\n",
        "args = {\n",
        "    'alphabet_size': dataloader.dataset[0].shape[0],\n",
        "    'seq_len':       dataloader.dataset[0].shape[1]\n",
        "}\n",
        "\n",
        "vae   = VAE(**args).to(device)\n",
        "opt   = optim.Adam(vae.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing fasta '/content/gdrive/MyDrive/data/BLAT_ECOLX_hmmerbit_plmc_n5_m30_f50_t0.2_r24-286_id100_b105.a2m'\n",
            "Parsing labels '/content/gdrive/MyDrive/data/BLAT_ECOLX_hmmerbit_plmc_n5_m30_f50_t0.2_r24-286_id100_b105_LABELS.a2m'\n",
            "Generating 8403 1-hot encodings\n",
            "Generating 8403 1-hot encodings. Took 0.922s torch.Size([8403, 23, 253])\n",
            "Generating 4807 1-hot encodings\n",
            "Generating 4807 1-hot encodings. Took 0.446s torch.Size([4807, 23, 253])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3ZMLrNuBRwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609ea645-b5c9-4524-bf08-e58adb79bbb0"
      },
      "source": [
        "# rl  = Reconstruction loss\n",
        "# kl  = Kullback-Leibler divergence loss\n",
        "# cor = Spearman correlation to experimentally measured \n",
        "#       protein fitness according to eq.1 from paper\n",
        "stats = { 'rl': [], 'kl': [], 'cor': [] }\n",
        "\n",
        "for epoch in range(1):\n",
        "    # Unsupervised training on the MSA sequences.\n",
        "    vae.train()\n",
        "    \n",
        "    epoch_losses = { 'rl': [], 'kl': [] }\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        opt.zero_grad()\n",
        "        x_hat, mu, logvar = vae(batch)\n",
        "        loss, rl, kl      = vae.loss(x_hat, batch, mu, logvar)\n",
        "        loss.mean().backward()\n",
        "        opt.step()\n",
        "        epoch_losses['rl'].append(rl.mean().item())\n",
        "        epoch_losses['kl'].append(kl.mean().item())\n",
        "\n",
        "    # Evaluation on mutants\n",
        "    vae.eval()\n",
        "    eval_batch = eval_batch.to(device)\n",
        "    x_hat_eval, mu, logvar = vae(eval_batch, rep=False)\n",
        "    elbos, _, _ = vae.loss(x_hat_eval, eval_batch, mu, logvar)\n",
        "    diffs       = elbos[1:] - elbos[0] # log-ratio (first equation in the paper)\n",
        "    cor, _      = spearmanr(mutants_df.value, diffs.detach().cpu())\n",
        "    \n",
        "    # Populate statistics \n",
        "    stats['rl'].append(np.mean(epoch_losses['rl']))\n",
        "    stats['kl'].append(np.mean(epoch_losses['kl']))\n",
        "    stats['cor'].append(np.abs(cor))\n",
        "\n",
        "    to_print = [\n",
        "        f\"{c.HEADER}EPOCH %03d\"          % epoch,\n",
        "        f\"{c.OKBLUE}RL=%4.4f\"            % stats['rl'][-1], \n",
        "        f\"{c.OKGREEN}KL=%4.4f\"           % stats['kl'][-1], \n",
        "        f\"{c.OKCYAN}|rho|=%4.4f{c.ENDC}\" % stats['cor'][-1]\n",
        "    ]\n",
        "    print(\" \".join(to_print))\n",
        "\n",
        "torch.save({\n",
        "    'state_dict': vae.state_dict(), \n",
        "    'stats':      stats,\n",
        "    'args':       args,\n",
        "}, \"trained.model.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [[ 0.3014,  0.8824, -0.9075,  ...,  2.2877,  1.9633,  0.3922],\n",
            "         [-4.6456, -2.4753, -3.0742,  ..., -2.8906, -1.0768, -2.3474],\n",
            "         [ 0.4227,  0.5659, -4.7076,  ..., -0.7510, -3.3283, -4.9070],\n",
            "         ...,\n",
            "         [-4.6729, -2.1956, -1.4500,  ..., -0.9200, -4.2350,  2.8232],\n",
            "         [-5.9248, -3.4167, -3.5359,  ..., -4.4695, -4.7759, -5.2614],\n",
            "         [ 2.1352,  2.5337,  2.4989,  ...,  1.5915,  1.3225,  2.1551]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.3401,  0.8350, -0.7765,  ...,  2.0729,  1.8131,  0.4141],\n",
            "         [-4.1375, -2.1637, -2.7087,  ..., -2.6164, -1.0287, -2.0407],\n",
            "         [ 0.3826,  0.4935, -4.1700,  ..., -0.6708, -2.9958, -4.2908],\n",
            "         ...,\n",
            "         [-4.1140, -1.9578, -1.2783,  ..., -0.8632, -3.7213,  2.4645],\n",
            "         [-5.2467, -3.0334, -3.1240,  ..., -3.8952, -4.1911, -4.6036],\n",
            "         [ 1.8626,  2.1663,  2.1243,  ...,  1.3545,  1.1030,  1.8661]],\n",
            "\n",
            "        [[ 2.2309,  2.2732, -0.3840,  ...,  1.9252,  2.7278,  2.8430],\n",
            "         [-4.8895, -1.2722, -2.6252,  ..., -3.8159, -2.8883, -1.2041],\n",
            "         [ 0.6351,  0.8418, -4.9605,  ..., -2.3034, -4.2274, -4.7851],\n",
            "         ...,\n",
            "         [-5.4217, -1.8181, -1.7372,  ..., -1.7019, -3.4337,  0.9504],\n",
            "         [-6.5550, -3.4495, -3.8219,  ..., -4.4048, -3.4594, -4.8257],\n",
            "         [ 1.6566,  0.7981,  0.2960,  ..., -0.9707,  0.7292,  1.7211]],\n",
            "\n",
            "        [[ 0.3702,  0.8066, -0.6673,  ...,  1.9063,  1.6933,  0.4407],\n",
            "         [-3.7569, -1.9268, -2.4391,  ..., -2.4058, -0.9998, -1.8096],\n",
            "         [ 0.3440,  0.4505, -3.7572,  ..., -0.6182, -2.7410, -3.8265],\n",
            "         ...,\n",
            "         [-3.6853, -1.7692, -1.1522,  ..., -0.8105, -3.3243,  2.1974],\n",
            "         [-4.7241, -2.7501, -2.8125,  ..., -3.4553, -3.7446, -4.0963],\n",
            "         [ 1.6632,  1.8810,  1.8327,  ...,  1.1628,  0.9293,  1.6557]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.8070,  -2.8988,  -3.8138,  ...,  -1.7797,  -1.7804,  -3.2162],\n",
            "         [ -5.9725,  -5.1488,  -5.4080,  ...,  -5.2286,  -3.6890,  -4.9421],\n",
            "         [ -2.6639,  -2.8709,  -6.2611,  ...,  -3.7840,  -5.1083,  -6.3661],\n",
            "         ...,\n",
            "         [ -5.7148,  -4.9224,  -4.2111,  ...,  -4.0860,  -5.7329,  -1.1286],\n",
            "         [ -6.6646,  -5.7718,  -5.5746,  ...,  -6.0628,  -6.2172,  -6.4801],\n",
            "         [ -1.2792,  -1.3721,  -1.3500,  ...,  -2.1332,  -2.0222,  -1.6753]],\n",
            "\n",
            "        [[ -3.0239,  -3.0452,  -4.8604,  ...,  -1.5002,  -1.6486,  -3.5564],\n",
            "         [ -7.6873,  -6.3323,  -7.0847,  ...,  -6.4604,  -4.3923,  -6.1700],\n",
            "         [ -2.7825,  -3.1972,  -8.5298,  ...,  -4.3914,  -6.6270,  -8.5660],\n",
            "         ...,\n",
            "         [ -7.6418,  -5.9996,  -5.3871,  ...,  -4.5888,  -7.6272,  -0.8207],\n",
            "         [ -8.9096,  -7.1957,  -7.4267,  ...,  -8.0683,  -8.1978,  -8.8689],\n",
            "         [ -0.9520,  -1.0870,  -1.2948,  ...,  -2.0029,  -2.0246,  -1.5272]],\n",
            "\n",
            "        [[ -2.8738,  -2.8891,  -4.9141,  ...,  -1.4349,  -1.5313,  -3.3133],\n",
            "         [ -7.8209,  -6.2467,  -7.0809,  ...,  -6.6132,  -4.5714,  -6.0529],\n",
            "         [ -2.7526,  -3.2056,  -8.7142,  ...,  -4.4735,  -6.8229,  -8.6125],\n",
            "         ...,\n",
            "         [ -7.8481,  -5.9670,  -5.4567,  ...,  -4.6426,  -7.7296,  -0.8823],\n",
            "         [ -9.1000,  -7.1882,  -7.5425,  ...,  -8.1920,  -8.2705,  -8.9669],\n",
            "         [ -1.0400,  -1.2377,  -1.5077,  ...,  -2.1310,  -2.1721,  -1.5504]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.7273,  -2.7404,  -4.4999,  ...,  -1.4993,  -1.5069,  -3.0694],\n",
            "         [ -7.2048,  -5.7391,  -6.4321,  ...,  -6.1886,  -4.3487,  -5.5242],\n",
            "         [ -2.6847,  -3.0818,  -7.8933,  ...,  -4.2431,  -6.3159,  -7.7743],\n",
            "         ...,\n",
            "         [ -7.1814,  -5.5331,  -5.0017,  ...,  -4.4354,  -7.0413,  -1.0191],\n",
            "         [ -8.3140,  -6.6087,  -6.8474,  ...,  -7.4674,  -7.5112,  -8.0871],\n",
            "         [ -1.2047,  -1.4091,  -1.5990,  ...,  -2.2178,  -2.2171,  -1.6175]],\n",
            "\n",
            "        [[ -1.4344,  -1.6895,  -5.0051,  ...,  -1.6010,  -1.3921,  -1.2174],\n",
            "         [ -8.5548,  -5.2349,  -7.2464,  ...,  -7.3421,  -7.0081,  -5.2646],\n",
            "         [ -3.0303,  -3.1209,  -9.5816,  ...,  -5.8296,  -8.3473,  -8.8456],\n",
            "         ...,\n",
            "         [ -9.0871,  -5.7809,  -6.3583,  ...,  -5.2281,  -7.5535,  -3.1101],\n",
            "         [-10.2204,  -7.4122,  -8.4430,  ...,  -7.9309,  -7.5793,  -8.8862],\n",
            "         [ -2.0088,  -3.1646,  -4.3252,  ...,  -4.4969,  -3.3907,  -2.3394]],\n",
            "\n",
            "        [[ -2.6313,  -2.6364,  -4.1867,  ...,  -1.5573,  -1.5038,  -2.8985],\n",
            "         [ -6.7585,  -5.3698,  -5.9585,  ...,  -5.8695,  -4.1969,  -5.1488],\n",
            "         [ -2.6575,  -2.9925,  -7.2767,  ...,  -4.0819,  -5.9381,  -7.1657],\n",
            "         ...,\n",
            "         [ -6.6869,  -5.2122,  -4.6717,  ...,  -4.2741,  -6.5214,  -1.1418],\n",
            "         [ -7.7257,  -6.1932,  -6.3319,  ...,  -6.9189,  -6.9418,  -7.4356],\n",
            "         [ -1.3384,  -1.5620,  -1.6867,  ...,  -2.3008,  -2.2678,  -1.6835]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.4161,  2.4784, -0.4022,  ..., -1.1221,  0.8078,  1.8475],\n",
            "        [ 2.0180,  2.0557, -0.3140,  ..., -0.9131,  0.6015,  1.5257],\n",
            "        [ 2.2995,  2.3452, -0.3724,  ..., -1.0774,  0.7372,  1.7397],\n",
            "        ...,\n",
            "        [ 2.0261,  2.1808, -0.3766,  ..., -0.7103,  0.7286,  1.7062],\n",
            "        [-0.0198,  0.2167, -0.8299,  ...,  1.5866,  1.2549,  1.9654],\n",
            "        [ 2.1983,  2.3928, -0.4349,  ..., -0.7184,  0.8511,  1.9212]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.4161,  2.4784, -0.4022,  ...,  2.0302,  2.9361,  3.1178],\n",
            "         [-5.2693, -1.3722, -2.7891,  ..., -4.1296, -3.1355, -1.2760],\n",
            "         [ 0.6841,  0.9252, -5.3743,  ..., -2.5505, -4.5899, -5.1891],\n",
            "         ...,\n",
            "         [-5.8575, -1.9761, -1.8668,  ..., -1.8713, -3.7326,  0.9583],\n",
            "         [-7.1267, -3.7401, -4.1514,  ..., -4.7858, -3.7150, -5.2278],\n",
            "         [ 1.7356,  0.8423,  0.2846,  ..., -1.1221,  0.8078,  1.8475]],\n",
            "\n",
            "        [[ 2.0180,  2.0557, -0.3140,  ...,  1.7358,  2.4709,  2.5786],\n",
            "         [-4.4123, -1.1496, -2.3609,  ..., -3.4555, -2.6227, -1.0630],\n",
            "         [ 0.5590,  0.7658, -4.4431,  ..., -2.0876, -3.8226, -4.2636],\n",
            "         ...,\n",
            "         [-4.7980, -1.6615, -1.5477,  ..., -1.5565, -3.0576,  0.8546],\n",
            "         [-5.8385, -3.1040, -3.4346,  ..., -3.9102, -3.0771, -4.2833],\n",
            "         [ 1.4605,  0.6812,  0.2018,  ..., -0.9131,  0.6015,  1.5257]],\n",
            "\n",
            "        [[ 2.2995,  2.3452, -0.3724,  ...,  1.9246,  2.7771,  2.9555],\n",
            "         [-4.9784, -1.2939, -2.6471,  ..., -3.9104, -2.9800, -1.1988],\n",
            "         [ 0.6391,  0.8705, -5.0603,  ..., -2.4047, -4.3434, -4.8729],\n",
            "         ...,\n",
            "         [-5.5073, -1.8649, -1.7652,  ..., -1.7772, -3.5024,  0.9112],\n",
            "         [-6.6942, -3.5299, -3.9163,  ..., -4.4841, -3.4782, -4.8969],\n",
            "         [ 1.6487,  0.7803,  0.2423,  ..., -1.0774,  0.7372,  1.7397]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.0261,  2.1808, -0.3766,  ...,  1.9864,  2.7670,  2.6449],\n",
            "         [-4.9225, -1.3328, -2.5753,  ..., -3.7504, -2.6999, -1.2605],\n",
            "         [ 0.6574,  0.8690, -4.9798,  ..., -2.2209, -4.1158, -4.8456],\n",
            "         ...,\n",
            "         [-5.3213, -1.9043, -1.6619,  ..., -1.5886, -3.4918,  1.0728],\n",
            "         [-6.5522, -3.4258, -3.7712,  ..., -4.4910, -3.7189, -4.9781],\n",
            "         [ 1.5524,  0.8735,  0.4418,  ..., -0.7103,  0.7286,  1.7062]],\n",
            "\n",
            "        [[-0.0198,  0.2167, -0.8299,  ...,  1.6927,  1.0754, -0.2788],\n",
            "         [-3.2745, -2.2495, -2.5032,  ..., -1.9116, -0.7711, -2.0213],\n",
            "         [ 0.1314,  0.4995, -3.2310,  ..., -0.4842, -2.2691, -3.4802],\n",
            "         ...,\n",
            "         [-2.9649, -1.6944, -1.2486,  ..., -0.7782, -3.0253,  2.4659],\n",
            "         [-3.9994, -2.8537, -2.6576,  ..., -2.9749, -3.5182, -3.6165],\n",
            "         [ 2.0570,  2.5165,  2.3709,  ...,  1.5866,  1.2549,  1.9654]],\n",
            "\n",
            "        [[ 2.1983,  2.3928, -0.4349,  ...,  2.1859,  3.0664,  2.8804],\n",
            "         [-5.4618, -1.4969, -2.8331,  ..., -4.1447, -2.9250, -1.4296],\n",
            "         [ 0.7552,  0.9722, -5.5651,  ..., -2.4703, -4.5351, -5.4583],\n",
            "         ...,\n",
            "         [-5.9636, -2.1123, -1.8384,  ..., -1.7134, -3.9349,  1.2012],\n",
            "         [-7.3344, -3.8027, -4.1900,  ..., -5.0742, -4.2106, -5.6376],\n",
            "         [ 1.7140,  1.0224,  0.5688,  ..., -0.7184,  0.8511,  1.9212]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.3767,  -1.6453,  -5.3192,  ...,  -1.6030,  -1.4135,  -1.1338],\n",
            "         [ -9.0621,  -5.4958,  -7.7061,  ...,  -7.7628,  -7.4850,  -5.5276],\n",
            "         [ -3.1087,  -3.1985, -10.2913,  ...,  -6.1837,  -8.9395,  -9.4407],\n",
            "         ...,\n",
            "         [ -9.6503,  -6.0998,  -6.7838,  ...,  -5.5045,  -8.0821,  -3.2933],\n",
            "         [-10.9195,  -7.8638,  -9.0684,  ...,  -8.4191,  -8.0646,  -9.4794],\n",
            "         [ -2.0572,  -3.2813,  -4.6324,  ...,  -4.7553,  -3.5418,  -2.4041]],\n",
            "\n",
            "        [[ -1.5121,  -1.7239,  -4.6019,  ...,  -1.6565,  -1.3881,  -1.2869],\n",
            "         [ -7.9425,  -4.9292,  -6.6487,  ...,  -6.8478,  -6.4816,  -4.9285],\n",
            "         [ -2.9712,  -3.0138,  -8.7309,  ...,  -5.4799,  -7.6816,  -8.1291],\n",
            "         ...,\n",
            "         [ -8.3282,  -5.4411,  -5.8355,  ...,  -4.9488,  -6.9166,  -3.0109],\n",
            "         [ -9.3686,  -6.8836,  -7.7224,  ...,  -7.3025,  -6.9361,  -8.1488],\n",
            "         [ -2.0697,  -3.0984,  -4.0861,  ...,  -4.3053,  -3.2575,  -2.3397]],\n",
            "\n",
            "        [[ -1.4103,  -1.6619,  -5.0816,  ...,  -1.6237,  -1.4093,  -1.1720],\n",
            "         [ -8.6882,  -5.3009,  -7.3563,  ...,  -7.4587,  -7.1664,  -5.3263],\n",
            "         [ -3.0707,  -3.1365,  -9.7695,  ...,  -5.9530,  -8.5298,  -9.0004],\n",
            "         ...,\n",
            "         [ -9.2171,  -5.8719,  -6.4744,  ...,  -5.3255,  -7.6888,  -3.2163],\n",
            "         [-10.4040,  -7.5370,  -8.6255,  ...,  -8.0324,  -7.6647,  -9.0244],\n",
            "         [ -2.0611,  -3.2267,  -4.4669,  ...,  -4.6256,  -3.4492,  -2.3877]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.5609,  -1.7528,  -4.9162,  ...,  -1.5449,  -1.2914,  -1.3184],\n",
            "         [ -8.5095,  -5.2664,  -7.1149,  ...,  -7.2817,  -6.7583,  -5.2238],\n",
            "         [ -2.9296,  -3.0646,  -9.5193,  ...,  -5.7522,  -8.1741,  -8.8089],\n",
            "         ...,\n",
            "         [ -8.9084,  -5.8378,  -6.2014,  ...,  -5.1199,  -7.5501,  -2.8905],\n",
            "         [-10.1393,  -7.3594,  -8.3107,  ...,  -8.0223,  -7.7773,  -8.9414],\n",
            "         [ -2.0346,  -3.0601,  -4.0978,  ...,  -4.2416,  -3.3298,  -2.2571]],\n",
            "\n",
            "        [[ -3.0213,  -3.3007,  -4.2213,  ...,  -1.7977,  -1.9444,  -3.7076],\n",
            "         [ -6.2760,  -5.7669,  -5.8946,  ...,  -5.4020,  -3.7909,  -5.4501],\n",
            "         [ -2.8701,  -3.0179,  -6.6225,  ...,  -3.9746,  -5.2889,  -6.9089],\n",
            "         ...,\n",
            "         [ -5.9664,  -5.2118,  -4.6401,  ...,  -4.2686,  -6.0451,  -0.9628],\n",
            "         [ -7.0009,  -6.3711,  -6.0490,  ...,  -6.4653,  -6.5380,  -7.0453],\n",
            "         [ -0.9445,  -1.0010,  -1.0205,  ...,  -1.9038,  -1.7649,  -1.4633]],\n",
            "\n",
            "        [[ -1.5226,  -1.7467,  -5.3286,  ...,  -1.4967,  -1.2798,  -1.2756],\n",
            "         [ -9.1827,  -5.6364,  -7.7268,  ...,  -7.8272,  -7.2712,  -5.5857],\n",
            "         [ -2.9657,  -3.1673, -10.4588,  ...,  -6.1529,  -8.8813,  -9.6143],\n",
            "         ...,\n",
            "         [ -9.6846,  -6.2518,  -6.7321,  ...,  -5.3960,  -8.2811,  -2.9549],\n",
            "         [-11.0554,  -7.9422,  -9.0837,  ...,  -8.7567,  -8.5568,  -9.7936],\n",
            "         [ -2.0070,  -3.1171,  -4.3249,  ...,  -4.4009,  -3.4950,  -2.2348]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.1530,  2.2021, -0.3242,  ..., -1.0278,  0.6527,  1.6105],\n",
            "        [ 0.0548,  0.3949, -0.7314,  ...,  1.4264,  1.1071,  1.7417],\n",
            "        [ 2.2115,  2.2909, -0.3480,  ..., -1.0136,  0.7108,  1.6949],\n",
            "        ...,\n",
            "        [-0.1844, -0.3289, -1.4064,  ...,  2.0777,  1.8903,  2.8341],\n",
            "        [-0.0368,  0.2120, -0.8871,  ...,  1.6302,  1.3038,  2.0359],\n",
            "        [ 0.9304,  1.2645, -0.5047,  ...,  0.4000,  0.5484,  1.4745]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.1530,  2.2021, -0.3242,  ...,  1.8248,  2.6224,  2.7889],\n",
            "         [-4.6849, -1.2226, -2.4573,  ..., -3.6457, -2.7990, -1.1158],\n",
            "         [ 0.5948,  0.8288, -4.7399,  ..., -2.2754, -4.0846, -4.5530],\n",
            "         ...,\n",
            "         [-5.1052, -1.7814, -1.6410,  ..., -1.6850, -3.2727,  0.8502],\n",
            "         [-6.2481, -3.3136, -3.6721,  ..., -4.1834, -3.2588, -4.5706],\n",
            "         [ 1.5071,  0.7119,  0.1906,  ..., -1.0278,  0.6527,  1.6105]],\n",
            "\n",
            "        [[ 0.0548,  0.3949, -0.7314,  ...,  1.7097,  1.2588, -0.0864],\n",
            "         [-3.3347, -2.0451, -2.4179,  ..., -1.9451, -0.7436, -1.9231],\n",
            "         [ 0.1808,  0.5279, -3.3345,  ..., -0.4571, -2.3320, -3.4802],\n",
            "         ...,\n",
            "         [-3.0204, -1.7533, -1.1453,  ..., -0.7915, -3.0587,  2.3283],\n",
            "         [-4.0986, -2.6953, -2.6229,  ..., -2.9765, -3.5752, -3.5984],\n",
            "         [ 1.8656,  2.2531,  2.1615,  ...,  1.4264,  1.1071,  1.7417]],\n",
            "\n",
            "        [[ 2.2115,  2.2909, -0.3480,  ...,  1.9233,  2.7557,  2.8814],\n",
            "         [-4.9238, -1.2925, -2.5654,  ..., -3.8050, -2.8894, -1.1885],\n",
            "         [ 0.6361,  0.8753, -4.9935,  ..., -2.3738, -4.2596, -4.8165],\n",
            "         ...,\n",
            "         [-5.3719, -1.8829, -1.7105,  ..., -1.7380, -3.4639,  0.9116],\n",
            "         [-6.5935, -3.4750, -3.8488,  ..., -4.4401, -3.4935, -4.8627],\n",
            "         [ 1.5637,  0.7765,  0.2525,  ..., -1.0136,  0.7108,  1.6949]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.1844, -0.3289, -1.4064,  ...,  1.8974,  0.9394, -0.7899],\n",
            "         [-3.8088, -3.2613, -3.3157,  ..., -2.1794, -1.0132, -2.6142],\n",
            "         [-0.0957,  0.3058, -3.6439,  ..., -0.6261, -2.5890, -4.2581],\n",
            "         ...,\n",
            "         [-3.3693, -1.8934, -1.7957,  ..., -1.1240, -3.5277,  3.2460],\n",
            "         [-4.5178, -3.7684, -3.2444,  ..., -3.6757, -3.9367, -4.3740],\n",
            "         [ 3.0085,  3.7776,  3.4034,  ...,  2.0777,  1.8903,  2.8341]],\n",
            "\n",
            "        [[-0.0368,  0.2120, -0.8871,  ...,  1.7546,  1.1416, -0.2863],\n",
            "         [-3.4080, -2.3399, -2.6023,  ..., -1.9694, -0.7917, -2.1078],\n",
            "         [ 0.0971,  0.5009, -3.3663,  ..., -0.5184, -2.3705, -3.6289],\n",
            "         ...,\n",
            "         [-3.0735, -1.7709, -1.3122,  ..., -0.8365, -3.1583,  2.5394],\n",
            "         [-4.1683, -2.9640, -2.7651,  ..., -3.1282, -3.6617, -3.7788],\n",
            "         [ 2.1441,  2.6233,  2.4929,  ...,  1.6302,  1.3038,  2.0359]],\n",
            "\n",
            "        [[ 0.9304,  1.2645, -0.5047,  ...,  1.8979,  2.1279,  1.2985],\n",
            "         [-3.9581, -1.5169, -2.1670,  ..., -2.7400, -1.4957, -1.4106],\n",
            "         [ 0.3840,  0.5656, -3.9331,  ..., -1.1624, -2.9941, -3.8516],\n",
            "         ...,\n",
            "         [-3.9099, -1.5902, -1.2114,  ..., -0.9741, -3.0782,  1.6698],\n",
            "         [-4.9164, -2.7299, -2.8675,  ..., -3.5636, -3.4909, -4.0899],\n",
            "         [ 1.3280,  1.1064,  1.0578,  ...,  0.4000,  0.5484,  1.4745]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.4642,  -1.6825,  -4.8107,  ...,  -1.6373,  -1.3949,  -1.2104],\n",
            "         [ -8.3021,  -5.1071,  -6.9438,  ...,  -7.1078,  -6.8163,  -5.1151],\n",
            "         [ -3.0225,  -3.0557,  -9.2264,  ...,  -5.7375,  -8.1019,  -8.5523],\n",
            "         ...,\n",
            "         [ -8.7225,  -5.6660,  -6.1275,  ...,  -5.1471,  -7.2900,  -3.1491],\n",
            "         [ -9.8654,  -7.1982,  -8.1586,  ...,  -7.6455,  -7.2761,  -8.5699],\n",
            "         [ -2.1102,  -3.1727,  -4.2959,  ...,  -4.4899,  -3.3646,  -2.3888]],\n",
            "\n",
            "        [[ -2.9101,  -3.0572,  -4.0852,  ...,  -1.7559,  -1.7787,  -3.4298],\n",
            "         [ -6.2996,  -5.4972,  -5.7717,  ...,  -5.4106,  -3.7812,  -5.2665],\n",
            "         [ -2.7841,  -2.9242,  -6.6883,  ...,  -3.9227,  -5.3695,  -6.8236],\n",
            "         ...,\n",
            "         [ -5.9854,  -5.2054,  -4.4991,  ...,  -4.2571,  -6.0962,  -1.0151],\n",
            "         [ -7.0636,  -6.1474,  -5.9767,  ...,  -6.4420,  -6.6128,  -6.9419],\n",
            "         [ -1.0994,  -1.1990,  -1.1923,  ...,  -2.0391,  -1.9305,  -1.6017]],\n",
            "\n",
            "        [[ -1.4553,  -1.6773,  -4.9802,  ...,  -1.6037,  -1.3768,  -1.1952],\n",
            "         [ -8.5907,  -5.2607,  -7.1977,  ...,  -7.3320,  -7.0220,  -5.2650],\n",
            "         [ -3.0308,  -3.0929,  -9.6257,  ...,  -5.9008,  -8.3921,  -8.8931],\n",
            "         ...,\n",
            "         [ -9.0387,  -5.8511,  -6.3428,  ...,  -5.2650,  -7.5964,  -3.1649],\n",
            "         [-10.2604,  -7.4432,  -8.4811,  ...,  -7.9671,  -7.6260,  -8.9392],\n",
            "         [ -2.1032,  -3.1917,  -4.3798,  ...,  -4.5406,  -3.4217,  -2.3817]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -3.6234,  -4.5156,  -5.3871,  ...,  -1.7804,  -2.3015,  -4.8238],\n",
            "         [ -7.2477,  -7.4480,  -7.2964,  ...,  -5.8573,  -4.2541,  -6.6481],\n",
            "         [ -3.5347,  -3.8809,  -7.6246,  ...,  -4.3039,  -5.8298,  -8.2919],\n",
            "         ...,\n",
            "         [ -6.8083,  -6.0801,  -5.7764,  ...,  -4.8018,  -6.7686,  -0.7878],\n",
            "         [ -7.9568,  -7.9551,  -7.2251,  ...,  -7.3535,  -7.1776,  -8.4078],\n",
            "         [ -0.4305,  -0.4091,  -0.5773,  ...,  -1.6001,  -1.3506,  -1.1997]],\n",
            "\n",
            "        [[ -3.0684,  -3.3573,  -4.3522,  ...,  -1.7640,  -1.9118,  -3.7651],\n",
            "         [ -6.4396,  -5.9092,  -6.0674,  ...,  -5.4880,  -3.8451,  -5.5867],\n",
            "         [ -2.9346,  -3.0684,  -6.8314,  ...,  -4.0370,  -5.4239,  -7.1077],\n",
            "         ...,\n",
            "         [ -6.1052,  -5.3402,  -4.7774,  ...,  -4.3551,  -6.2117,  -0.9395],\n",
            "         [ -7.1999,  -6.5333,  -6.2302,  ...,  -6.6468,  -6.7151,  -7.2577],\n",
            "         [ -0.8876,  -0.9459,  -0.9723,  ...,  -1.8884,  -1.7496,  -1.4429]],\n",
            "\n",
            "        [[ -2.1935,  -2.1913,  -4.1679,  ...,  -1.4776,  -1.2402,  -2.0827],\n",
            "         [ -7.0819,  -4.9727,  -5.8302,  ...,  -6.1156,  -4.8637,  -4.7918],\n",
            "         [ -2.7399,  -2.8902,  -7.5963,  ...,  -4.5380,  -6.3621,  -7.2328],\n",
            "         ...,\n",
            "         [ -7.0338,  -5.0460,  -4.8746,  ...,  -4.3496,  -6.4462,  -1.7114],\n",
            "         [ -8.0402,  -6.1857,  -6.5307,  ...,  -6.9391,  -6.8590,  -7.4711],\n",
            "         [ -1.7959,  -2.3494,  -2.6054,  ...,  -2.9755,  -2.8196,  -1.9067]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.2087,  2.1558, -0.2802,  ..., -1.2624,  0.5722,  1.4995],\n",
            "        [ 0.3546,  0.8477, -0.8183,  ...,  1.3264,  1.0952,  1.8598],\n",
            "        [-0.1076,  0.2219, -1.0838,  ...,  1.9050,  1.5979,  2.4187],\n",
            "        ...,\n",
            "        [ 0.0741,  0.5195, -0.7452,  ...,  1.4449,  1.1177,  1.7991],\n",
            "        [ 0.8839,  1.2965, -0.6694,  ...,  0.7104,  0.7639,  1.7490],\n",
            "        [ 0.0317,  0.3444, -0.7791,  ...,  1.4933,  1.1681,  1.8244]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.2087e+00,  2.1558e+00, -2.8019e-01,  ...,  1.6399e+00,\n",
            "           2.4186e+00,  2.8421e+00],\n",
            "         [-4.3919e+00, -1.1628e+00, -2.2757e+00,  ..., -3.5067e+00,\n",
            "          -2.8207e+00, -9.7319e-01],\n",
            "         [ 5.4990e-01,  8.1156e-01, -4.4434e+00,  ..., -2.2676e+00,\n",
            "          -4.0013e+00, -4.2017e+00],\n",
            "         ...,\n",
            "         [-4.8136e+00, -1.6646e+00, -1.5922e+00,  ..., -1.7579e+00,\n",
            "          -3.0301e+00,  6.6257e-01],\n",
            "         [-5.8800e+00, -3.1871e+00, -3.5196e+00,  ..., -3.8199e+00,\n",
            "          -2.8280e+00, -4.1463e+00],\n",
            "         [ 1.4743e+00,  5.6266e-01,  5.6079e-03,  ..., -1.2624e+00,\n",
            "           5.7215e-01,  1.4995e+00]],\n",
            "\n",
            "        [[ 3.5455e-01,  8.4771e-01, -8.1827e-01,  ...,  2.1466e+00,\n",
            "           1.9412e+00,  4.3356e-01],\n",
            "         [-4.2948e+00, -2.2305e+00, -2.7362e+00,  ..., -2.6693e+00,\n",
            "          -1.0498e+00, -2.0726e+00],\n",
            "         [ 3.1799e-01,  5.1346e-01, -4.3240e+00,  ..., -7.5930e-01,\n",
            "          -3.1341e+00, -4.4318e+00],\n",
            "         ...,\n",
            "         [-4.1735e+00, -2.0662e+00, -1.3274e+00,  ..., -1.0009e+00,\n",
            "          -3.8571e+00,  2.4780e+00],\n",
            "         [-5.4281e+00, -3.1437e+00, -3.2515e+00,  ..., -4.0500e+00,\n",
            "          -4.3325e+00, -4.7614e+00],\n",
            "         [ 1.8718e+00,  2.1755e+00,  2.1636e+00,  ...,  1.3264e+00,\n",
            "           1.0952e+00,  1.8598e+00]],\n",
            "\n",
            "        [[-1.0758e-01,  2.2190e-01, -1.0838e+00,  ...,  1.9944e+00,\n",
            "           1.3598e+00, -3.2514e-01],\n",
            "         [-4.0194e+00, -2.7472e+00, -3.0820e+00,  ..., -2.2922e+00,\n",
            "          -8.8882e-01, -2.5067e+00],\n",
            "         [ 5.8990e-02,  5.4199e-01, -4.0065e+00,  ..., -6.3123e-01,\n",
            "          -2.8033e+00, -4.3552e+00],\n",
            "         ...,\n",
            "         [-3.6807e+00, -2.1003e+00, -1.5806e+00,  ..., -9.7543e-01,\n",
            "          -3.7759e+00,  2.9557e+00],\n",
            "         [-4.9877e+00, -3.4441e+00, -3.2368e+00,  ..., -3.8494e+00,\n",
            "          -4.3489e+00, -4.5665e+00],\n",
            "         [ 2.5153e+00,  3.1281e+00,  3.0147e+00,  ...,  1.9050e+00,\n",
            "           1.5979e+00,  2.4187e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 7.4119e-02,  5.1951e-01, -7.4517e-01,  ...,  1.8551e+00,\n",
            "           1.4560e+00,  2.1653e-02],\n",
            "         [-3.6482e+00, -2.1314e+00, -2.5879e+00,  ..., -2.1320e+00,\n",
            "          -7.9491e-01, -2.0284e+00],\n",
            "         [ 2.1532e-01,  5.3413e-01, -3.6729e+00,  ..., -5.2382e-01,\n",
            "          -2.5898e+00, -3.8103e+00],\n",
            "         ...,\n",
            "         [-3.3530e+00, -1.9042e+00, -1.1961e+00,  ..., -8.5681e-01,\n",
            "          -3.3667e+00,  2.4156e+00],\n",
            "         [-4.5296e+00, -2.8444e+00, -2.8207e+00,  ..., -3.3297e+00,\n",
            "          -3.8922e+00, -3.9753e+00],\n",
            "         [ 1.8961e+00,  2.2982e+00,  2.2404e+00,  ...,  1.4449e+00,\n",
            "           1.1177e+00,  1.7991e+00]],\n",
            "\n",
            "        [[ 8.8386e-01,  1.2965e+00, -6.6943e-01,  ...,  2.2066e+00,\n",
            "           2.3812e+00,  1.2297e+00],\n",
            "         [-4.5788e+00, -1.8976e+00, -2.5284e+00,  ..., -3.0394e+00,\n",
            "          -1.5176e+00, -1.7485e+00],\n",
            "         [ 4.0622e-01,  6.1055e-01, -4.5732e+00,  ..., -1.2103e+00,\n",
            "          -3.3945e+00, -4.5695e+00],\n",
            "         ...,\n",
            "         [-4.5405e+00, -1.8895e+00, -1.3956e+00,  ..., -1.0943e+00,\n",
            "          -3.6995e+00,  2.1095e+00],\n",
            "         [-5.7184e+00, -3.1663e+00, -3.3230e+00,  ..., -4.2358e+00,\n",
            "          -4.1866e+00, -4.8730e+00],\n",
            "         [ 1.6053e+00,  1.4886e+00,  1.4795e+00,  ...,  7.1040e-01,\n",
            "           7.6390e-01,  1.7490e+00]],\n",
            "\n",
            "        [[ 3.1655e-02,  3.4440e-01, -7.7907e-01,  ...,  1.7442e+00,\n",
            "           1.2580e+00, -1.4866e-01],\n",
            "         [-3.4011e+00, -2.1531e+00, -2.4877e+00,  ..., -1.9688e+00,\n",
            "          -7.6268e-01, -1.9838e+00],\n",
            "         [ 1.3512e-01,  5.3391e-01, -3.3987e+00,  ..., -4.9897e-01,\n",
            "          -2.3899e+00, -3.5762e+00],\n",
            "         ...,\n",
            "         [-3.0671e+00, -1.7981e+00, -1.2045e+00,  ..., -8.5078e-01,\n",
            "          -3.1366e+00,  2.3946e+00],\n",
            "         [-4.1817e+00, -2.8077e+00, -2.7094e+00,  ..., -3.0604e+00,\n",
            "          -3.6589e+00, -3.7001e+00],\n",
            "         [ 1.9587e+00,  2.3740e+00,  2.2769e+00,  ...,  1.4933e+00,\n",
            "           1.1681e+00,  1.8244e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[-1.4112, -1.6555, -4.6482,  ..., -1.7424, -1.5123, -1.1513],\n",
            "         [-8.0117, -4.9741, -6.6437,  ..., -6.8890, -6.7516, -4.9666],\n",
            "         [-3.0699, -2.9997, -8.8113,  ..., -5.6499, -7.9322, -8.1952],\n",
            "         ...,\n",
            "         [-8.4334, -5.4759, -5.9602,  ..., -5.1402, -6.9610, -3.3308],\n",
            "         [-9.4998, -6.9984, -7.8876,  ..., -7.2022, -6.7590, -8.1397],\n",
            "         [-2.1455, -3.2486, -4.3624,  ..., -4.6447, -3.3588, -2.4939]],\n",
            "\n",
            "        [[-2.7309, -2.7502, -4.5958,  ..., -1.4449, -1.4272, -3.0693],\n",
            "         [-7.3802, -5.8284, -6.5137,  ..., -6.2607, -4.4181, -5.5755],\n",
            "         [-2.7675, -3.0845, -8.1015,  ..., -4.3507, -6.5025, -7.9346],\n",
            "         ...,\n",
            "         [-7.2590, -5.6641, -5.1049,  ..., -4.5924, -7.2254, -1.0249],\n",
            "         [-8.5135, -6.7417, -7.0291,  ..., -7.6415, -7.7008, -8.2643],\n",
            "         [-1.2136, -1.4225, -1.6140,  ..., -2.2650, -2.2731, -1.6431]],\n",
            "\n",
            "        [[-3.3085, -3.6325, -4.9242,  ..., -1.6829, -1.8828, -4.0992],\n",
            "         [-7.2204, -6.6016, -6.9224,  ..., -5.9695, -4.1314, -6.2808],\n",
            "         [-3.1420, -3.3125, -7.8469,  ..., -4.3085, -6.0459, -8.1292],\n",
            "         ...,\n",
            "         [-6.8816, -5.9548, -5.4210,  ..., -4.6528, -7.0185, -0.8183],\n",
            "         [-8.1886, -7.2985, -7.0772,  ..., -7.5267, -7.5915, -8.3406],\n",
            "         [-0.6856, -0.7264, -0.8257,  ..., -1.7723, -1.6447, -1.3554]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-2.9223, -2.9882, -4.2232,  ..., -1.6554, -1.6656, -3.3835],\n",
            "         [-6.6446, -5.6391, -6.0660,  ..., -5.6425, -3.9165, -5.4336],\n",
            "         [-2.7811, -2.9736, -7.1509,  ..., -4.0343, -5.7114, -7.2155],\n",
            "         ...,\n",
            "         [-6.3495, -5.4119, -4.6741,  ..., -4.3673, -6.4883, -0.9896],\n",
            "         [-7.5261, -6.3521, -6.2988,  ..., -6.8403, -7.0138, -7.3804],\n",
            "         [-1.1004, -1.2096, -1.2376,  ..., -2.0656, -2.0039, -1.6061]],\n",
            "\n",
            "        [[-2.3148, -2.3176, -4.6237,  ..., -1.3376, -1.1933, -2.2978],\n",
            "         [-7.7774, -5.5118, -6.4827,  ..., -6.5837, -5.0921, -5.2760],\n",
            "         [-2.7924, -3.0036, -8.5275,  ..., -4.7546, -6.9691, -8.0970],\n",
            "         ...,\n",
            "         [-7.7391, -5.5037, -5.3499,  ..., -4.6385, -7.2740, -1.4180],\n",
            "         [-8.9170, -6.7805, -7.2773,  ..., -7.7800, -7.7612, -8.4005],\n",
            "         [-1.5933, -2.1256, -2.4748,  ..., -2.8339, -2.8106, -1.7785]],\n",
            "\n",
            "        [[-2.9543, -3.1475, -4.1797,  ..., -1.7414, -1.7941, -3.5330],\n",
            "         [-6.3871, -5.6450, -5.8883,  ..., -5.4543, -3.8148, -5.3681],\n",
            "         [-2.8509, -2.9580, -6.7993,  ..., -3.9845, -5.4421, -6.9605],\n",
            "         ...,\n",
            "         [-6.0531, -5.2900, -4.6051,  ..., -4.3363, -6.1887, -0.9898],\n",
            "         [-7.1677, -6.2996, -6.1100,  ..., -6.5460, -6.7110, -7.0844],\n",
            "         [-1.0273, -1.1179, -1.1237,  ..., -1.9923, -1.8840, -1.5600]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.0589,  0.4873, -0.7981,  ...,  1.5483,  1.2190,  1.8946],\n",
            "        [ 2.4851,  2.4871, -0.3014,  ..., -1.3893,  0.7422,  1.7438],\n",
            "        [-0.0665,  0.0267, -0.9891,  ...,  1.7129,  1.3829,  2.1518],\n",
            "        ...,\n",
            "        [ 0.1646,  0.6814, -0.8484,  ...,  1.5398,  1.2372,  1.9734],\n",
            "        [ 0.8390,  1.1729, -0.5064,  ...,  0.5035,  0.5684,  1.4476],\n",
            "        [-0.0067, -0.5028, -1.0164,  ...,  1.4459,  1.0970,  1.7692]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 5.8907e-02,  4.8726e-01, -7.9811e-01,  ...,  1.8942e+00,\n",
            "           1.4816e+00, -3.0184e-02],\n",
            "         [-3.7682e+00, -2.2445e+00, -2.6830e+00,  ..., -2.1722e+00,\n",
            "          -8.0292e-01, -2.1263e+00],\n",
            "         [ 1.8451e-01,  5.6551e-01, -3.8057e+00,  ..., -5.5053e-01,\n",
            "          -2.6724e+00, -3.9650e+00],\n",
            "         ...,\n",
            "         [-3.4423e+00, -1.9957e+00, -1.2786e+00,  ..., -9.1436e-01,\n",
            "          -3.4988e+00,  2.5139e+00],\n",
            "         [-4.6800e+00, -2.9679e+00, -2.9412e+00,  ..., -3.4680e+00,\n",
            "          -4.0506e+00, -4.1232e+00],\n",
            "         [ 2.0201e+00,  2.4505e+00,  2.4059e+00,  ...,  1.5483e+00,\n",
            "           1.2190e+00,  1.8946e+00]],\n",
            "\n",
            "        [[ 2.4851e+00,  2.4871e+00, -3.0140e-01,  ...,  1.8939e+00,\n",
            "           2.8044e+00,  3.2746e+00],\n",
            "         [-5.1059e+00, -1.3465e+00, -2.5578e+00,  ..., -4.0057e+00,\n",
            "          -3.2046e+00, -1.1494e+00],\n",
            "         [ 6.8673e-01,  9.7669e-01, -5.2123e+00,  ..., -2.6745e+00,\n",
            "          -4.6093e+00, -4.9801e+00],\n",
            "         ...,\n",
            "         [-5.6335e+00, -1.9668e+00, -1.8336e+00,  ..., -2.0115e+00,\n",
            "          -3.5983e+00,  7.2993e-01],\n",
            "         [-6.9290e+00, -3.6965e+00, -4.1024e+00,  ..., -4.5648e+00,\n",
            "          -3.3976e+00, -4.9483e+00],\n",
            "         [ 1.6137e+00,  6.9891e-01,  6.7530e-02,  ..., -1.3893e+00,\n",
            "           7.4223e-01,  1.7438e+00]],\n",
            "\n",
            "        [[-6.6492e-02,  2.6674e-02, -9.8906e-01,  ...,  1.7390e+00,\n",
            "           1.0292e+00, -4.4867e-01],\n",
            "         [-3.2906e+00, -2.4715e+00, -2.6023e+00,  ..., -1.8656e+00,\n",
            "          -8.0552e-01, -2.1333e+00],\n",
            "         [-3.7650e-02,  4.2493e-01, -3.1810e+00,  ..., -5.6703e-01,\n",
            "          -2.2912e+00, -3.5020e+00],\n",
            "         ...,\n",
            "         [-2.8698e+00, -1.6990e+00, -1.4235e+00,  ..., -9.3295e-01,\n",
            "          -3.0540e+00,  2.5186e+00],\n",
            "         [-3.9406e+00, -3.0651e+00, -2.7571e+00,  ..., -3.0410e+00,\n",
            "          -3.5066e+00, -3.6647e+00],\n",
            "         [ 2.2993e+00,  2.8001e+00,  2.6637e+00,  ...,  1.7129e+00,\n",
            "           1.3829e+00,  2.1518e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.6464e-01,  6.8137e-01, -8.4842e-01,  ...,  2.1178e+00,\n",
            "           1.7667e+00,  1.6930e-01],\n",
            "         [-4.2438e+00, -2.3647e+00, -2.8683e+00,  ..., -2.5108e+00,\n",
            "          -9.1995e-01, -2.2268e+00],\n",
            "         [ 2.5027e-01,  5.6156e-01, -4.2672e+00,  ..., -6.7789e-01,\n",
            "          -3.0498e+00, -4.4396e+00],\n",
            "         ...,\n",
            "         [-4.0090e+00, -2.1379e+00, -1.3557e+00,  ..., -9.9179e-01,\n",
            "          -3.9092e+00,  2.6314e+00],\n",
            "         [-5.3247e+00, -3.2074e+00, -3.2613e+00,  ..., -3.9913e+00,\n",
            "          -4.4376e+00, -4.7109e+00],\n",
            "         [ 2.0270e+00,  2.4536e+00,  2.4443e+00,  ...,  1.5398e+00,\n",
            "           1.2372e+00,  1.9734e+00]],\n",
            "\n",
            "        [[ 8.3905e-01,  1.1729e+00, -5.0635e-01,  ...,  1.9184e+00,\n",
            "           2.0940e+00,  1.1680e+00],\n",
            "         [-3.9355e+00, -1.5750e+00, -2.1339e+00,  ..., -2.6538e+00,\n",
            "          -1.4050e+00, -1.4381e+00],\n",
            "         [ 3.4797e-01,  5.6197e-01, -3.8962e+00,  ..., -1.0954e+00,\n",
            "          -2.9563e+00, -3.8291e+00],\n",
            "         ...,\n",
            "         [-3.8000e+00, -1.6372e+00, -1.2002e+00,  ..., -1.0024e+00,\n",
            "          -3.0978e+00,  1.7242e+00],\n",
            "         [-4.8490e+00, -2.7199e+00, -2.8476e+00,  ..., -3.5361e+00,\n",
            "          -3.5157e+00, -4.0600e+00],\n",
            "         [ 1.3193e+00,  1.1621e+00,  1.1297e+00,  ...,  5.0346e-01,\n",
            "           5.6835e-01,  1.4476e+00]],\n",
            "\n",
            "        [[-6.6914e-03, -5.0282e-01, -1.0164e+00,  ...,  1.1882e+00,\n",
            "           6.0819e-01, -7.6734e-01],\n",
            "         [-2.1161e+00, -2.3158e+00, -2.0443e+00,  ..., -1.2472e+00,\n",
            "          -6.5868e-01, -1.4603e+00],\n",
            "         [-1.2110e-01,  1.2639e-01, -2.0504e+00,  ..., -3.5478e-01,\n",
            "          -1.5474e+00, -2.4615e+00],\n",
            "         ...,\n",
            "         [-1.5843e+00, -1.0851e+00, -1.2106e+00,  ..., -9.9069e-01,\n",
            "          -1.9432e+00,  2.0527e+00],\n",
            "         [-2.3815e+00, -2.4675e+00, -2.0780e+00,  ..., -1.9570e+00,\n",
            "          -2.0294e+00, -2.2371e+00],\n",
            "         [ 2.1006e+00,  2.5301e+00,  2.0754e+00,  ...,  1.4459e+00,\n",
            "           1.0970e+00,  1.7692e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.9732,  -3.0825,  -4.3538,  ...,  -1.6564,  -1.6767,  -3.4957],\n",
            "         [ -6.8004,  -5.8142,  -6.2387,  ...,  -5.7227,  -3.9612,  -5.5918],\n",
            "         [ -2.8476,  -3.0042,  -7.3614,  ...,  -4.1011,  -5.8307,  -7.4305],\n",
            "         ...,\n",
            "         [ -6.4744,  -5.5655,  -4.8343,  ...,  -4.4649,  -6.6571,  -0.9516],\n",
            "         [ -7.7121,  -6.5377,  -6.4969,  ...,  -7.0186,  -7.2089,  -7.5886],\n",
            "         [ -1.0120,  -1.1193,  -1.1498,  ...,  -2.0022,  -1.9393,  -1.5709]],\n",
            "\n",
            "        [[ -1.3313,  -1.5891,  -5.1557,  ...,  -1.6892,  -1.5218,  -1.0343],\n",
            "         [ -8.9223,  -5.4226,  -7.4122,  ...,  -7.5888,  -7.5308,  -5.4583],\n",
            "         [ -3.1297,  -3.0995, -10.0666,  ...,  -6.2576,  -8.9355,  -9.2890],\n",
            "         ...,\n",
            "         [ -9.4499,  -6.0429,  -6.6879,  ...,  -5.5947,  -7.9245,  -3.5790],\n",
            "         [-10.7454,  -7.7727,  -8.9568,  ...,  -8.1480,  -7.7239,  -9.2572],\n",
            "         [ -2.2027,  -3.3772,  -4.7868,  ...,  -4.9725,  -3.5840,  -2.5651]],\n",
            "\n",
            "        [[ -3.1318,  -3.5819,  -4.4655,  ...,  -1.7771,  -1.9879,  -3.9443],\n",
            "         [ -6.3559,  -6.0800,  -6.0787,  ...,  -5.3818,  -3.8225,  -5.6290],\n",
            "         [ -3.1030,  -3.1836,  -6.6575,  ...,  -4.0832,  -5.3082,  -6.9976],\n",
            "         ...,\n",
            "         [ -5.9352,  -5.3075,  -4.8999,  ...,  -4.4491,  -6.0710,  -0.9771],\n",
            "         [ -7.0060,  -6.6736,  -6.2335,  ...,  -6.5572,  -6.5236,  -7.1604],\n",
            "         [ -0.7661,  -0.8084,  -0.8127,  ...,  -1.8032,  -1.6341,  -1.3439]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.9203,  -2.9654,  -4.6041,  ...,  -1.5033,  -1.5503,  -3.3903],\n",
            "         [ -7.3288,  -6.0114,  -6.6240,  ...,  -6.1319,  -4.2369,  -5.7865],\n",
            "         [ -2.8347,  -3.0852,  -8.0229,  ...,  -4.2990,  -6.3667,  -7.9993],\n",
            "         ...,\n",
            "         [ -7.0940,  -5.7847,  -5.1113,  ...,  -4.6129,  -7.2262,  -0.9282],\n",
            "         [ -8.4097,  -6.8541,  -7.0170,  ...,  -7.6124,  -7.7545,  -8.2705],\n",
            "         [ -1.0580,  -1.1931,  -1.3114,  ...,  -2.0813,  -2.0797,  -1.5862]],\n",
            "\n",
            "        [[ -2.2584,  -2.2565,  -4.1190,  ...,  -1.4628,  -1.2408,  -2.1824],\n",
            "         [ -7.0330,  -5.0044,  -5.7466,  ...,  -6.0351,  -4.7398,  -4.7886],\n",
            "         [ -2.7495,  -2.8674,  -7.5089,  ...,  -4.4767,  -6.2911,  -7.1796],\n",
            "         ...,\n",
            "         [ -6.8975,  -5.0666,  -4.8129,  ...,  -4.3837,  -6.4325,  -1.6263],\n",
            "         [ -7.9465,  -6.1493,  -6.4603,  ...,  -6.9173,  -6.8505,  -7.4105],\n",
            "         [ -1.7782,  -2.2674,  -2.4830,  ...,  -2.8778,  -2.7664,  -1.9029]],\n",
            "\n",
            "        [[ -2.9799,  -3.8843,  -4.0557,  ...,  -2.1031,  -2.2234,  -4.0141],\n",
            "         [ -5.0893,  -5.6973,  -5.0836,  ...,  -4.5385,  -3.4903,  -4.7071],\n",
            "         [ -3.0943,  -3.2551,  -5.0897,  ...,  -3.6461,  -4.3790,  -5.7083],\n",
            "         ...,\n",
            "         [ -4.5574,  -4.4665,  -4.2499,  ...,  -4.2820,  -4.7748,  -1.1940],\n",
            "         [ -5.3547,  -5.8490,  -5.1173,  ...,  -5.2484,  -4.8610,  -5.4838],\n",
            "         [ -0.8726,  -0.8514,  -0.9639,  ...,  -1.8454,  -1.7346,  -1.4776]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.8265,  1.9781, -0.2201,  ..., -0.7588,  0.5865,  1.4476],\n",
            "        [ 2.3446,  2.3898, -0.2416,  ..., -1.3074,  0.6983,  1.6565],\n",
            "        [ 2.2743,  2.2636, -0.2225,  ..., -1.3417,  0.6192,  1.5407],\n",
            "        ...,\n",
            "        [-0.0106, -0.0365, -0.9219,  ...,  1.5753,  1.2462,  1.9470],\n",
            "        [-0.0168,  0.2743, -0.9234,  ...,  1.6907,  1.3738,  2.0859],\n",
            "        [ 0.1659,  0.3947, -0.5020,  ...,  1.0196,  0.7158,  1.2442]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.8265,  1.9781, -0.2201,  ...,  1.7857,  2.4693,  2.4754],\n",
            "         [-4.4059, -1.1982, -2.1557,  ..., -3.2867, -2.4718, -1.0665],\n",
            "         [ 0.6133,  0.8544, -4.4192,  ..., -2.0945, -3.7338, -4.2588],\n",
            "         ...,\n",
            "         [-4.5960, -1.7825, -1.4713,  ..., -1.5302, -3.0799,  0.8531],\n",
            "         [-5.7828, -3.0734, -3.3802,  ..., -3.9341, -3.2350, -4.3412],\n",
            "         [ 1.2532,  0.6915,  0.2481,  ..., -0.7588,  0.5865,  1.4476]],\n",
            "\n",
            "        [[ 2.3446,  2.3898, -0.2416,  ...,  1.8420,  2.7008,  3.1383],\n",
            "         [-4.9132, -1.2979, -2.4181,  ..., -3.8174, -3.0615, -1.1064],\n",
            "         [ 0.6897,  0.9689, -4.9985,  ..., -2.5759, -4.4131, -4.7752],\n",
            "         ...,\n",
            "         [-5.3561, -1.9182, -1.7497,  ..., -1.9210, -3.4508,  0.6989],\n",
            "         [-6.6236, -3.5413, -3.9287,  ..., -4.3775, -3.2846, -4.7480],\n",
            "         [ 1.4964,  0.6675,  0.0572,  ..., -1.3074,  0.6983,  1.6565]],\n",
            "\n",
            "        [[ 2.2743,  2.2636, -0.2225,  ...,  1.6846,  2.4942,  3.0193],\n",
            "         [-4.5780, -1.2278, -2.2646,  ..., -3.6108, -2.9426, -1.0013],\n",
            "         [ 0.6389,  0.9159, -4.6445,  ..., -2.4347, -4.1885, -4.3959],\n",
            "         ...,\n",
            "         [-4.9892, -1.7819, -1.6530,  ..., -1.8661, -3.1804,  0.6153],\n",
            "         [-6.1588, -3.3375, -3.6836,  ..., -4.0043, -2.9534, -4.3427],\n",
            "         [ 1.4505,  0.5745, -0.0158,  ..., -1.3417,  0.6192,  1.5407]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.0106, -0.0365, -0.9219,  ...,  1.6024,  0.9212, -0.4753],\n",
            "         [-2.9382, -2.2946, -2.3586,  ..., -1.6683, -0.7690, -1.9128],\n",
            "         [-0.0765,  0.3647, -2.8101,  ..., -0.5235, -2.0468, -3.0985],\n",
            "         ...,\n",
            "         [-2.4828, -1.4996, -1.3253,  ..., -0.9388, -2.6967,  2.2750],\n",
            "         [-3.4422, -2.8376, -2.5163,  ..., -2.6390, -3.0961, -3.2033],\n",
            "         [ 2.1559,  2.6021,  2.4268,  ...,  1.5753,  1.2462,  1.9470]],\n",
            "\n",
            "        [[-0.0168,  0.2743, -0.9234,  ...,  1.8638,  1.3269, -0.2481],\n",
            "         [-3.6789, -2.4288, -2.7383,  ..., -2.0915, -0.8326, -2.2128],\n",
            "         [ 0.0439,  0.5155, -3.6588,  ..., -0.5822, -2.5942, -3.9025],\n",
            "         ...,\n",
            "         [-3.2884, -1.9398, -1.4111,  ..., -0.9893, -3.4208,  2.5893],\n",
            "         [-4.5163, -3.1183, -2.9625,  ..., -3.4090, -3.9540, -4.0683],\n",
            "         [ 2.2305,  2.7256,  2.6528,  ...,  1.6907,  1.3738,  2.0859]],\n",
            "\n",
            "        [[ 0.1659,  0.3947, -0.5020,  ...,  1.4619,  1.1257,  0.0295],\n",
            "         [-2.6556, -1.5399, -1.8228,  ..., -1.5743, -0.6716, -1.4246],\n",
            "         [ 0.1254,  0.4116, -2.5803,  ..., -0.3863, -1.9036, -2.5798],\n",
            "         ...,\n",
            "         [-2.2471, -1.3997, -0.8730,  ..., -0.7778, -2.3288,  1.7101],\n",
            "         [-3.1574, -2.1323, -2.0515,  ..., -2.1620, -2.7252, -2.6725],\n",
            "         [ 1.3765,  1.5879,  1.5276,  ...,  1.0196,  0.7158,  1.2442]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.6344,  -1.7506,  -4.3980,  ...,  -1.6001,  -1.3245,  -1.3217],\n",
            "         [ -7.8667,  -4.9269,  -6.3336,  ...,  -6.6725,  -6.2656,  -4.8635],\n",
            "         [ -2.8475,  -2.8743,  -8.5971,  ...,  -5.4803,  -7.5276,  -8.0558],\n",
            "         ...,\n",
            "         [ -8.0568,  -5.5112,  -5.6492,  ...,  -4.9160,  -6.8737,  -2.9440],\n",
            "         [ -9.2436,  -6.8021,  -7.5581,  ...,  -7.3199,  -7.0288,  -8.1382],\n",
            "         [ -2.2076,  -3.0372,  -3.9298,  ...,  -4.1446,  -3.2073,  -2.3495]],\n",
            "\n",
            "        [[ -1.3908,  -1.5948,  -4.9258,  ...,  -1.6808,  -1.4966,  -1.0621],\n",
            "         [ -8.6487,  -5.2824,  -7.1024,  ...,  -7.3402,  -7.2589,  -5.3069],\n",
            "         [ -3.0458,  -3.0156,  -9.6828,  ...,  -6.0988,  -8.6105,  -8.9757],\n",
            "         ...,\n",
            "         [ -9.0916,  -5.9028,  -6.4340,  ...,  -5.4438,  -7.6482,  -3.5016],\n",
            "         [-10.3590,  -7.5258,  -8.6129,  ...,  -7.9003,  -7.4820,  -8.9484],\n",
            "         [ -2.2391,  -3.3171,  -4.6271,  ...,  -4.8302,  -3.4991,  -2.5439]],\n",
            "\n",
            "        [[ -1.3981,  -1.6086,  -4.7072,  ...,  -1.7433,  -1.5419,  -1.0773],\n",
            "         [ -8.2504,  -5.0999,  -6.7493,  ...,  -7.0387,  -6.9787,  -5.0979],\n",
            "         [ -3.0336,  -2.9563,  -9.1292,  ...,  -5.8626,  -8.2246,  -8.4925],\n",
            "         ...,\n",
            "         [ -8.6617,  -5.6541,  -6.1377,  ...,  -5.2941,  -7.2165,  -3.4813],\n",
            "         [ -9.8312,  -7.2097,  -8.1683,  ...,  -7.4323,  -6.9895,  -8.4393],\n",
            "         [ -2.2220,  -3.2977,  -4.5005,  ...,  -4.7696,  -3.4169,  -2.5560]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -3.0085,  -3.5211,  -4.2147,  ...,  -1.8326,  -2.0103,  -3.8237],\n",
            "         [ -5.9361,  -5.7792,  -5.6513,  ...,  -5.1032,  -3.7006,  -5.2612],\n",
            "         [ -3.0744,  -3.1199,  -6.1029,  ...,  -3.9585,  -4.9783,  -6.4469],\n",
            "         ...,\n",
            "         [ -5.4807,  -4.9842,  -4.6181,  ...,  -4.3738,  -5.6283,  -1.0734],\n",
            "         [ -6.4401,  -6.3222,  -5.8091,  ...,  -6.0740,  -6.0276,  -6.5517],\n",
            "         [ -0.8420,  -0.8825,  -0.8660,  ...,  -1.8597,  -1.6853,  -1.4014]],\n",
            "\n",
            "        [[ -3.0876,  -3.3594,  -4.5087,  ...,  -1.6991,  -1.8004,  -3.7737],\n",
            "         [ -6.7497,  -6.0625,  -6.3237,  ...,  -5.6544,  -3.9599,  -5.7384],\n",
            "         [ -3.0269,  -3.1182,  -7.2441,  ...,  -4.1451,  -5.7215,  -7.4281],\n",
            "         ...,\n",
            "         [ -6.3592,  -5.5735,  -4.9964,  ...,  -4.5522,  -6.5481,  -0.9363],\n",
            "         [ -7.5871,  -6.7520,  -6.5479,  ...,  -6.9719,  -7.0813,  -7.5939],\n",
            "         [ -0.8403,  -0.9081,  -0.9325,  ...,  -1.8722,  -1.7535,  -1.4397]],\n",
            "\n",
            "        [[ -2.6841,  -2.8081,  -3.5168,  ...,  -1.8316,  -1.7421,  -3.0379],\n",
            "         [ -5.5056,  -4.7427,  -4.8376,  ...,  -4.8678,  -3.5394,  -4.4920],\n",
            "         [ -2.7246,  -2.7912,  -5.5950,  ...,  -3.6798,  -4.7714,  -5.6472],\n",
            "         ...,\n",
            "         [ -5.0971,  -4.6025,  -3.8877,  ...,  -4.0713,  -5.1966,  -1.3572],\n",
            "         [ -6.0075,  -5.3351,  -5.0662,  ...,  -5.4555,  -5.5930,  -5.7398],\n",
            "         [ -1.4735,  -1.6149,  -1.4871,  ...,  -2.2739,  -2.1520,  -1.8232]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.0989,  0.3469, -0.6584,  ...,  1.3201,  0.9892,  1.5577],\n",
            "        [ 0.1896,  0.7480, -0.8557,  ...,  1.5557,  1.2694,  1.9928],\n",
            "        [ 2.2987,  2.3168, -0.1910,  ..., -1.4196,  0.6227,  1.5423],\n",
            "        ...,\n",
            "        [ 0.0289,  0.2034, -0.8002,  ...,  1.4947,  1.1580,  1.8072],\n",
            "        [-0.2154, -1.2548, -1.8813,  ...,  2.0763,  2.1081,  2.9889],\n",
            "        [ 2.2335,  2.4737, -0.2451,  ..., -1.0118,  0.8107,  1.7845]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 9.8867e-02,  3.4687e-01, -6.5837e-01,  ...,  1.6169e+00,\n",
            "           1.1744e+00, -1.2772e-01],\n",
            "         [-3.0422e+00, -1.8955e+00, -2.1616e+00,  ..., -1.7315e+00,\n",
            "          -7.1645e-01, -1.7292e+00],\n",
            "         [ 9.0409e-02,  4.7291e-01, -2.9980e+00,  ..., -4.6721e-01,\n",
            "          -2.1584e+00, -3.0976e+00],\n",
            "         ...,\n",
            "         [-2.6241e+00, -1.6139e+00, -1.0897e+00,  ..., -8.7627e-01,\n",
            "          -2.7610e+00,  2.0526e+00],\n",
            "         [-3.6562e+00, -2.5310e+00, -2.4352e+00,  ..., -2.6197e+00,\n",
            "          -3.2208e+00, -3.1929e+00],\n",
            "         [ 1.7359e+00,  2.0455e+00,  1.9868e+00,  ...,  1.3201e+00,\n",
            "           9.8923e-01,  1.5577e+00]],\n",
            "\n",
            "        [[ 1.8957e-01,  7.4799e-01, -8.5566e-01,  ...,  2.1934e+00,\n",
            "           1.8655e+00,  2.0415e-01],\n",
            "         [-4.3985e+00, -2.4180e+00, -2.9114e+00,  ..., -2.5756e+00,\n",
            "          -9.7070e-01, -2.2738e+00],\n",
            "         [ 2.3946e-01,  5.6007e-01, -4.4223e+00,  ..., -7.4010e-01,\n",
            "          -3.1854e+00, -4.5861e+00],\n",
            "         ...,\n",
            "         [-4.1357e+00, -2.2107e+00, -1.4286e+00,  ..., -1.0860e+00,\n",
            "          -4.0471e+00,  2.6378e+00],\n",
            "         [-5.5175e+00, -3.3082e+00, -3.3866e+00,  ..., -4.1569e+00,\n",
            "          -4.5755e+00, -4.8827e+00],\n",
            "         [ 2.0504e+00,  2.4767e+00,  2.4987e+00,  ...,  1.5557e+00,\n",
            "           1.2694e+00,  1.9928e+00]],\n",
            "\n",
            "        [[ 2.2987e+00,  2.3168e+00, -1.9101e-01,  ...,  1.6619e+00,\n",
            "           2.4659e+00,  3.1039e+00],\n",
            "         [-4.5924e+00, -1.2485e+00, -2.2284e+00,  ..., -3.6222e+00,\n",
            "          -3.0028e+00, -9.9100e-01],\n",
            "         [ 6.8926e-01,  9.4722e-01, -4.6647e+00,  ..., -2.5008e+00,\n",
            "          -4.2497e+00, -4.3996e+00],\n",
            "         ...,\n",
            "         [-5.0045e+00, -1.8064e+00, -1.6725e+00,  ..., -1.9198e+00,\n",
            "          -3.1910e+00,  5.5702e-01],\n",
            "         [-6.1990e+00, -3.3768e+00, -3.7178e+00,  ..., -4.0013e+00,\n",
            "          -2.9166e+00, -4.3362e+00],\n",
            "         [ 1.4385e+00,  5.4990e-01, -5.7315e-02,  ..., -1.4196e+00,\n",
            "           6.2267e-01,  1.5423e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.8893e-02,  2.0345e-01, -8.0018e-01,  ...,  1.6668e+00,\n",
            "           1.1005e+00, -2.8997e-01],\n",
            "         [-3.1242e+00, -2.1429e+00, -2.3353e+00,  ..., -1.7614e+00,\n",
            "          -7.6575e-01, -1.8936e+00],\n",
            "         [ 6.6307e-03,  4.3411e-01, -3.0490e+00,  ..., -5.2020e-01,\n",
            "          -2.2101e+00, -3.2391e+00],\n",
            "         ...,\n",
            "         [-2.6880e+00, -1.6358e+00, -1.2444e+00,  ..., -9.2624e-01,\n",
            "          -2.8635e+00,  2.2212e+00],\n",
            "         [-3.7375e+00, -2.7669e+00, -2.5702e+00,  ..., -2.7726e+00,\n",
            "          -3.3132e+00, -3.3617e+00],\n",
            "         [ 1.9907e+00,  2.3708e+00,  2.2923e+00,  ...,  1.4947e+00,\n",
            "           1.1580e+00,  1.8072e+00]],\n",
            "\n",
            "        [[-2.1536e-01, -1.2548e+00, -1.8813e+00,  ...,  1.3443e+00,\n",
            "           7.3249e-01, -1.4756e+00],\n",
            "         [-3.0998e+00, -3.7681e+00, -3.3463e+00,  ..., -1.8378e+00,\n",
            "          -1.1533e+00, -2.3399e+00],\n",
            "         [-4.9773e-01, -2.5310e-01, -2.9012e+00,  ..., -3.8712e-01,\n",
            "          -2.4406e+00, -3.8316e+00],\n",
            "         ...,\n",
            "         [-2.2399e+00, -1.5801e+00, -2.2091e+00,  ..., -1.7391e+00,\n",
            "          -2.9661e+00,  3.2359e+00],\n",
            "         [-3.4069e+00, -3.8685e+00, -3.1438e+00,  ..., -3.3384e+00,\n",
            "          -2.7063e+00, -3.4311e+00],\n",
            "         [ 3.4841e+00,  4.4793e+00,  3.5697e+00,  ...,  2.0763e+00,\n",
            "           2.1081e+00,  2.9889e+00]],\n",
            "\n",
            "        [[ 2.2335e+00,  2.4737e+00, -2.4515e-01,  ...,  2.1053e+00,\n",
            "           2.9634e+00,  3.1064e+00],\n",
            "         [-5.3682e+00, -1.4460e+00, -2.5479e+00,  ..., -3.9794e+00,\n",
            "          -3.0426e+00, -1.2917e+00],\n",
            "         [ 8.2212e-01,  1.0707e+00, -5.4574e+00,  ..., -2.6762e+00,\n",
            "          -4.5932e+00, -5.2959e+00],\n",
            "         ...,\n",
            "         [-5.7251e+00, -2.1756e+00, -1.8183e+00,  ..., -1.8970e+00,\n",
            "          -3.8285e+00,  9.0906e-01],\n",
            "         [-7.2118e+00, -3.7780e+00, -4.1772e+00,  ..., -4.9178e+00,\n",
            "          -3.9386e+00, -5.3997e+00],\n",
            "         [ 1.4745e+00,  8.5178e-01,  2.9498e-01,  ..., -1.0118e+00,\n",
            "           8.1070e-01,  1.7845e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.8140,  -2.9956,  -3.8568,  ...,  -1.7771,  -1.7740,  -3.3367],\n",
            "         [ -5.9551,  -5.2380,  -5.3600,  ...,  -5.1256,  -3.6649,  -4.9382],\n",
            "         [ -2.8225,  -2.8695,  -6.1964,  ...,  -3.8613,  -5.1068,  -6.3066],\n",
            "         ...,\n",
            "         [ -5.5370,  -4.9563,  -4.2881,  ...,  -4.2703,  -5.7095,  -1.1564],\n",
            "         [ -6.5691,  -5.8734,  -5.6336,  ...,  -6.0138,  -6.1692,  -6.4019],\n",
            "         [ -1.1770,  -1.2969,  -1.2116,  ...,  -2.0739,  -1.9592,  -1.6513]],\n",
            "\n",
            "        [[ -2.9148,  -2.9232,  -4.6722,  ...,  -1.4556,  -1.5040,  -3.3731],\n",
            "         [ -7.5029,  -6.0891,  -6.7279,  ...,  -6.2245,  -4.3402,  -5.8510],\n",
            "         [ -2.8649,  -3.1111,  -8.2388,  ...,  -4.3891,  -6.5549,  -8.1634],\n",
            "         ...,\n",
            "         [ -7.2401,  -5.8818,  -5.2451,  ...,  -4.7350,  -7.4165,  -0.9395],\n",
            "         [ -8.6219,  -6.9794,  -7.2032,  ...,  -7.8058,  -7.9449,  -8.4599],\n",
            "         [ -1.0540,  -1.1945,  -1.3179,  ...,  -2.0933,  -2.1000,  -1.5844]],\n",
            "\n",
            "        [[ -1.3933,  -1.5669,  -4.6984,  ...,  -1.7705,  -1.5965,  -1.0357],\n",
            "         [ -8.2844,  -5.1322,  -6.7358,  ...,  -7.0545,  -7.0652,  -5.1306],\n",
            "         [ -3.0027,  -2.9365,  -9.1721,  ...,  -5.9331,  -8.3121,  -8.5392],\n",
            "         ...,\n",
            "         [ -8.6965,  -5.6901,  -6.1799,  ...,  -5.3521,  -7.2533,  -3.5826],\n",
            "         [ -9.8910,  -7.2605,  -8.2252,  ...,  -7.4336,  -6.9790,  -8.4758],\n",
            "         [ -2.2534,  -3.3338,  -4.5647,  ...,  -4.8520,  -3.4397,  -2.5973]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.9331,  -3.2269,  -4.0930,  ...,  -1.7723,  -1.8623,  -3.5966],\n",
            "         [ -6.0862,  -5.5733,  -5.6282,  ...,  -5.2006,  -3.7285,  -5.2002],\n",
            "         [ -2.9554,  -2.9962,  -6.3418,  ...,  -3.9594,  -5.1728,  -6.5457],\n",
            "         ...,\n",
            "         [ -5.6500,  -5.0661,  -4.5372,  ...,  -4.3654,  -5.8263,  -1.0854],\n",
            "         [ -6.6996,  -6.1972,  -5.8630,  ...,  -6.2118,  -6.2759,  -6.6683],\n",
            "         [ -0.9713,  -1.0595,  -1.0006,  ...,  -1.9445,  -1.8048,  -1.4994]],\n",
            "\n",
            "        [[ -3.9518,  -5.9181,  -5.8893,  ...,  -2.1609,  -2.5556,  -5.6122],\n",
            "         [ -6.8363,  -8.4313,  -7.3542,  ...,  -5.3430,  -4.4414,  -6.4765],\n",
            "         [ -4.2342,  -4.9164,  -6.9091,  ...,  -3.8923,  -5.7287,  -7.9682],\n",
            "         ...,\n",
            "         [ -5.9763,  -6.2434,  -6.2171,  ...,  -5.2443,  -6.2542,  -0.9007],\n",
            "         [ -7.1434,  -8.5317,  -7.1517,  ...,  -6.8436,  -5.9944,  -7.5677],\n",
            "         [ -0.2524,  -0.1840,  -0.4382,  ...,  -1.4289,  -1.1800,  -1.1477]],\n",
            "\n",
            "        [[ -1.5039,  -1.6207,  -5.0828,  ...,  -1.5416,  -1.3747,  -1.1248],\n",
            "         [ -9.1056,  -5.5404,  -7.3856,  ...,  -7.6263,  -7.3807,  -5.5230],\n",
            "         [ -2.9153,  -3.0237, -10.2951,  ...,  -6.3231,  -8.9313,  -9.5271],\n",
            "         ...,\n",
            "         [ -9.4626,  -6.2700,  -6.6560,  ...,  -5.5439,  -8.1666,  -3.3222],\n",
            "         [-10.9492,  -7.8724,  -9.0148,  ...,  -8.5647,  -8.2767,  -9.6309],\n",
            "         [ -2.2629,  -3.2426,  -4.5427,  ...,  -4.6587,  -3.5274,  -2.4467]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.1455,  0.7086, -0.8577,  ...,  1.6230,  1.3182,  2.0226],\n",
            "        [-0.0514, -0.1894, -1.2007,  ...,  1.8574,  1.5839,  2.3619],\n",
            "        [ 2.2757,  2.4164, -0.1651,  ..., -1.3047,  0.6935,  1.6315],\n",
            "        ...,\n",
            "        [ 2.2281,  2.3857, -0.1621,  ..., -1.2414,  0.6888,  1.6211],\n",
            "        [ 0.4128,  0.9002, -0.7059,  ...,  1.1869,  0.9924,  1.7040],\n",
            "        [-0.0059,  0.2163, -0.9202,  ...,  1.6771,  1.3523,  2.0432]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.4554e-01,  7.0856e-01, -8.5768e-01,  ...,  2.1952e+00,\n",
            "           1.8174e+00,  1.2591e-01],\n",
            "         [-4.3858e+00, -2.4467e+00, -2.9462e+00,  ..., -2.5068e+00,\n",
            "          -9.4893e-01, -2.3246e+00],\n",
            "         [ 2.2298e-01,  5.6241e-01, -4.4088e+00,  ..., -7.3412e-01,\n",
            "          -3.1662e+00, -4.5821e+00],\n",
            "         ...,\n",
            "         [-4.0655e+00, -2.2228e+00, -1.4450e+00,  ..., -1.1037e+00,\n",
            "          -4.0579e+00,  2.6709e+00],\n",
            "         [-5.4808e+00, -3.3302e+00, -3.3853e+00,  ..., -4.1307e+00,\n",
            "          -4.6044e+00, -4.8525e+00],\n",
            "         [ 2.0900e+00,  2.5397e+00,  2.5694e+00,  ...,  1.6230e+00,\n",
            "           1.3182e+00,  2.0226e+00]],\n",
            "\n",
            "        [[-5.1436e-02, -1.8941e-01, -1.2007e+00,  ...,  1.7715e+00,\n",
            "           9.9609e-01, -6.6746e-01],\n",
            "         [-3.3888e+00, -2.7927e+00, -2.8409e+00,  ..., -1.8661e+00,\n",
            "          -9.3494e-01, -2.2642e+00],\n",
            "         [-1.8791e-01,  2.4023e-01, -3.2450e+00,  ..., -6.2036e-01,\n",
            "          -2.3734e+00, -3.6699e+00],\n",
            "         ...,\n",
            "         [-2.8656e+00, -1.6989e+00, -1.6265e+00,  ..., -1.1848e+00,\n",
            "          -3.1176e+00,  2.6390e+00],\n",
            "         [-3.9576e+00, -3.3410e+00, -2.9244e+00,  ..., -3.1712e+00,\n",
            "          -3.4996e+00, -3.7592e+00],\n",
            "         [ 2.6545e+00,  3.2210e+00,  2.9915e+00,  ...,  1.8574e+00,\n",
            "           1.5839e+00,  2.3619e+00]],\n",
            "\n",
            "        [[ 2.2757e+00,  2.4164e+00, -1.6508e-01,  ...,  1.8436e+00,\n",
            "           2.6435e+00,  3.1622e+00],\n",
            "         [-4.8954e+00, -1.3072e+00, -2.3278e+00,  ..., -3.7474e+00,\n",
            "          -3.0534e+00, -1.1081e+00],\n",
            "         [ 7.8270e-01,  9.8865e-01, -4.9768e+00,  ..., -2.6253e+00,\n",
            "          -4.4010e+00, -4.7523e+00],\n",
            "         ...,\n",
            "         [-5.2837e+00, -1.9537e+00, -1.7378e+00,  ..., -1.9292e+00,\n",
            "          -3.4416e+00,  6.4233e-01],\n",
            "         [-6.5885e+00, -3.5314e+00, -3.9135e+00,  ..., -4.3600e+00,\n",
            "          -3.2765e+00, -4.7278e+00],\n",
            "         [ 1.4044e+00,  6.5092e-01,  1.9791e-02,  ..., -1.3047e+00,\n",
            "           6.9354e-01,  1.6315e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.2281e+00,  2.3857e+00, -1.6215e-01,  ...,  1.8572e+00,\n",
            "           2.6451e+00,  3.1007e+00],\n",
            "         [-4.8743e+00, -1.2932e+00, -2.3198e+00,  ..., -3.7084e+00,\n",
            "          -3.0016e+00, -1.1144e+00],\n",
            "         [ 7.7612e-01,  9.7612e-01, -4.9493e+00,  ..., -2.5885e+00,\n",
            "          -4.3450e+00, -4.7375e+00],\n",
            "         ...,\n",
            "         [-5.2400e+00, -1.9479e+00, -1.7180e+00,  ..., -1.8865e+00,\n",
            "          -3.4276e+00,  6.6660e-01],\n",
            "         [-6.5388e+00, -3.4942e+00, -3.8782e+00,  ..., -4.3528e+00,\n",
            "          -3.3006e+00, -4.7221e+00],\n",
            "         [ 1.3770e+00,  6.6303e-01,  4.1563e-02,  ..., -1.2414e+00,\n",
            "           6.8878e-01,  1.6211e+00]],\n",
            "\n",
            "        [[ 4.1276e-01,  9.0016e-01, -7.0585e-01,  ...,  2.1030e+00,\n",
            "           1.9471e+00,  5.1391e-01],\n",
            "         [-4.1618e+00, -2.0930e+00, -2.5297e+00,  ..., -2.5418e+00,\n",
            "          -1.0942e+00, -1.9295e+00],\n",
            "         [ 2.9466e-01,  4.9541e-01, -4.1580e+00,  ..., -8.2122e-01,\n",
            "          -3.0778e+00, -4.2111e+00],\n",
            "         ...,\n",
            "         [-3.9266e+00, -1.9990e+00, -1.3095e+00,  ..., -1.0919e+00,\n",
            "          -3.6744e+00,  2.2413e+00],\n",
            "         [-5.2029e+00, -3.0323e+00, -3.1336e+00,  ..., -3.8628e+00,\n",
            "          -4.1188e+00, -4.5202e+00],\n",
            "         [ 1.7019e+00,  1.9398e+00,  1.9555e+00,  ...,  1.1869e+00,\n",
            "           9.9242e-01,  1.7040e+00]],\n",
            "\n",
            "        [[-5.9143e-03,  2.1628e-01, -9.2016e-01,  ...,  1.8180e+00,\n",
            "           1.2219e+00, -3.2409e-01],\n",
            "         [-3.4933e+00, -2.3893e+00, -2.6287e+00,  ..., -1.9387e+00,\n",
            "          -8.4127e-01, -2.1442e+00],\n",
            "         [-1.6007e-02,  4.3676e-01, -3.4316e+00,  ..., -5.9780e-01,\n",
            "          -2.4775e+00, -3.6713e+00],\n",
            "         ...,\n",
            "         [-3.0453e+00, -1.8205e+00, -1.4187e+00,  ..., -1.0282e+00,\n",
            "          -3.2359e+00,  2.4557e+00],\n",
            "         [-4.2241e+00, -3.0667e+00, -2.8613e+00,  ..., -3.2071e+00,\n",
            "          -3.7236e+00, -3.8321e+00],\n",
            "         [ 2.2167e+00,  2.6722e+00,  2.6088e+00,  ...,  1.6771e+00,\n",
            "           1.3523e+00,  2.0432e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.9581,  -2.9732,  -4.6682,  ...,  -1.4639,  -1.5371,  -3.4654],\n",
            "         [ -7.4894,  -6.1285,  -6.7567,  ...,  -6.1659,  -4.3034,  -5.9159],\n",
            "         [ -2.8807,  -3.1194,  -8.2193,  ...,  -4.3933,  -6.5207,  -8.1734],\n",
            "         ...,\n",
            "         [ -7.1692,  -5.9046,  -5.2555,  ...,  -4.7629,  -7.4124,  -0.9204],\n",
            "         [ -8.5844,  -7.0120,  -7.1958,  ...,  -7.7899,  -7.9589,  -8.4438],\n",
            "         [ -1.0137,  -1.1421,  -1.2411,  ...,  -2.0362,  -2.0362,  -1.5687]],\n",
            "\n",
            "        [[ -3.2656,  -3.9914,  -4.8376,  ...,  -1.7706,  -2.0780,  -4.2879],\n",
            "         [ -6.6030,  -6.5947,  -6.4779,  ...,  -5.4081,  -4.0090,  -5.8847],\n",
            "         [ -3.4021,  -3.5617,  -6.8820,  ...,  -4.1624,  -5.4475,  -7.2904],\n",
            "         ...,\n",
            "         [ -6.0798,  -5.5009,  -5.2634,  ...,  -4.7268,  -6.1917,  -0.9815],\n",
            "         [ -7.1718,  -7.1430,  -6.5613,  ...,  -6.7133,  -6.5737,  -7.3797],\n",
            "         [ -0.5597,  -0.5810,  -0.6455,  ...,  -1.6847,  -1.4902,  -1.2586]],\n",
            "\n",
            "        [[ -1.4378,  -1.5493,  -4.8113,  ...,  -1.6773,  -1.5379,  -1.0361],\n",
            "         [ -8.6089,  -5.2729,  -6.9741,  ...,  -7.2684,  -7.2348,  -5.3063],\n",
            "         [ -2.9308,  -2.9771,  -9.6230,  ...,  -6.1462,  -8.5824,  -8.9505],\n",
            "         ...,\n",
            "         [ -8.9972,  -5.9194,  -6.3840,  ...,  -5.4501,  -7.6230,  -3.5559],\n",
            "         [-10.3020,  -7.4971,  -8.5597,  ...,  -7.8810,  -7.4579,  -8.9260],\n",
            "         [ -2.3091,  -3.3148,  -4.6264,  ...,  -4.8257,  -3.4879,  -2.5667]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.4611,  -1.5631,  -4.7745,  ...,  -1.6574,  -1.5077,  -1.0605],\n",
            "         [ -8.5636,  -5.2421,  -6.9322,  ...,  -7.2230,  -7.1544,  -5.2756],\n",
            "         [ -2.9131,  -2.9727,  -9.5616,  ...,  -6.1031,  -8.4978,  -8.8986],\n",
            "         ...,\n",
            "         [ -8.9292,  -5.8967,  -6.3304,  ...,  -5.4011,  -7.5803,  -3.4945],\n",
            "         [-10.2281,  -7.4430,  -8.4905,  ...,  -7.8674,  -7.4534,  -8.8833],\n",
            "         [ -2.3122,  -3.2858,  -4.5708,  ...,  -4.7560,  -3.4640,  -2.5400]],\n",
            "\n",
            "        [[ -2.6343,  -2.6075,  -4.3662,  ...,  -1.4271,  -1.3750,  -2.8860],\n",
            "         [ -7.2089,  -5.6006,  -6.1901,  ...,  -6.0718,  -4.4163,  -5.3294],\n",
            "         [ -2.7524,  -3.0122,  -7.8184,  ...,  -4.3513,  -6.3999,  -7.6109],\n",
            "         ...,\n",
            "         [ -6.9737,  -5.5066,  -4.9699,  ...,  -4.6219,  -6.9965,  -1.1586],\n",
            "         [ -8.2500,  -6.5399,  -6.7940,  ...,  -7.3928,  -7.4409,  -7.9201],\n",
            "         [ -1.3451,  -1.5678,  -1.7049,  ...,  -2.3431,  -2.3297,  -1.6959]],\n",
            "\n",
            "        [[ -3.0510,  -3.3604,  -4.4194,  ...,  -1.7088,  -1.8427,  -3.7809],\n",
            "         [ -6.5383,  -5.9660,  -6.1280,  ...,  -5.4655,  -3.9059,  -5.6010],\n",
            "         [ -3.0610,  -3.1399,  -6.9308,  ...,  -4.1245,  -5.5421,  -7.1281],\n",
            "         ...,\n",
            "         [ -6.0904,  -5.3971,  -4.9180,  ...,  -4.5550,  -6.3005,  -1.0012],\n",
            "         [ -7.2691,  -6.6433,  -6.3605,  ...,  -6.7338,  -6.7882,  -7.2890],\n",
            "         [ -0.8283,  -0.9044,  -0.8904,  ...,  -1.8496,  -1.7123,  -1.4136]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.2447,  0.8696, -0.9271,  ...,  1.6620,  1.3930,  2.1281],\n",
            "        [ 2.1900,  2.4629, -0.1530,  ..., -1.0819,  0.7785,  1.7272],\n",
            "        [ 2.1721,  2.3685, -0.1241,  ..., -1.1958,  0.6925,  1.6156],\n",
            "        ...,\n",
            "        [ 2.3936,  2.4744, -0.1190,  ..., -1.5749,  0.6818,  1.6099],\n",
            "        [ 0.3153,  0.8670, -0.8137,  ...,  1.4362,  1.1961,  1.8954],\n",
            "        [ 1.7901,  2.0788, -0.1449,  ..., -0.7253,  0.6380,  1.4942]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.2447,  0.8696, -0.9271,  ...,  2.4044,  2.0667,  0.2854],\n",
            "         [-4.8480, -2.6174, -3.1198,  ..., -2.8168, -1.0738, -2.4594],\n",
            "         [ 0.2805,  0.5612, -4.8862,  ..., -0.8935, -3.5391, -5.0651],\n",
            "         ...,\n",
            "         [-4.6031, -2.3870, -1.5724,  ..., -1.2221, -4.4622,  2.7904],\n",
            "         [-6.1111, -3.6057, -3.7449,  ..., -4.6594, -5.0079, -5.4306],\n",
            "         [ 2.1557,  2.5992,  2.6452,  ...,  1.6620,  1.3930,  2.1281]],\n",
            "\n",
            "        [[ 2.1900,  2.4629, -0.1530,  ...,  2.0522,  2.8308,  3.1329],\n",
            "         [-5.2324, -1.4112, -2.4250,  ..., -3.8659, -3.0412, -1.2528],\n",
            "         [ 0.8890,  1.0466, -5.3172,  ..., -2.7161, -4.5345, -5.1384],\n",
            "         ...,\n",
            "         [-5.5556, -2.1379, -1.7675,  ..., -1.9009, -3.7219,  0.7892],\n",
            "         [-7.0192, -3.7035, -4.0991,  ..., -4.7618, -3.7550, -5.2052],\n",
            "         [ 1.3885,  0.7894,  0.1801,  ..., -1.0819,  0.7785,  1.7272]],\n",
            "\n",
            "        [[ 2.1721,  2.3685, -0.1241,  ...,  1.8790,  2.6263,  3.0730],\n",
            "         [-4.8761, -1.2974, -2.2873,  ..., -3.6716, -2.9744, -1.1296],\n",
            "         [ 0.8205,  0.9739, -4.9478,  ..., -2.6041, -4.3230, -4.7412],\n",
            "         ...,\n",
            "         [-5.2063, -1.9668, -1.6862,  ..., -1.8572, -3.4332,  0.6597],\n",
            "         [-6.5254, -3.4845, -3.8662,  ..., -4.3638, -3.3323, -4.7353],\n",
            "         [ 1.3376,  0.6750,  0.0434,  ..., -1.1958,  0.6925,  1.6156]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.3936,  2.4744, -0.1190,  ...,  1.6938,  2.4948,  3.3563],\n",
            "         [-4.7926, -1.3335, -2.2455,  ..., -3.7579, -3.2022, -1.0221],\n",
            "         [ 0.8308,  1.0066, -4.8919,  ..., -2.7366, -4.5080, -4.5987],\n",
            "         ...,\n",
            "         [-5.2368, -1.9162, -1.7299,  ..., -2.0583, -3.3606,  0.4790],\n",
            "         [-6.5099, -3.5675, -3.9119,  ..., -4.1859, -2.9853, -4.5303],\n",
            "         [ 1.4671,  0.5653, -0.1302,  ..., -1.5749,  0.6818,  1.6099]],\n",
            "\n",
            "        [[ 0.3153,  0.8670, -0.8137,  ...,  2.2429,  1.9831,  0.3713],\n",
            "         [-4.4666, -2.3465, -2.8055,  ..., -2.6475, -1.0669, -2.1887],\n",
            "         [ 0.2871,  0.5101, -4.4866,  ..., -0.8476, -3.2880, -4.5959],\n",
            "         ...,\n",
            "         [-4.2189, -2.1850, -1.4278,  ..., -1.1599, -4.0470,  2.4953],\n",
            "         [-5.6121, -3.2947, -3.4164,  ..., -4.2253, -4.5356, -4.9357],\n",
            "         [ 1.9118,  2.2631,  2.2936,  ...,  1.4362,  1.1961,  1.8954]],\n",
            "\n",
            "        [[ 1.7901,  2.0788, -0.1449,  ...,  1.9011,  2.5328,  2.5735],\n",
            "         [-4.6181, -1.2803, -2.1467,  ..., -3.3512, -2.5444, -1.1462],\n",
            "         [ 0.7599,  0.9149, -4.6406,  ..., -2.2544, -3.8886, -4.4869],\n",
            "         ...,\n",
            "         [-4.7561, -1.9244, -1.5098,  ..., -1.5888, -3.2602,  0.8461],\n",
            "         [-6.0739, -3.2184, -3.5347,  ..., -4.1653, -3.4651, -4.6022],\n",
            "         [ 1.1952,  0.7326,  0.2631,  ..., -0.7253,  0.6380,  1.4942]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.9346,  -2.9146,  -4.9590,  ...,  -1.3510,  -1.4656,  -3.4126],\n",
            "         [ -8.0273,  -6.4016,  -7.1518,  ...,  -6.5722,  -4.6060,  -6.1574],\n",
            "         [ -2.8989,  -3.2231,  -8.9181,  ...,  -4.6489,  -7.0714,  -8.7631],\n",
            "         ...,\n",
            "         [ -7.7824,  -6.1712,  -5.6043,  ...,  -4.9775,  -7.9945,  -0.9076],\n",
            "         [ -9.2904,  -7.3899,  -7.7769,  ...,  -8.4148,  -8.5402,  -9.1286],\n",
            "         [ -1.0236,  -1.1850,  -1.3867,  ...,  -2.0934,  -2.1393,  -1.5699]],\n",
            "\n",
            "        [[ -1.5254,  -1.5807,  -4.9074,  ...,  -1.5646,  -1.4541,  -1.0878],\n",
            "         [ -8.9478,  -5.4548,  -7.1794,  ...,  -7.4828,  -7.3261,  -5.4735],\n",
            "         [ -2.8264,  -2.9970, -10.0716,  ...,  -6.3330,  -8.8194,  -9.3591],\n",
            "         ...,\n",
            "         [ -9.2710,  -6.1815,  -6.5219,  ...,  -5.5177,  -8.0068,  -3.4315],\n",
            "         [-10.7346,  -7.7471,  -8.8535,  ...,  -8.3786,  -8.0399,  -9.4259],\n",
            "         [ -2.3269,  -3.2542,  -4.5743,  ...,  -4.6987,  -3.5064,  -2.4935]],\n",
            "\n",
            "        [[ -1.4978,  -1.5681,  -4.7089,  ...,  -1.6387,  -1.5129,  -1.0719],\n",
            "         [ -8.5459,  -5.2340,  -6.8722,  ...,  -7.1893,  -7.1136,  -5.2745],\n",
            "         [ -2.8493,  -2.9627,  -9.5327,  ...,  -6.1218,  -8.4622,  -8.8861],\n",
            "         ...,\n",
            "         [ -8.8762,  -5.9035,  -6.2710,  ...,  -5.3749,  -7.5724,  -3.4852],\n",
            "         [-10.1952,  -7.4211,  -8.4510,  ...,  -7.8815,  -7.4715,  -8.8802],\n",
            "         [ -2.3322,  -3.2617,  -4.5415,  ...,  -4.7135,  -3.4467,  -2.5293]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.3758,  -1.4920,  -4.7787,  ...,  -1.8005,  -1.7122,  -0.9417],\n",
            "         [ -8.5620,  -5.2999,  -6.9052,  ...,  -7.2522,  -7.4092,  -5.3202],\n",
            "         [ -2.9386,  -2.9598,  -9.5516,  ...,  -6.2309,  -8.7149,  -8.8967],\n",
            "         ...,\n",
            "         [ -9.0061,  -5.8826,  -6.3896,  ...,  -5.5526,  -7.5676,  -3.8190],\n",
            "         [-10.2792,  -7.5339,  -8.5716,  ...,  -7.6802,  -7.1922,  -8.8283],\n",
            "         [ -2.3022,  -3.4011,  -4.7899,  ...,  -5.0692,  -3.5252,  -2.6882]],\n",
            "\n",
            "        [[ -2.7797,  -2.7587,  -4.6309,  ...,  -1.3912,  -1.4248,  -3.1520],\n",
            "         [ -7.5615,  -5.9721,  -6.6228,  ...,  -6.2816,  -4.4748,  -5.7121],\n",
            "         [ -2.8078,  -3.1155,  -8.3038,  ...,  -4.4816,  -6.6959,  -8.1192],\n",
            "         ...,\n",
            "         [ -7.3138,  -5.8106,  -5.2451,  ...,  -4.7940,  -7.4549,  -1.0281],\n",
            "         [ -8.7070,  -6.9203,  -7.2336,  ...,  -7.8594,  -7.9435,  -8.4591],\n",
            "         [ -1.1831,  -1.3625,  -1.5236,  ...,  -2.1979,  -2.2118,  -1.6280]],\n",
            "\n",
            "        [[ -1.6947,  -1.7014,  -4.4050,  ...,  -1.5456,  -1.3445,  -1.2848],\n",
            "         [ -8.1029,  -5.0605,  -6.4067,  ...,  -6.7979,  -6.4218,  -5.0045],\n",
            "         [ -2.7249,  -2.8653,  -8.9006,  ...,  -5.7011,  -7.7660,  -8.3451],\n",
            "         ...,\n",
            "         [ -8.2409,  -5.7046,  -5.7699,  ...,  -5.0355,  -7.1375,  -3.0122],\n",
            "         [ -9.5587,  -6.9986,  -7.7948,  ...,  -7.6120,  -7.3425,  -8.4604],\n",
            "         [ -2.2896,  -3.0476,  -3.9969,  ...,  -4.1720,  -3.2394,  -2.3640]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.1215,  2.3801, -0.1018,  ..., -1.1348,  0.7148,  1.6378],\n",
            "        [ 0.9015,  1.3459, -0.4364,  ...,  0.4384,  0.6109,  1.4973],\n",
            "        [ 0.1276,  0.7115, -0.8709,  ...,  1.6939,  1.3756,  2.0450],\n",
            "        ...,\n",
            "        [ 1.0365,  1.4740, -0.3838,  ...,  0.2711,  0.6015,  1.5182],\n",
            "        [ 2.2123,  2.4290, -0.0955,  ..., -1.2839,  0.7070,  1.6410],\n",
            "        [ 0.0381,  0.1342, -0.8348,  ...,  1.5284,  1.1783,  1.8025]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.1215e+00,  2.3801e+00, -1.0180e-01,  ...,  1.9283e+00,\n",
            "           2.6524e+00,  3.0665e+00],\n",
            "         [-4.9583e+00, -1.3322e+00, -2.2886e+00,  ..., -3.6874e+00,\n",
            "          -2.9704e+00, -1.1755e+00],\n",
            "         [ 8.8351e-01,  9.9140e-01, -5.0294e+00,  ..., -2.6494e+00,\n",
            "          -4.3561e+00, -4.8335e+00],\n",
            "         ...,\n",
            "         [-5.2568e+00, -2.0264e+00, -1.6798e+00,  ..., -1.8500e+00,\n",
            "          -3.5031e+00,  6.8624e-01],\n",
            "         [-6.6281e+00, -3.5287e+00, -3.9098e+00,  ..., -4.4616e+00,\n",
            "          -3.4555e+00, -4.8545e+00],\n",
            "         [ 1.3144e+00,  7.0826e-01,  7.8941e-02,  ..., -1.1348e+00,\n",
            "           7.1483e-01,  1.6378e+00]],\n",
            "\n",
            "        [[ 9.0147e-01,  1.3459e+00, -4.3638e-01,  ...,  2.0446e+00,\n",
            "           2.2217e+00,  1.3698e+00],\n",
            "         [-4.2206e+00, -1.6435e+00, -2.1340e+00,  ..., -2.7784e+00,\n",
            "          -1.5666e+00, -1.4998e+00],\n",
            "         [ 4.7543e-01,  6.2790e-01, -4.1890e+00,  ..., -1.3626e+00,\n",
            "          -3.2134e+00, -4.1054e+00],\n",
            "         ...,\n",
            "         [-4.0365e+00, -1.7589e+00, -1.2931e+00,  ..., -1.1416e+00,\n",
            "          -3.3091e+00,  1.6657e+00],\n",
            "         [-5.2316e+00, -2.9172e+00, -3.0726e+00,  ..., -3.8286e+00,\n",
            "          -3.7379e+00, -4.3683e+00],\n",
            "         [ 1.2610e+00,  1.1230e+00,  1.0801e+00,  ...,  4.3839e-01,\n",
            "           6.1086e-01,  1.4973e+00]],\n",
            "\n",
            "        [[ 1.2762e-01,  7.1149e-01, -8.7089e-01,  ...,  2.2129e+00,\n",
            "           1.8065e+00,  8.1824e-02],\n",
            "         [-4.4411e+00, -2.4902e+00, -2.9972e+00,  ..., -2.4826e+00,\n",
            "          -9.6002e-01, -2.3954e+00],\n",
            "         [ 2.0674e-01,  5.4989e-01, -4.4646e+00,  ..., -7.8088e-01,\n",
            "          -3.2173e+00, -4.6373e+00],\n",
            "         ...,\n",
            "         [-4.0647e+00, -2.2463e+00, -1.4816e+00,  ..., -1.1411e+00,\n",
            "          -4.1253e+00,  2.7049e+00],\n",
            "         [-5.5349e+00, -3.3864e+00, -3.4349e+00,  ..., -4.1810e+00,\n",
            "          -4.6794e+00, -4.8965e+00],\n",
            "         [ 2.1195e+00,  2.5734e+00,  2.6234e+00,  ...,  1.6939e+00,\n",
            "           1.3756e+00,  2.0450e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.0365e+00,  1.4740e+00, -3.8384e-01,  ...,  2.0588e+00,\n",
            "           2.3185e+00,  1.5852e+00],\n",
            "         [-4.3462e+00, -1.5970e+00, -2.1196e+00,  ..., -2.9148e+00,\n",
            "          -1.7256e+00, -1.4593e+00],\n",
            "         [ 5.5702e-01,  7.0103e-01, -4.3184e+00,  ..., -1.5356e+00,\n",
            "          -3.3434e+00, -4.2298e+00],\n",
            "         ...,\n",
            "         [-4.1991e+00, -1.7949e+00, -1.3370e+00,  ..., -1.1944e+00,\n",
            "          -3.3491e+00,  1.5425e+00],\n",
            "         [-5.4462e+00, -2.9937e+00, -3.1780e+00,  ..., -3.9562e+00,\n",
            "          -3.7899e+00, -4.5018e+00],\n",
            "         [ 1.2387e+00,  1.0549e+00,  9.6551e-01,  ...,  2.7113e-01,\n",
            "           6.0149e-01,  1.5182e+00]],\n",
            "\n",
            "        [[ 2.2123e+00,  2.4290e+00, -9.5518e-02,  ...,  1.8724e+00,\n",
            "           2.6152e+00,  3.1818e+00],\n",
            "         [-4.9338e+00, -1.3290e+00, -2.2819e+00,  ..., -3.7284e+00,\n",
            "          -3.0650e+00, -1.1424e+00],\n",
            "         [ 8.8493e-01,  9.9794e-01, -5.0150e+00,  ..., -2.7071e+00,\n",
            "          -4.4265e+00, -4.7931e+00],\n",
            "         ...,\n",
            "         [-5.2833e+00, -2.0028e+00, -1.7044e+00,  ..., -1.9214e+00,\n",
            "          -3.4777e+00,  6.0767e-01],\n",
            "         [-6.6311e+00, -3.5559e+00, -3.9396e+00,  ..., -4.4052e+00,\n",
            "          -3.3231e+00, -4.7751e+00],\n",
            "         [ 1.3524e+00,  6.6412e-01,  2.4519e-03,  ..., -1.2839e+00,\n",
            "           7.0701e-01,  1.6410e+00]],\n",
            "\n",
            "        [[ 3.8146e-02,  1.3417e-01, -8.3475e-01,  ...,  1.6247e+00,\n",
            "           9.8464e-01, -3.8243e-01],\n",
            "         [-2.9737e+00, -2.1422e+00, -2.2709e+00,  ..., -1.6285e+00,\n",
            "          -7.8652e-01, -1.8683e+00],\n",
            "         [-6.9699e-02,  3.3531e-01, -2.8531e+00,  ..., -5.6472e-01,\n",
            "          -2.1224e+00, -3.0479e+00],\n",
            "         ...,\n",
            "         [-2.4783e+00, -1.5096e+00, -1.2761e+00,  ..., -9.7628e-01,\n",
            "          -2.7139e+00,  2.1187e+00],\n",
            "         [-3.4839e+00, -2.7599e+00, -2.5045e+00,  ..., -2.6147e+00,\n",
            "          -3.1181e+00, -3.1702e+00],\n",
            "         [ 2.0114e+00,  2.3549e+00,  2.2886e+00,  ...,  1.5284e+00,\n",
            "           1.1783e+00,  1.8025e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.5419,  -1.5717,  -4.7010,  ...,  -1.6141,  -1.5075,  -1.0827],\n",
            "         [ -8.6217,  -5.2841,  -6.8878,  ...,  -7.2298,  -7.1303,  -5.3247],\n",
            "         [ -2.7799,  -2.9604,  -9.6286,  ...,  -6.1918,  -8.5160,  -8.9827],\n",
            "         ...,\n",
            "         [ -8.9202,  -5.9782,  -6.2790,  ...,  -5.3924,  -7.6630,  -3.4630],\n",
            "         [-10.2915,  -7.4805,  -8.5090,  ...,  -8.0040,  -7.6154,  -9.0038],\n",
            "         [ -2.3490,  -3.2436,  -4.5203,  ...,  -4.6772,  -3.4450,  -2.5114]],\n",
            "\n",
            "        [[ -2.2500,  -2.1459,  -4.1664,  ...,  -1.3874,  -1.2282,  -2.0533],\n",
            "         [ -7.3720,  -5.1353,  -5.8640,  ...,  -6.2103,  -5.0164,  -4.9228],\n",
            "         [ -2.6760,  -2.8639,  -7.9190,  ...,  -4.7945,  -6.6632,  -7.5284],\n",
            "         ...,\n",
            "         [ -7.1880,  -5.2507,  -5.0231,  ...,  -4.5735,  -6.7589,  -1.7573],\n",
            "         [ -8.3831,  -6.4091,  -6.8026,  ...,  -7.2606,  -7.1877,  -7.7914],\n",
            "         [ -1.8904,  -2.3688,  -2.6499,  ...,  -2.9935,  -2.8390,  -1.9258]],\n",
            "\n",
            "        [[ -2.9818,  -2.9835,  -4.6999,  ...,  -1.4648,  -1.5573,  -3.5297],\n",
            "         [ -7.5505,  -6.1852,  -6.8262,  ...,  -6.1603,  -4.3238,  -6.0069],\n",
            "         [ -2.9027,  -3.1452,  -8.2936,  ...,  -4.4585,  -6.5811,  -8.2488],\n",
            "         ...,\n",
            "         [ -7.1741,  -5.9413,  -5.3106,  ...,  -4.8188,  -7.4891,  -0.9066],\n",
            "         [ -8.6444,  -7.0815,  -7.2639,  ...,  -7.8587,  -8.0432,  -8.5080],\n",
            "         [ -0.9899,  -1.1216,  -1.2056,  ...,  -1.9838,  -1.9883,  -1.5666]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.1717,  -2.0743,  -4.2062,  ...,  -1.3875,  -1.2190,  -1.8979],\n",
            "         [ -7.5544,  -5.1453,  -5.9420,  ...,  -6.3610,  -5.2631,  -4.9424],\n",
            "         [ -2.6511,  -2.8472,  -8.1407,  ...,  -4.9818,  -6.8810,  -7.7129],\n",
            "         ...,\n",
            "         [ -7.4072,  -5.3432,  -5.1594,  ...,  -4.6406,  -6.8866,  -1.9406],\n",
            "         [ -8.6543,  -6.5420,  -7.0003,  ...,  -7.4025,  -7.3274,  -7.9849],\n",
            "         [ -1.9695,  -2.4933,  -2.8568,  ...,  -3.1751,  -2.9360,  -1.9649]],\n",
            "\n",
            "        [[ -1.4898,  -1.5382,  -4.7351,  ...,  -1.6665,  -1.5776,  -1.0289],\n",
            "         [ -8.6359,  -5.2963,  -6.9215,  ...,  -7.2673,  -7.2577,  -5.3530],\n",
            "         [ -2.8172,  -2.9693,  -9.6546,  ...,  -6.2460,  -8.6192,  -9.0037],\n",
            "         ...,\n",
            "         [ -8.9854,  -5.9700,  -6.3440,  ...,  -5.4603,  -7.6704,  -3.6030],\n",
            "         [-10.3331,  -7.5232,  -8.5793,  ...,  -7.9441,  -7.5158,  -8.9858],\n",
            "         [ -2.3497,  -3.3031,  -4.6372,  ...,  -4.8228,  -3.4857,  -2.5696]],\n",
            "\n",
            "        [[ -2.9112,  -3.2592,  -4.0678,  ...,  -1.7935,  -1.9276,  -3.6500],\n",
            "         [ -5.9231,  -5.5355,  -5.5039,  ...,  -5.0467,  -3.6987,  -5.1358],\n",
            "         [ -3.0190,  -3.0581,  -6.0861,  ...,  -3.9829,  -5.0346,  -6.3155],\n",
            "         ...,\n",
            "         [ -5.4276,  -4.9030,  -4.5091,  ...,  -4.3944,  -5.6261,  -1.1489],\n",
            "         [ -6.4332,  -6.1533,  -5.7375,  ...,  -6.0328,  -6.0304,  -6.4378],\n",
            "         [ -0.9379,  -1.0385,  -0.9444,  ...,  -1.8898,  -1.7339,  -1.4651]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.1363,  0.6364, -0.7312,  ...,  1.4768,  1.1618,  1.7588],\n",
            "        [ 1.4371,  1.7970, -0.1332,  ..., -0.3882,  0.5356,  1.3710],\n",
            "        [ 0.4513,  1.0232, -0.7675,  ...,  1.3097,  1.1264,  1.8501],\n",
            "        ...,\n",
            "        [ 0.1697,  0.7916, -0.8945,  ...,  1.7116,  1.4067,  2.0795],\n",
            "        [ 0.2940,  0.6956, -0.5272,  ...,  1.0367,  0.7934,  1.3445],\n",
            "        [ 2.3120,  2.6263, -0.0794,  ..., -1.2925,  0.8192,  1.8124]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.1363,  0.6364, -0.7312,  ...,  1.9691,  1.5789,  0.0531],\n",
            "         [-3.8491, -2.1596, -2.6149,  ..., -2.1493, -0.8818, -2.0864],\n",
            "         [ 0.1816,  0.4784, -3.8406,  ..., -0.6786, -2.7975, -3.9419],\n",
            "         ...,\n",
            "         [-3.4072, -1.9577, -1.2776,  ..., -1.0504, -3.5311,  2.3513],\n",
            "         [-4.7344, -2.9654, -2.9679,  ..., -3.5032, -4.0374, -4.1396],\n",
            "         [ 1.8387,  2.2178,  2.2400,  ...,  1.4768,  1.1618,  1.7588]],\n",
            "\n",
            "        [[ 1.4371,  1.7970, -0.1332,  ...,  1.8490,  2.3392,  2.1294],\n",
            "         [-4.2286, -1.2709, -1.9302,  ..., -3.0118, -2.1659, -1.1541],\n",
            "         [ 0.7260,  0.8340, -4.2322,  ..., -1.9730, -3.4564, -4.1083],\n",
            "         ...,\n",
            "         [-4.2005, -1.8053, -1.3180,  ..., -1.3412, -3.0365,  0.9403],\n",
            "         [-5.4589, -2.9301, -3.1845,  ..., -3.8222, -3.3879, -4.2801],\n",
            "         [ 1.0498,  0.7388,  0.3991,  ..., -0.3882,  0.5356,  1.3710]],\n",
            "\n",
            "        [[ 0.4513,  1.0232, -0.7675,  ...,  2.3082,  2.1291,  0.5767],\n",
            "         [-4.6065, -2.2897, -2.7323,  ..., -2.7569, -1.2096, -2.1374],\n",
            "         [ 0.3565,  0.5179, -4.6175,  ..., -1.0146, -3.4122, -4.6837],\n",
            "         ...,\n",
            "         [-4.3241, -2.1633, -1.4437,  ..., -1.2229, -4.0701,  2.4191],\n",
            "         [-5.7688, -3.3376, -3.4767,  ..., -4.3353, -4.5557, -5.0380],\n",
            "         [ 1.8019,  2.0678,  2.1094,  ...,  1.3097,  1.1264,  1.8501]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.1697,  0.7916, -0.8945,  ...,  2.3034,  1.8979,  0.1350],\n",
            "         [-4.6221, -2.5541, -3.0614,  ..., -2.5959, -1.0166, -2.4527],\n",
            "         [ 0.2367,  0.5474, -4.6474,  ..., -0.8638, -3.3633, -4.8191],\n",
            "         ...,\n",
            "         [-4.2411, -2.2968, -1.5263,  ..., -1.2010, -4.2769,  2.7510],\n",
            "         [-5.7710, -3.4975, -3.5794,  ..., -4.3803, -4.8364, -5.1167],\n",
            "         [ 2.1292,  2.5858,  2.6438,  ...,  1.7116,  1.4067,  2.0795]],\n",
            "\n",
            "        [[ 0.2940,  0.6956, -0.5272,  ...,  1.7307,  1.4985,  0.2850],\n",
            "         [-3.2796, -1.7104, -2.0809,  ..., -1.9609, -0.9055, -1.6036],\n",
            "         [ 0.2114,  0.3816, -3.2296,  ..., -0.6234, -2.4601, -3.2161],\n",
            "         ...,\n",
            "         [-2.8936, -1.6360, -1.0352,  ..., -0.9412, -2.8935,  1.8269],\n",
            "         [-4.0123, -2.4548, -2.4712,  ..., -2.8817, -3.2614, -3.4156],\n",
            "         [ 1.3895,  1.5924,  1.5857,  ...,  1.0367,  0.7934,  1.3445]],\n",
            "\n",
            "        [[ 2.3120,  2.6263, -0.0794,  ...,  2.0893,  2.8623,  3.3867],\n",
            "         [-5.4135, -1.4581, -2.4567,  ..., -4.0217, -3.2781, -1.2961],\n",
            "         [ 1.0278,  1.0896, -5.5256,  ..., -2.9795, -4.7893, -5.3193],\n",
            "         ...,\n",
            "         [-5.7622, -2.2093, -1.8120,  ..., -2.0269, -3.8642,  0.6843],\n",
            "         [-7.3115, -3.8782, -4.3045,  ..., -4.9210, -3.7648, -5.3382],\n",
            "         [ 1.4113,  0.7786,  0.0754,  ..., -1.2925,  0.8192,  1.8124]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.8525,  -2.8588,  -4.2411,  ...,  -1.5554,  -1.5880,  -3.3363],\n",
            "         [ -6.8379,  -5.6548,  -6.1248,  ...,  -5.6738,  -4.0486,  -5.4757],\n",
            "         [ -2.8071,  -3.0167,  -7.3505,  ...,  -4.2031,  -5.9644,  -7.3313],\n",
            "         ...,\n",
            "         [ -6.3959,  -5.4529,  -4.7875,  ...,  -4.5750,  -6.6979,  -1.0381],\n",
            "         [ -7.7232,  -6.4606,  -6.4778,  ...,  -7.0278,  -7.2043,  -7.5290],\n",
            "         [ -1.1501,  -1.2774,  -1.2699,  ...,  -2.0477,  -2.0051,  -1.6306]],\n",
            "\n",
            "        [[ -1.8909,  -1.8174,  -4.0572,  ...,  -1.5198,  -1.2901,  -1.4925],\n",
            "         [ -7.5566,  -4.8853,  -5.8542,  ...,  -6.3805,  -5.7952,  -4.7760],\n",
            "         [ -2.6021,  -2.7804,  -8.1562,  ...,  -5.3417,  -7.0857,  -7.7302],\n",
            "         ...,\n",
            "         [ -7.5286,  -5.4198,  -5.2420,  ...,  -4.7100,  -6.6658,  -2.6816],\n",
            "         [ -8.7870,  -6.5445,  -7.1085,  ...,  -7.1910,  -7.0172,  -7.9020],\n",
            "         [ -2.2782,  -2.8757,  -3.5250,  ...,  -3.7570,  -3.0937,  -2.2509]],\n",
            "\n",
            "        [[ -2.6637,  -2.5909,  -4.6308,  ...,  -1.3273,  -1.3492,  -2.9460],\n",
            "         [ -7.7215,  -5.9038,  -6.5956,  ...,  -6.3924,  -4.6880,  -5.6601],\n",
            "         [ -2.7585,  -3.0962,  -8.4808,  ...,  -4.6501,  -6.8906,  -8.2065],\n",
            "         ...,\n",
            "         [ -7.4391,  -5.7774,  -5.3070,  ...,  -4.8584,  -7.5484,  -1.1036],\n",
            "         [ -8.8838,  -6.9518,  -7.3400,  ...,  -7.9708,  -8.0341,  -8.5608],\n",
            "         [ -1.3131,  -1.5464,  -1.7539,  ...,  -2.3258,  -2.3519,  -1.6727]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.9634,  -2.9368,  -4.8011,  ...,  -1.4089,  -1.5329,  -3.5160],\n",
            "         [ -7.7553,  -6.2826,  -6.9680,  ...,  -6.3082,  -4.4474,  -6.1038],\n",
            "         [ -2.8965,  -3.1810,  -8.5540,  ...,  -4.5761,  -6.7941,  -8.4702],\n",
            "         ...,\n",
            "         [ -7.3742,  -6.0253,  -5.4329,  ...,  -4.9133,  -7.7077,  -0.9000],\n",
            "         [ -8.9041,  -7.2260,  -7.4860,  ...,  -8.0926,  -8.2672,  -8.7678],\n",
            "         [ -1.0040,  -1.1426,  -1.2627,  ...,  -2.0007,  -2.0241,  -1.5715]],\n",
            "\n",
            "        [[ -2.6088,  -2.5872,  -3.7544,  ...,  -1.6203,  -1.5252,  -2.8703],\n",
            "         [ -6.1823,  -4.9932,  -5.3081,  ...,  -5.3119,  -3.9293,  -4.7590],\n",
            "         [ -2.6913,  -2.9012,  -6.4568,  ...,  -3.9744,  -5.4839,  -6.3715],\n",
            "         ...,\n",
            "         [ -5.7963,  -4.9188,  -4.2623,  ...,  -4.2922,  -5.9172,  -1.3284],\n",
            "         [ -6.9151,  -5.7376,  -5.6984,  ...,  -6.2327,  -6.2851,  -6.5710],\n",
            "         [ -1.5132,  -1.6904,  -1.6415,  ...,  -2.3143,  -2.2303,  -1.8108]],\n",
            "\n",
            "        [[ -1.4913,  -1.5107,  -5.0032,  ...,  -1.5971,  -1.5787,  -1.0023],\n",
            "         [ -9.2169,  -5.5951,  -7.3805,  ...,  -7.7081,  -7.7191,  -5.6851],\n",
            "         [ -2.7756,  -3.0474, -10.4494,  ...,  -6.6659,  -9.2303,  -9.7084],\n",
            "         ...,\n",
            "         [ -9.5656,  -6.3463,  -6.7358,  ...,  -5.7133,  -8.3052,  -3.7047],\n",
            "         [-11.1148,  -8.0152,  -9.2283,  ...,  -8.6074,  -8.2058,  -9.7273],\n",
            "         [ -2.3921,  -3.3584,  -4.8483,  ...,  -4.9789,  -3.6218,  -2.5767]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[-0.0024,  0.2401, -1.0567,  ...,  1.8810,  1.5508,  2.2237],\n",
            "        [ 0.2714,  0.5788, -0.3859,  ...,  0.8346,  0.5821,  1.0799],\n",
            "        [ 0.2053,  0.8952, -0.9856,  ...,  1.8500,  1.5494,  2.2520],\n",
            "        ...,\n",
            "        [ 0.6873,  1.1535, -0.4834,  ...,  0.7236,  0.6801,  1.4803],\n",
            "        [ 0.4851,  0.9537, -0.5542,  ...,  0.9759,  0.8160,  1.4952],\n",
            "        [ 1.8029,  2.0968, -0.0319,  ..., -0.8605,  0.6153,  1.5018]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[-2.4393e-03,  2.4015e-01, -1.0567e+00,  ...,  1.9143e+00,\n",
            "           1.2574e+00, -4.1203e-01],\n",
            "         [-3.7535e+00, -2.6017e+00, -2.8622e+00,  ..., -2.0193e+00,\n",
            "          -9.5579e-01, -2.3737e+00],\n",
            "         [-9.6619e-02,  3.5780e-01, -3.6765e+00,  ..., -7.4474e-01,\n",
            "          -2.6952e+00, -3.9462e+00],\n",
            "         ...,\n",
            "         [-3.2037e+00, -1.8883e+00, -1.6083e+00,  ..., -1.1641e+00,\n",
            "          -3.4930e+00,  2.6104e+00],\n",
            "         [-4.5195e+00, -3.3392e+00, -3.1010e+00,  ..., -3.5112e+00,\n",
            "          -3.9872e+00, -4.1406e+00],\n",
            "         [ 2.4160e+00,  2.9064e+00,  2.8847e+00,  ...,  1.8810e+00,\n",
            "           1.5508e+00,  2.2237e+00]],\n",
            "\n",
            "        [[ 2.7141e-01,  5.7883e-01, -3.8594e-01,  ...,  1.4626e+00,\n",
            "           1.2272e+00,  2.2691e-01],\n",
            "         [-2.6548e+00, -1.3844e+00, -1.7109e+00,  ..., -1.5959e+00,\n",
            "          -8.0641e-01, -1.3144e+00],\n",
            "         [ 1.6357e-01,  3.3342e-01, -2.5715e+00,  ..., -4.9985e-01,\n",
            "          -1.9981e+00, -2.4955e+00],\n",
            "         ...,\n",
            "         [-2.1912e+00, -1.3415e+00, -8.3520e-01,  ..., -8.1825e-01,\n",
            "          -2.2704e+00,  1.4990e+00],\n",
            "         [-3.1612e+00, -2.0229e+00, -1.9811e+00,  ..., -2.1616e+00,\n",
            "          -2.6008e+00, -2.6022e+00],\n",
            "         [ 1.1440e+00,  1.2709e+00,  1.2378e+00,  ...,  8.3460e-01,\n",
            "           5.8207e-01,  1.0799e+00]],\n",
            "\n",
            "        [[ 2.0531e-01,  8.9524e-01, -9.8557e-01,  ...,  2.5017e+00,\n",
            "           2.0807e+00,  1.7259e-01],\n",
            "         [-5.0785e+00, -2.7821e+00, -3.3144e+00,  ..., -2.8514e+00,\n",
            "          -1.1171e+00, -2.6759e+00],\n",
            "         [ 2.7111e-01,  5.7387e-01, -5.1217e+00,  ..., -1.0005e+00,\n",
            "          -3.7047e+00, -5.3241e+00],\n",
            "         ...,\n",
            "         [-4.6942e+00, -2.4840e+00, -1.6759e+00,  ..., -1.3023e+00,\n",
            "          -4.7100e+00,  2.9827e+00],\n",
            "         [-6.3738e+00, -3.8124e+00, -3.9446e+00,  ..., -4.8914e+00,\n",
            "          -5.3013e+00, -5.6823e+00],\n",
            "         [ 2.2834e+00,  2.7847e+00,  2.8674e+00,  ...,  1.8500e+00,\n",
            "           1.5494e+00,  2.2520e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 6.8732e-01,  1.1535e+00, -4.8335e-01,  ...,  2.0613e+00,\n",
            "           2.0788e+00,  9.7127e-01],\n",
            "         [-4.0923e+00, -1.7595e+00, -2.1704e+00,  ..., -2.5860e+00,\n",
            "          -1.3534e+00, -1.6255e+00],\n",
            "         [ 4.0613e-01,  5.1507e-01, -4.0340e+00,  ..., -1.1149e+00,\n",
            "          -3.0580e+00, -3.9873e+00],\n",
            "         ...,\n",
            "         [-3.7544e+00, -1.7635e+00, -1.2268e+00,  ..., -1.0878e+00,\n",
            "          -3.3219e+00,  1.8730e+00],\n",
            "         [-5.0023e+00, -2.8662e+00, -2.9842e+00,  ..., -3.6870e+00,\n",
            "          -3.7437e+00, -4.2372e+00],\n",
            "         [ 1.3335e+00,  1.3147e+00,  1.3090e+00,  ...,  7.2355e-01,\n",
            "           6.8008e-01,  1.4803e+00]],\n",
            "\n",
            "        [[ 4.8509e-01,  9.5365e-01, -5.5422e-01,  ...,  1.9865e+00,\n",
            "           1.8544e+00,  6.0322e-01],\n",
            "         [-3.8792e+00, -1.8600e+00, -2.2512e+00,  ..., -2.3705e+00,\n",
            "          -1.1511e+00, -1.7297e+00],\n",
            "         [ 3.1647e-01,  4.5021e-01, -3.8311e+00,  ..., -8.9931e-01,\n",
            "          -2.9063e+00, -3.8228e+00],\n",
            "         ...,\n",
            "         [-3.5243e+00, -1.7939e+00, -1.1935e+00,  ..., -1.0586e+00,\n",
            "          -3.3185e+00,  1.9719e+00],\n",
            "         [-4.7759e+00, -2.8036e+00, -2.8842e+00,  ..., -3.5044e+00,\n",
            "          -3.7201e+00, -4.0837e+00],\n",
            "         [ 1.4487e+00,  1.5759e+00,  1.5839e+00,  ...,  9.7587e-01,\n",
            "           8.1601e-01,  1.4952e+00]],\n",
            "\n",
            "        [[ 1.8029e+00,  2.0968e+00, -3.1897e-02,  ...,  1.8523e+00,\n",
            "           2.4223e+00,  2.6300e+00],\n",
            "         [-4.5558e+00, -1.2496e+00, -2.0675e+00,  ..., -3.3090e+00,\n",
            "          -2.6236e+00, -1.1360e+00],\n",
            "         [ 8.7852e-01,  8.9594e-01, -4.5766e+00,  ..., -2.3874e+00,\n",
            "          -3.9061e+00, -4.4086e+00],\n",
            "         ...,\n",
            "         [-4.6423e+00, -1.8932e+00, -1.4463e+00,  ..., -1.5983e+00,\n",
            "          -3.1934e+00,  7.2489e-01],\n",
            "         [-5.9849e+00, -3.1924e+00, -3.5188e+00,  ..., -4.0786e+00,\n",
            "          -3.2882e+00, -4.4745e+00],\n",
            "         [ 1.1432e+00,  6.8486e-01,  1.3317e-01,  ..., -8.6052e-01,\n",
            "           6.1528e-01,  1.5018e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[-3.1233, -3.4469, -4.7169,  ..., -1.6798, -1.8763, -3.9847],\n",
            "         [-6.8744, -6.2887, -6.5224,  ..., -5.6134, -4.0895, -5.9463],\n",
            "         [-3.2175, -3.3293, -7.3367,  ..., -4.3389, -5.8289, -7.5189],\n",
            "         ...,\n",
            "         [-6.3246, -5.5754, -5.2685,  ..., -4.7582, -6.6268, -0.9623],\n",
            "         [-7.6404, -7.0262, -6.7612,  ..., -7.1053, -7.1209, -7.7132],\n",
            "         [-0.7049, -0.7807, -0.7755,  ..., -1.7132, -1.5829, -1.3490]],\n",
            "\n",
            "        [[-2.5722, -2.5759, -3.3738,  ..., -1.7780, -1.6424, -2.7979],\n",
            "         [-5.4984, -4.5391, -4.6987,  ..., -4.8365, -3.6760, -4.3393],\n",
            "         [-2.6801, -2.8213, -5.5593,  ..., -3.7404, -4.8677, -5.5203],\n",
            "         ...,\n",
            "         [-5.0348, -4.4962, -3.8230,  ..., -4.0588, -5.1400, -1.5258],\n",
            "         [-6.0048, -5.1776, -4.9690,  ..., -5.4022, -5.4704, -5.6270],\n",
            "         [-1.6996, -1.8838, -1.7500,  ..., -2.4060, -2.2875, -1.9449]],\n",
            "\n",
            "        [[-3.0184, -2.9742, -5.1310,  ..., -1.3290, -1.5200, -3.6411],\n",
            "         [-8.3022, -6.6515, -7.4598,  ..., -6.6821, -4.7178, -6.4896],\n",
            "         [-2.9526, -3.2956, -9.2671,  ..., -4.8312, -7.3054, -9.1377],\n",
            "         ...,\n",
            "         [-7.9179, -6.3535, -5.8213,  ..., -5.1330, -8.3107, -0.8310],\n",
            "         [-9.5975, -7.6818, -8.0901,  ..., -8.7221, -8.9020, -9.4960],\n",
            "         [-0.9402, -1.0848, -1.2780,  ..., -1.9807, -2.0512, -1.5616]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-2.3893, -2.2759, -4.0961,  ..., -1.3760, -1.2732, -2.3770],\n",
            "         [-7.1688, -5.1889, -5.7831,  ..., -6.0233, -4.7054, -4.9737],\n",
            "         [-2.6704, -2.9143, -7.6468,  ..., -4.5522, -6.4101, -7.3356],\n",
            "         ...,\n",
            "         [-6.8309, -5.1929, -4.8395,  ..., -4.5251, -6.6740, -1.4753],\n",
            "         [-8.0789, -6.2956, -6.5969,  ..., -7.1243, -7.0957, -7.5854],\n",
            "         [-1.7431, -2.1147, -2.3038,  ..., -2.7138, -2.6720, -1.8680]],\n",
            "\n",
            "        [[-2.5183, -2.4391, -4.0446,  ..., -1.4462, -1.3782, -2.6875],\n",
            "         [-6.8826, -5.2528, -5.7416,  ..., -5.8032, -4.3836, -5.0204],\n",
            "         [-2.6869, -2.9425, -7.3215,  ..., -4.3320, -6.1388, -7.1136],\n",
            "         ...,\n",
            "         [-6.5277, -5.1866, -4.6839,  ..., -4.4913, -6.5510, -1.3188],\n",
            "         [-7.7793, -6.1963, -6.3746,  ..., -6.9371, -6.9527, -7.3744],\n",
            "         [-1.5547, -1.8169, -1.9065,  ..., -2.4568, -2.4165, -1.7955]],\n",
            "\n",
            "        [[-1.6932, -1.6698, -4.2721,  ..., -1.5766, -1.4544, -1.2528],\n",
            "         [-8.0519, -5.0162, -6.3077,  ..., -6.7379, -6.5003, -5.0189],\n",
            "         [-2.6176, -2.8706, -8.8168,  ..., -5.8163, -7.7827, -8.2915],\n",
            "         ...,\n",
            "         [-8.1384, -5.6598, -5.6865,  ..., -5.0272, -7.0700, -3.1580],\n",
            "         [-9.4810, -6.9590, -7.7590,  ..., -7.5074, -7.1649, -8.3574],\n",
            "         [-2.3529, -3.0817, -4.1070,  ..., -4.2894, -3.2614, -2.3811]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.9216,  2.2444, -0.0070,  ..., -0.9130,  0.6951,  1.6398],\n",
            "        [ 0.1348,  0.6053, -0.7546,  ...,  1.5503,  1.2282,  1.7843],\n",
            "        [ 1.9501,  2.1629,  0.0257,  ..., -1.1216,  0.5965,  1.5230],\n",
            "        ...,\n",
            "        [ 1.7991,  2.1061, -0.0060,  ..., -0.8269,  0.6336,  1.5408],\n",
            "        [ 0.1158,  0.5917, -0.8254,  ...,  1.6713,  1.3486,  1.9124],\n",
            "        [ 0.0788,  0.3395, -0.8725,  ...,  1.6524,  1.3197,  1.8965]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.9216e+00,  2.2444e+00, -7.0407e-03,  ...,  2.0049e+00,\n",
            "           2.5856e+00,  2.8043e+00],\n",
            "         [-4.9052e+00, -1.3537e+00, -2.1930e+00,  ..., -3.5284e+00,\n",
            "          -2.8101e+00, -1.2487e+00],\n",
            "         [ 9.8360e-01,  9.6202e-01, -4.9517e+00,  ..., -2.6153e+00,\n",
            "          -4.2044e+00, -4.7856e+00],\n",
            "         ...,\n",
            "         [-5.0036e+00, -2.0469e+00, -1.5185e+00,  ..., -1.7094e+00,\n",
            "          -3.4730e+00,  7.5596e-01],\n",
            "         [-6.4956e+00, -3.4462e+00, -3.8015e+00,  ..., -4.4417e+00,\n",
            "          -3.5753e+00, -4.8698e+00],\n",
            "         [ 1.2077e+00,  7.5762e-01,  1.6299e-01,  ..., -9.1298e-01,\n",
            "           6.9512e-01,  1.6398e+00]],\n",
            "\n",
            "        [[ 1.3478e-01,  6.0535e-01, -7.5459e-01,  ...,  1.9369e+00,\n",
            "           1.5137e+00, -4.4698e-02],\n",
            "         [-3.8162e+00, -2.2006e+00, -2.6372e+00,  ..., -2.0698e+00,\n",
            "          -8.8158e-01, -2.1450e+00],\n",
            "         [ 1.4608e-01,  4.7331e-01, -3.8290e+00,  ..., -7.0180e-01,\n",
            "          -2.7725e+00, -3.9241e+00],\n",
            "         ...,\n",
            "         [-3.3068e+00, -1.9595e+00, -1.3209e+00,  ..., -1.0795e+00,\n",
            "          -3.5157e+00,  2.3901e+00],\n",
            "         [-4.6765e+00, -2.9924e+00, -2.9856e+00,  ..., -3.4712e+00,\n",
            "          -4.0485e+00, -4.0919e+00],\n",
            "         [ 1.9108e+00,  2.2983e+00,  2.3154e+00,  ...,  1.5503e+00,\n",
            "           1.2282e+00,  1.7843e+00]],\n",
            "\n",
            "        [[ 1.9501e+00,  2.1629e+00,  2.5750e-02,  ...,  1.7766e+00,\n",
            "           2.3374e+00,  2.8056e+00],\n",
            "         [-4.4942e+00, -1.2263e+00, -2.0380e+00,  ..., -3.3392e+00,\n",
            "          -2.7847e+00, -1.0903e+00],\n",
            "         [ 9.0878e-01,  8.8603e-01, -4.5329e+00,  ..., -2.5150e+00,\n",
            "          -4.0058e+00, -4.3213e+00],\n",
            "         ...,\n",
            "         [-4.6396e+00, -1.8466e+00, -1.4400e+00,  ..., -1.6959e+00,\n",
            "          -3.1379e+00,  5.6574e-01],\n",
            "         [-5.9493e+00, -3.2186e+00, -3.5579e+00,  ..., -3.9675e+00,\n",
            "          -3.0330e+00, -4.3040e+00],\n",
            "         [ 1.1795e+00,  6.1313e-01, -2.4477e-02,  ..., -1.1216e+00,\n",
            "           5.9648e-01,  1.5230e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.7991e+00,  2.1061e+00, -5.9754e-03,  ...,  1.9172e+00,\n",
            "           2.4540e+00,  2.6196e+00],\n",
            "         [-4.6383e+00, -1.2855e+00, -2.0830e+00,  ..., -3.3302e+00,\n",
            "          -2.6395e+00, -1.1847e+00],\n",
            "         [ 9.1951e-01,  9.0626e-01, -4.6622e+00,  ..., -2.4405e+00,\n",
            "          -3.9571e+00, -4.4988e+00],\n",
            "         ...,\n",
            "         [-4.6884e+00, -1.9411e+00, -1.4284e+00,  ..., -1.6046e+00,\n",
            "          -3.2657e+00,  7.4905e-01],\n",
            "         [-6.0963e+00, -3.2468e+00, -3.5750e+00,  ..., -4.1712e+00,\n",
            "          -3.3930e+00, -4.5824e+00],\n",
            "         [ 1.1414e+00,  7.1448e-01,  1.6024e-01,  ..., -8.2687e-01,\n",
            "           6.3360e-01,  1.5408e+00]],\n",
            "\n",
            "        [[ 1.1577e-01,  5.9171e-01, -8.2539e-01,  ...,  1.9956e+00,\n",
            "           1.5474e+00, -9.7998e-02],\n",
            "         [-3.9851e+00, -2.3388e+00, -2.7846e+00,  ..., -2.1428e+00,\n",
            "          -9.0407e-01, -2.2800e+00],\n",
            "         [ 1.2398e-01,  4.9921e-01, -4.0114e+00,  ..., -7.3386e-01,\n",
            "          -2.8891e+00, -4.1398e+00],\n",
            "         ...,\n",
            "         [-3.4652e+00, -2.0545e+00, -1.4156e+00,  ..., -1.1184e+00,\n",
            "          -3.6967e+00,  2.5413e+00],\n",
            "         [-4.8982e+00, -3.1509e+00, -3.1402e+00,  ..., -3.6673e+00,\n",
            "          -4.2584e+00, -4.3098e+00],\n",
            "         [ 2.0596e+00,  2.4803e+00,  2.5070e+00,  ...,  1.6713e+00,\n",
            "           1.3486e+00,  1.9124e+00]],\n",
            "\n",
            "        [[ 7.8760e-02,  3.3952e-01, -8.7246e-01,  ...,  1.7959e+00,\n",
            "           1.2239e+00, -3.0148e-01],\n",
            "         [-3.4739e+00, -2.2863e+00, -2.5609e+00,  ..., -1.8551e+00,\n",
            "          -8.7767e-01, -2.1114e+00],\n",
            "         [-2.4620e-02,  3.8203e-01, -3.4153e+00,  ..., -6.8471e-01,\n",
            "          -2.5081e+00, -3.5886e+00],\n",
            "         ...,\n",
            "         [-2.9257e+00, -1.7587e+00, -1.3934e+00,  ..., -1.0849e+00,\n",
            "          -3.1989e+00,  2.3485e+00],\n",
            "         [-4.1674e+00, -3.0043e+00, -2.8439e+00,  ..., -3.1392e+00,\n",
            "          -3.6798e+00, -3.7355e+00],\n",
            "         [ 2.0882e+00,  2.4869e+00,  2.4661e+00,  ...,  1.6524e+00,\n",
            "           1.3197e+00,  1.8965e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.6608,  -1.6457,  -4.4579,  ...,  -1.5256,  -1.4739,  -1.2149],\n",
            "         [ -8.4876,  -5.2438,  -6.6439,  ...,  -7.0589,  -6.8695,  -5.2679],\n",
            "         [ -2.5988,  -2.9281,  -9.4025,  ...,  -6.1458,  -8.2639,  -8.8048],\n",
            "         ...,\n",
            "         [ -8.5860,  -5.9370,  -5.9693,  ...,  -5.2399,  -7.5325,  -3.2632],\n",
            "         [-10.0780,  -7.3363,  -8.2523,  ...,  -7.9721,  -7.6348,  -8.8890],\n",
            "         [ -2.3747,  -3.1325,  -4.2878,  ...,  -4.4434,  -3.3643,  -2.3794]],\n",
            "\n",
            "        [[ -2.8636,  -2.9042,  -4.2651,  ...,  -1.5940,  -1.6401,  -3.4476],\n",
            "         [ -6.8145,  -5.7101,  -6.1477,  ...,  -5.6008,  -4.0355,  -5.5480],\n",
            "         [ -2.8523,  -3.0363,  -7.3395,  ...,  -4.2328,  -5.9264,  -7.3271],\n",
            "         ...,\n",
            "         [ -6.3052,  -5.4691,  -4.8314,  ...,  -4.6104,  -6.6696,  -1.0128],\n",
            "         [ -7.6749,  -6.5020,  -6.4962,  ...,  -7.0022,  -7.2023,  -7.4949],\n",
            "         [ -1.0875,  -1.2113,  -1.1951,  ...,  -1.9807,  -1.9257,  -1.6187]],\n",
            "\n",
            "        [[ -1.6007,  -1.6205,  -4.2665,  ...,  -1.6396,  -1.5838,  -1.1629],\n",
            "         [ -8.0450,  -5.0098,  -6.3303,  ...,  -6.7554,  -6.7059,  -5.0588],\n",
            "         [ -2.6420,  -2.8974,  -8.8251,  ...,  -5.9312,  -7.9271,  -8.2898],\n",
            "         ...,\n",
            "         [ -8.1904,  -5.6301,  -5.7323,  ...,  -5.1120,  -7.0592,  -3.4028],\n",
            "         [ -9.5001,  -7.0021,  -7.8501,  ...,  -7.3837,  -6.9542,  -8.2725],\n",
            "         [ -2.3713,  -3.1704,  -4.3167,  ...,  -4.5378,  -3.3248,  -2.4455]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.7049,  -1.6817,  -4.2731,  ...,  -1.5385,  -1.4513,  -1.2737],\n",
            "         [ -8.1422,  -5.0734,  -6.3501,  ...,  -6.7859,  -6.5447,  -5.0780],\n",
            "         [ -2.5844,  -2.8816,  -8.9293,  ...,  -5.8963,  -7.8624,  -8.3921],\n",
            "         ...,\n",
            "         [ -8.1923,  -5.7289,  -5.6955,  ...,  -5.0603,  -7.1710,  -3.1442],\n",
            "         [ -9.6002,  -7.0346,  -7.8421,  ...,  -7.6269,  -7.2983,  -8.4757],\n",
            "         [ -2.3625,  -3.0733,  -4.1069,  ...,  -4.2826,  -3.2717,  -2.3525]],\n",
            "\n",
            "        [[ -2.9294,  -2.9973,  -4.4450,  ...,  -1.5901,  -1.6621,  -3.5888],\n",
            "         [ -7.0304,  -5.9278,  -6.4043,  ...,  -5.7285,  -4.1136,  -5.7709],\n",
            "         [ -2.9212,  -3.0898,  -7.6310,  ...,  -4.3196,  -6.0986,  -7.6307],\n",
            "         ...,\n",
            "         [ -6.5104,  -5.6435,  -5.0353,  ...,  -4.7041,  -6.9063,  -0.9495],\n",
            "         [ -7.9434,  -6.7399,  -6.7598,  ...,  -7.2530,  -7.4679,  -7.8006],\n",
            "         [ -0.9856,  -1.1088,  -1.1127,  ...,  -1.9144,  -1.8609,  -1.5785]],\n",
            "\n",
            "        [[ -2.9207,  -3.1593,  -4.3000,  ...,  -1.7015,  -1.8204,  -3.6884],\n",
            "         [ -6.4733,  -5.7851,  -5.9885,  ...,  -5.3525,  -3.9220,  -5.4983],\n",
            "         [ -3.0240,  -3.1167,  -6.8429,  ...,  -4.1821,  -5.5524,  -6.9755],\n",
            "         ...,\n",
            "         [ -5.9251,  -5.2575,  -4.8210,  ...,  -4.5822,  -6.2433,  -1.0385],\n",
            "         [ -7.1669,  -6.5031,  -6.2715,  ...,  -6.6366,  -6.7242,  -7.1224],\n",
            "         [ -0.9112,  -1.0118,  -0.9615,  ...,  -1.8450,  -1.7246,  -1.4905]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.2032,  2.3958,  0.0633,  ..., -1.4072,  0.6743,  1.6890],\n",
            "        [ 0.7748,  1.3311, -0.5831,  ...,  0.9016,  0.8772,  1.7639],\n",
            "        [ 2.1766,  2.4354,  0.0574,  ..., -1.2857,  0.7187,  1.7435],\n",
            "        ...,\n",
            "        [ 0.6894,  1.1880, -0.5081,  ...,  0.8284,  0.7624,  1.5709],\n",
            "        [ 2.2487,  2.4298,  0.0641,  ..., -1.4660,  0.6825,  1.7068],\n",
            "        [ 0.1188,  0.3855, -0.8063,  ...,  1.5607,  1.2297,  1.7647]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.2032e+00,  2.3958e+00,  6.3299e-02,  ...,  1.8555e+00,\n",
            "           2.4568e+00,  3.1677e+00],\n",
            "         [-4.8510e+00, -1.3606e+00, -2.1598e+00,  ..., -3.6543e+00,\n",
            "          -3.1201e+00, -1.1694e+00],\n",
            "         [ 1.0500e+00,  9.9121e-01, -4.9346e+00,  ..., -2.8548e+00,\n",
            "          -4.4499e+00, -4.6799e+00],\n",
            "         ...,\n",
            "         [-5.0842e+00, -2.0000e+00, -1.5316e+00,  ..., -1.9253e+00,\n",
            "          -3.4158e+00,  4.8673e-01],\n",
            "         [-6.5383e+00, -3.5576e+00, -3.9167e+00,  ..., -4.2875e+00,\n",
            "          -3.1719e+00, -4.6397e+00],\n",
            "         [ 1.3219e+00,  6.3761e-01, -8.2846e-02,  ..., -1.4072e+00,\n",
            "           6.7432e-01,  1.6890e+00]],\n",
            "\n",
            "        [[ 7.7476e-01,  1.3311e+00, -5.8306e-01,  ...,  2.4053e+00,\n",
            "           2.3946e+00,  1.0453e+00],\n",
            "         [-4.8219e+00, -2.1019e+00, -2.5342e+00,  ..., -2.9351e+00,\n",
            "          -1.5034e+00, -1.9711e+00],\n",
            "         [ 4.9731e-01,  5.8509e-01, -4.7904e+00,  ..., -1.3708e+00,\n",
            "          -3.5864e+00, -4.7867e+00],\n",
            "         ...,\n",
            "         [-4.4597e+00, -2.0569e+00, -1.4010e+00,  ..., -1.2476e+00,\n",
            "          -3.9805e+00,  2.2292e+00],\n",
            "         [-5.9599e+00, -3.3704e+00, -3.5293e+00,  ..., -4.4648e+00,\n",
            "          -4.4732e+00, -5.1175e+00],\n",
            "         [ 1.5539e+00,  1.5905e+00,  1.6096e+00,  ...,  9.0164e-01,\n",
            "           8.7722e-01,  1.7639e+00]],\n",
            "\n",
            "        [[ 2.1766e+00,  2.4354e+00,  5.7381e-02,  ...,  1.9877e+00,\n",
            "           2.5990e+00,  3.1481e+00],\n",
            "         [-5.0452e+00, -1.3861e+00, -2.2470e+00,  ..., -3.7264e+00,\n",
            "          -3.1197e+00, -1.2514e+00],\n",
            "         [ 1.0735e+00,  1.0072e+00, -5.1306e+00,  ..., -2.8978e+00,\n",
            "          -4.5149e+00, -4.9123e+00],\n",
            "         ...,\n",
            "         [-5.2539e+00, -2.0820e+00, -1.5671e+00,  ..., -1.9001e+00,\n",
            "          -3.5763e+00,  5.8372e-01],\n",
            "         [-6.7729e+00, -3.6365e+00, -4.0266e+00,  ..., -4.5283e+00,\n",
            "          -3.4338e+00, -4.9040e+00],\n",
            "         [ 1.3017e+00,  7.1180e-01, -6.3406e-03,  ..., -1.2857e+00,\n",
            "           7.1866e-01,  1.7435e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 6.8944e-01,  1.1880e+00, -5.0815e-01,  ...,  2.1810e+00,\n",
            "           2.1358e+00,  8.9863e-01],\n",
            "         [-4.2993e+00, -1.8990e+00, -2.2990e+00,  ..., -2.6263e+00,\n",
            "          -1.3591e+00, -1.7775e+00],\n",
            "         [ 4.2978e-01,  5.2003e-01, -4.2463e+00,  ..., -1.1847e+00,\n",
            "          -3.2141e+00, -4.2202e+00],\n",
            "         ...,\n",
            "         [-3.9144e+00, -1.8595e+00, -1.2480e+00,  ..., -1.1356e+00,\n",
            "          -3.5414e+00,  2.0185e+00],\n",
            "         [-5.2790e+00, -3.0291e+00, -3.1466e+00,  ..., -3.9072e+00,\n",
            "          -3.9799e+00, -4.4952e+00],\n",
            "         [ 1.4133e+00,  1.4388e+00,  1.4400e+00,  ...,  8.2840e-01,\n",
            "           7.6242e-01,  1.5709e+00]],\n",
            "\n",
            "        [[ 2.2487e+00,  2.4298e+00,  6.4138e-02,  ...,  1.8501e+00,\n",
            "           2.4617e+00,  3.2318e+00],\n",
            "         [-4.8861e+00, -1.3781e+00, -2.1717e+00,  ..., -3.6996e+00,\n",
            "          -3.1751e+00, -1.1696e+00],\n",
            "         [ 1.0644e+00,  1.0056e+00, -4.9769e+00,  ..., -2.8996e+00,\n",
            "          -4.5136e+00, -4.7111e+00],\n",
            "         ...,\n",
            "         [-5.1406e+00, -2.0137e+00, -1.5506e+00,  ..., -1.9666e+00,\n",
            "          -3.4418e+00,  4.6420e-01],\n",
            "         [-6.6067e+00, -3.6027e+00, -3.9616e+00,  ..., -4.3113e+00,\n",
            "          -3.1640e+00, -4.6634e+00],\n",
            "         [ 1.3490e+00,  6.3224e-01, -1.0015e-01,  ..., -1.4660e+00,\n",
            "           6.8249e-01,  1.7068e+00]],\n",
            "\n",
            "        [[ 1.1880e-01,  3.8548e-01, -8.0630e-01,  ...,  1.7438e+00,\n",
            "           1.2000e+00, -2.7273e-01],\n",
            "         [-3.3578e+00, -2.1689e+00, -2.4450e+00,  ..., -1.7734e+00,\n",
            "          -8.3927e-01, -2.0162e+00],\n",
            "         [-5.7043e-03,  3.8849e-01, -3.3024e+00,  ..., -6.7622e-01,\n",
            "          -2.4328e+00, -3.4378e+00],\n",
            "         ...,\n",
            "         [-2.7983e+00, -1.7004e+00, -1.2917e+00,  ..., -1.0433e+00,\n",
            "          -3.0764e+00,  2.2513e+00],\n",
            "         [-4.0135e+00, -2.8797e+00, -2.7437e+00,  ..., -2.9868e+00,\n",
            "          -3.5486e+00, -3.5670e+00],\n",
            "         [ 1.9630e+00,  2.3258e+00,  2.3033e+00,  ...,  1.5607e+00,\n",
            "           1.2297e+00,  1.7647e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.4975,  -1.5468,  -4.5160,  ...,  -1.6698,  -1.7198,  -1.0459],\n",
            "         [ -8.5516,  -5.3032,  -6.7392,  ...,  -7.1797,  -7.2967,  -5.3830],\n",
            "         [ -2.6507,  -2.9514,  -9.5139,  ...,  -6.3802,  -8.6265,  -8.8935],\n",
            "         ...,\n",
            "         [ -8.7849,  -5.9426,  -6.1110,  ...,  -5.4506,  -7.5924,  -3.7269],\n",
            "         [-10.2390,  -7.5002,  -8.4960,  ...,  -7.8129,  -7.3486,  -8.8532],\n",
            "         [ -2.3788,  -3.3050,  -4.6622,  ...,  -4.9326,  -3.5023,  -2.5246]],\n",
            "\n",
            "        [[ -2.4159,  -2.2888,  -4.5514,  ...,  -1.2193,  -1.2335,  -2.5046],\n",
            "         [ -8.0126,  -5.7218,  -6.5025,  ...,  -6.5597,  -5.1315,  -5.5210],\n",
            "         [ -2.6934,  -3.0348,  -8.7587,  ...,  -4.9954,  -7.2144,  -8.3366],\n",
            "         ...,\n",
            "         [ -7.6503,  -5.6767,  -5.3694,  ...,  -4.8722,  -7.6086,  -1.3207],\n",
            "         [ -9.1506,  -6.9903,  -7.4977,  ...,  -8.0894,  -8.1013,  -8.6674],\n",
            "         [ -1.6368,  -2.0294,  -2.3587,  ...,  -2.7230,  -2.7509,  -1.7860]],\n",
            "\n",
            "        [[ -1.5313,  -1.5586,  -4.5991,  ...,  -1.5968,  -1.6392,  -1.0775],\n",
            "         [ -8.7531,  -5.3801,  -6.9035,  ...,  -7.3109,  -7.3579,  -5.4770],\n",
            "         [ -2.6344,  -2.9867,  -9.7870,  ...,  -6.4823,  -8.7531,  -9.1379],\n",
            "         ...,\n",
            "         [ -8.9618,  -6.0759,  -6.2236,  ...,  -5.4846,  -7.8144,  -3.6419],\n",
            "         [-10.4808,  -7.6304,  -8.6831,  ...,  -8.1128,  -7.6720,  -9.1296],\n",
            "         [ -2.4062,  -3.2821,  -4.6628,  ...,  -4.8701,  -3.5195,  -2.4821]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.4076,  -2.2884,  -4.2059,  ...,  -1.3147,  -1.2814,  -2.5001],\n",
            "         [ -7.3964,  -5.3754,  -5.9968,  ...,  -6.1221,  -4.7763,  -5.1763],\n",
            "         [ -2.6673,  -2.9563,  -7.9441,  ...,  -4.6804,  -6.6313,  -7.6189],\n",
            "         ...,\n",
            "         [ -7.0114,  -5.3359,  -4.9458,  ...,  -4.6314,  -6.9587,  -1.3803],\n",
            "         [ -8.3761,  -6.5055,  -6.8444,  ...,  -7.4029,  -7.3971,  -7.8940],\n",
            "         [ -1.6837,  -2.0376,  -2.2578,  ...,  -2.6673,  -2.6548,  -1.8278]],\n",
            "\n",
            "        [[ -1.4767,  -1.5337,  -4.5556,  ...,  -1.6871,  -1.7509,  -1.0228],\n",
            "         [ -8.6114,  -5.3416,  -6.7914,  ...,  -7.2369,  -7.3877,  -5.4242],\n",
            "         [ -2.6609,  -2.9578,  -9.5965,  ...,  -6.4368,  -8.7262,  -8.9657],\n",
            "         ...,\n",
            "         [ -8.8660,  -5.9771,  -6.1703,  ...,  -5.5039,  -7.6544,  -3.7904],\n",
            "         [-10.3320,  -7.5662,  -8.5813,  ...,  -7.8486,  -7.3766,  -8.9180],\n",
            "         [ -2.3763,  -3.3312,  -4.7198,  ...,  -5.0033,  -3.5301,  -2.5478]],\n",
            "\n",
            "        [[ -2.8424,  -3.0488,  -4.1503,  ...,  -1.7156,  -1.8096,  -3.5951],\n",
            "         [ -6.3190,  -5.6032,  -5.7890,  ...,  -5.2328,  -3.8489,  -5.3386],\n",
            "         [ -2.9669,  -3.0458,  -6.6463,  ...,  -4.1356,  -5.4424,  -6.7601],\n",
            "         ...,\n",
            "         [ -5.7596,  -5.1347,  -4.6357,  ...,  -4.5028,  -6.0860,  -1.0710],\n",
            "         [ -6.9748,  -6.3140,  -6.0877,  ...,  -6.4463,  -6.5582,  -6.8894],\n",
            "         [ -0.9983,  -1.1085,  -1.0407,  ...,  -1.8987,  -1.7800,  -1.5577]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.8506,  1.3566, -0.4664,  ...,  0.6706,  0.7423,  1.6369],\n",
            "        [ 0.3241,  0.9053, -0.7752,  ...,  1.4829,  1.2299,  1.8348],\n",
            "        [ 1.8984,  2.1552,  0.0898,  ..., -1.0439,  0.6110,  1.5738],\n",
            "        ...,\n",
            "        [ 0.0862,  0.1450, -1.0240,  ...,  1.7509,  1.4220,  2.0052],\n",
            "        [ 2.3474,  2.5202,  0.1087,  ..., -1.5910,  0.7124,  1.7863],\n",
            "        [ 0.8693,  1.3291, -0.3654,  ...,  0.4789,  0.6129,  1.4891]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.8506,  1.3566, -0.4664,  ...,  2.2943,  2.3105,  1.1792],\n",
            "         [-4.5786, -1.8963, -2.3414,  ..., -2.8355, -1.5494, -1.7913],\n",
            "         [ 0.5196,  0.6106, -4.5417,  ..., -1.4604, -3.4510, -4.4935],\n",
            "         ...,\n",
            "         [-4.2198, -1.9204, -1.2998,  ..., -1.1955, -3.6810,  1.9701],\n",
            "         [-5.6475, -3.1736, -3.3380,  ..., -4.2023, -4.1524, -4.7900],\n",
            "         [ 1.3763,  1.3378,  1.3276,  ...,  0.6706,  0.7423,  1.6369]],\n",
            "\n",
            "        [[ 0.3241,  0.9053, -0.7752,  ...,  2.2479,  1.8871,  0.2271],\n",
            "         [-4.4342, -2.3573, -2.8154,  ..., -2.4674, -1.0475, -2.2822],\n",
            "         [ 0.2588,  0.4786, -4.4356,  ..., -0.9673, -3.2957, -4.5216],\n",
            "         ...,\n",
            "         [-3.9777, -2.1531, -1.3696,  ..., -1.1737, -4.0315,  2.5207],\n",
            "         [-5.5139, -3.3029, -3.4127,  ..., -4.1614, -4.5194, -4.8444],\n",
            "         [ 1.8602,  2.2362,  2.2872,  ...,  1.4829,  1.2299,  1.8348]],\n",
            "\n",
            "        [[ 1.8984,  2.1552,  0.0898,  ...,  1.8912,  2.3810,  2.7342],\n",
            "         [-4.5905, -1.2635, -2.0506,  ..., -3.3312, -2.7465, -1.1757],\n",
            "         [ 0.9781,  0.8982, -4.6265,  ..., -2.5817, -4.0276, -4.4339],\n",
            "         ...,\n",
            "         [-4.6583, -1.9158, -1.3558,  ..., -1.6548, -3.2220,  0.6157],\n",
            "         [-6.0566, -3.2596, -3.6031,  ..., -4.0897, -3.1921, -4.4475],\n",
            "         [ 1.1488,  0.6660,  0.0301,  ..., -1.0439,  0.6110,  1.5738]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0862,  0.1450, -1.0240,  ...,  1.6941,  1.0006, -0.5189],\n",
            "         [-3.2367, -2.4154, -2.5768,  ..., -1.6547, -0.8836, -2.1410],\n",
            "         [-0.1974,  0.2480, -3.0999,  ..., -0.7389, -2.3362, -3.3526],\n",
            "         ...,\n",
            "         [-2.6182, -1.5733, -1.4787,  ..., -1.1042, -2.9797,  2.3404],\n",
            "         [-3.7602, -3.0793, -2.7771,  ..., -2.9379, -3.3869, -3.4888],\n",
            "         [ 2.2881,  2.7158,  2.6345,  ...,  1.7509,  1.4220,  2.0052]],\n",
            "\n",
            "        [[ 2.3474,  2.5202,  0.1087,  ...,  1.9034,  2.4980,  3.3781],\n",
            "         [-5.0312, -1.4397, -2.2126,  ..., -3.8203, -3.3090, -1.2184],\n",
            "         [ 1.1384,  1.0427, -5.1408,  ..., -3.0642, -4.6981, -4.8568],\n",
            "         ...,\n",
            "         [-5.3069, -2.0873, -1.5579,  ..., -2.0553, -3.5566,  0.4207],\n",
            "         [-6.8459, -3.7442, -4.1100,  ..., -4.4415, -3.2194, -4.7991],\n",
            "         [ 1.4057,  0.6470, -0.1212,  ..., -1.5910,  0.7124,  1.7863]],\n",
            "\n",
            "        [[ 0.8693,  1.3291, -0.3654,  ...,  2.1168,  2.1684,  1.2376],\n",
            "         [-4.2248, -1.6805, -2.1153,  ..., -2.6775, -1.5369, -1.5846],\n",
            "         [ 0.5185,  0.6013, -4.1785,  ..., -1.4369, -3.2204, -4.0909],\n",
            "         ...,\n",
            "         [-3.8735, -1.7626, -1.1913,  ..., -1.1249, -3.3252,  1.7093],\n",
            "         [-5.1981, -2.9249, -3.0777,  ..., -3.8221, -3.7546, -4.3495],\n",
            "         [ 1.2134,  1.1242,  1.0810,  ...,  0.4789,  0.6129,  1.4891]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.3251,  -2.2029,  -4.3183,  ...,  -1.2525,  -1.2424,  -2.3072],\n",
            "         [ -7.7542,  -5.4559,  -6.1934,  ...,  -6.3823,  -5.1023,  -5.2777],\n",
            "         [ -2.6561,  -2.9490,  -8.3937,  ...,  -5.0072,  -7.0039,  -7.9799],\n",
            "         ...,\n",
            "         [ -7.3955,  -5.4800,  -5.1518,  ...,  -4.7423,  -7.2339,  -1.5163],\n",
            "         [ -8.8231,  -6.7332,  -7.1900,  ...,  -7.7491,  -7.7053,  -8.2764],\n",
            "         [ -1.7994,  -2.2217,  -2.5244,  ...,  -2.8762,  -2.8105,  -1.8495]],\n",
            "\n",
            "        [[ -2.7412,  -2.6881,  -4.5380,  ...,  -1.3760,  -1.4908,  -3.2869],\n",
            "         [ -7.4994,  -5.9507,  -6.5782,  ...,  -6.0913,  -4.4254,  -5.7961],\n",
            "         [ -2.8065,  -3.1147,  -8.1983,  ...,  -4.5912,  -6.6736,  -8.0355],\n",
            "         ...,\n",
            "         [ -7.0429,  -5.7465,  -5.1323,  ...,  -4.7975,  -7.4094,  -0.9932],\n",
            "         [ -8.5792,  -6.8962,  -7.1755,  ...,  -7.7852,  -7.8973,  -8.3583],\n",
            "         [ -1.2050,  -1.3571,  -1.4756,  ...,  -2.1409,  -2.1480,  -1.6791]],\n",
            "\n",
            "        [[ -1.6436,  -1.6445,  -4.2041,  ...,  -1.5592,  -1.5556,  -1.2161],\n",
            "         [ -8.1325,  -5.0631,  -6.3445,  ...,  -6.7815,  -6.6831,  -5.1260],\n",
            "         [ -2.5639,  -2.9014,  -8.9204,  ...,  -6.0321,  -7.9642,  -8.3842],\n",
            "         ...,\n",
            "         [ -8.2003,  -5.7154,  -5.6497,  ...,  -5.1051,  -7.1586,  -3.3346],\n",
            "         [ -9.5985,  -7.0593,  -7.8970,  ...,  -7.5400,  -7.1287,  -8.3978],\n",
            "         [ -2.3932,  -3.1336,  -4.2637,  ...,  -4.4942,  -3.3256,  -2.3765]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.9526,  -3.3896,  -4.4356,  ...,  -1.7833,  -1.9869,  -3.9209],\n",
            "         [ -6.2756,  -5.9500,  -5.9884,  ...,  -5.1321,  -3.8711,  -5.5431],\n",
            "         [ -3.2362,  -3.2865,  -6.5115,  ...,  -4.2163,  -5.3238,  -6.7547],\n",
            "         ...,\n",
            "         [ -5.6571,  -5.1078,  -4.8903,  ...,  -4.5816,  -5.9673,  -1.0617],\n",
            "         [ -6.7991,  -6.6139,  -6.1887,  ...,  -6.4153,  -6.3745,  -6.8908],\n",
            "         [ -0.7507,  -0.8188,  -0.7771,  ...,  -1.7265,  -1.5656,  -1.3968]],\n",
            "\n",
            "        [[ -1.4416,  -1.5115,  -4.6253,  ...,  -1.6869,  -1.8229,  -0.9813],\n",
            "         [ -8.8202,  -5.4713,  -6.9465,  ...,  -7.4106,  -7.6300,  -5.5778],\n",
            "         [ -2.6505,  -2.9889,  -9.8747,  ...,  -6.6545,  -9.0190,  -9.2161],\n",
            "         ...,\n",
            "         [ -9.0958,  -6.1189,  -6.2918,  ...,  -5.6456,  -7.8775,  -3.9387],\n",
            "         [-10.6349,  -7.7759,  -8.8440,  ...,  -8.0318,  -7.5404,  -9.1585],\n",
            "         [ -2.3832,  -3.3847,  -4.8552,  ...,  -5.1813,  -3.6085,  -2.5730]],\n",
            "\n",
            "        [[ -2.2683,  -2.1468,  -4.0577,  ...,  -1.3283,  -1.2667,  -2.1687],\n",
            "         [ -7.3624,  -5.1564,  -5.8076,  ...,  -6.1226,  -4.9721,  -4.9909],\n",
            "         [ -2.6191,  -2.8745,  -7.8708,  ...,  -4.8820,  -6.6555,  -7.4972],\n",
            "         ...,\n",
            "         [ -7.0112,  -5.2385,  -4.8836,  ...,  -4.5700,  -6.7603,  -1.6970],\n",
            "         [ -8.3357,  -6.4008,  -6.7700,  ...,  -7.2672,  -7.1897,  -7.7558],\n",
            "         [ -1.9242,  -2.3516,  -2.6113,  ...,  -2.9662,  -2.8222,  -1.9172]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.0026,  1.5301, -0.4309,  ...,  0.5427,  0.7678,  1.7325],\n",
            "        [ 0.4811,  1.0227, -0.6879,  ...,  1.2553,  1.0727,  1.7128],\n",
            "        [ 0.7671,  1.2845, -0.5129,  ...,  0.8189,  0.7957,  1.6354],\n",
            "        ...,\n",
            "        [ 2.0937,  2.3319,  0.1298,  ..., -1.2664,  0.6664,  1.6935],\n",
            "        [ 1.9082,  2.2268,  0.0987,  ..., -0.9555,  0.6735,  1.6604],\n",
            "        [ 1.8744,  2.1562,  0.1078,  ..., -0.9851,  0.6253,  1.5946]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.0026e+00,  1.5301e+00, -4.3086e-01,  ...,  2.4120e+00,\n",
            "           2.4705e+00,  1.4158e+00],\n",
            "         [-4.8821e+00, -1.9469e+00, -2.4106e+00,  ..., -3.0460e+00,\n",
            "          -1.7300e+00, -1.8430e+00],\n",
            "         [ 6.2802e-01,  6.9749e-01, -4.8626e+00,  ..., -1.7291e+00,\n",
            "          -3.7133e+00, -4.7780e+00],\n",
            "         ...,\n",
            "         [-4.5457e+00, -2.0300e+00, -1.3551e+00,  ..., -1.2729e+00,\n",
            "          -3.8904e+00,  1.9548e+00],\n",
            "         [-6.0899e+00, -3.3785e+00, -3.5746e+00,  ..., -4.5231e+00,\n",
            "          -4.3820e+00, -5.1414e+00],\n",
            "         [ 1.3936e+00,  1.3345e+00,  1.3017e+00,  ...,  5.4270e-01,\n",
            "           7.6785e-01,  1.7325e+00]],\n",
            "\n",
            "        [[ 4.8112e-01,  1.0227e+00, -6.8790e-01,  ...,  2.2598e+00,\n",
            "           1.9936e+00,  4.5269e-01],\n",
            "         [-4.4198e+00, -2.2153e+00, -2.6380e+00,  ..., -2.5241e+00,\n",
            "          -1.1477e+00, -2.1245e+00],\n",
            "         [ 3.2386e-01,  4.8172e-01, -4.4087e+00,  ..., -1.0790e+00,\n",
            "          -3.3097e+00, -4.4041e+00],\n",
            "         ...,\n",
            "         [-3.9768e+00, -2.0816e+00, -1.3004e+00,  ..., -1.1703e+00,\n",
            "          -3.9062e+00,  2.3613e+00],\n",
            "         [-5.4884e+00, -3.2206e+00, -3.3465e+00,  ..., -4.1167e+00,\n",
            "          -4.3646e+00, -4.7767e+00],\n",
            "         [ 1.6837e+00,  1.9600e+00,  2.0069e+00,  ...,  1.2553e+00,\n",
            "           1.0727e+00,  1.7128e+00]],\n",
            "\n",
            "        [[ 7.6709e-01,  1.2845e+00, -5.1287e-01,  ...,  2.3246e+00,\n",
            "           2.2639e+00,  9.8402e-01],\n",
            "         [-4.5700e+00, -1.9893e+00, -2.4000e+00,  ..., -2.7551e+00,\n",
            "          -1.4283e+00, -1.8821e+00],\n",
            "         [ 4.6765e-01,  5.6109e-01, -4.5224e+00,  ..., -1.3493e+00,\n",
            "          -3.4126e+00, -4.4627e+00],\n",
            "         ...,\n",
            "         [-4.1445e+00, -1.9614e+00, -1.2721e+00,  ..., -1.1747e+00,\n",
            "          -3.7514e+00,  2.1232e+00],\n",
            "         [-5.6112e+00, -3.1990e+00, -3.3438e+00,  ..., -4.1885e+00,\n",
            "          -4.2171e+00, -4.7973e+00],\n",
            "         [ 1.4461e+00,  1.4781e+00,  1.4952e+00,  ...,  8.1892e-01,\n",
            "           7.9574e-01,  1.6354e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.0937e+00,  2.3319e+00,  1.2981e-01,  ...,  1.9609e+00,\n",
            "           2.4617e+00,  3.0144e+00],\n",
            "         [-4.8473e+00, -1.3512e+00, -2.1423e+00,  ..., -3.5596e+00,\n",
            "          -2.9996e+00, -1.2249e+00],\n",
            "         [ 1.0746e+00,  9.6227e-01, -4.9165e+00,  ..., -2.8503e+00,\n",
            "          -4.3496e+00, -4.6755e+00],\n",
            "         ...,\n",
            "         [-4.9809e+00, -2.0290e+00, -1.4194e+00,  ..., -1.8197e+00,\n",
            "          -3.4230e+00,  5.5202e-01],\n",
            "         [-6.4760e+00, -3.5002e+00, -3.8673e+00,  ..., -4.3228e+00,\n",
            "          -3.2793e+00, -4.6811e+00],\n",
            "         [ 1.2501e+00,  6.9050e-01, -6.1957e-03,  ..., -1.2664e+00,\n",
            "           6.6644e-01,  1.6935e+00]],\n",
            "\n",
            "        [[ 1.9082e+00,  2.2268e+00,  9.8732e-02,  ...,  2.0579e+00,\n",
            "           2.5261e+00,  2.7610e+00],\n",
            "         [-4.8747e+00, -1.3621e+00, -2.1474e+00,  ..., -3.4625e+00,\n",
            "          -2.7895e+00, -1.2844e+00],\n",
            "         [ 1.0499e+00,  9.5411e-01, -4.9186e+00,  ..., -2.7090e+00,\n",
            "          -4.1942e+00, -4.7272e+00],\n",
            "         ...,\n",
            "         [-4.8986e+00, -2.0649e+00, -1.3775e+00,  ..., -1.6817e+00,\n",
            "          -3.4535e+00,  7.2673e-01],\n",
            "         [-6.4420e+00, -3.4331e+00, -3.7867e+00,  ..., -4.4079e+00,\n",
            "          -3.5360e+00, -4.8230e+00],\n",
            "         [ 1.1754e+00,  7.6272e-01,  1.5128e-01,  ..., -9.5554e-01,\n",
            "           6.7353e-01,  1.6604e+00]],\n",
            "\n",
            "        [[ 1.8744e+00,  2.1562e+00,  1.0782e-01,  ...,  1.9602e+00,\n",
            "           2.4121e+00,  2.7004e+00],\n",
            "         [-4.6652e+00, -1.2974e+00, -2.0674e+00,  ..., -3.3418e+00,\n",
            "          -2.7252e+00, -1.2148e+00],\n",
            "         [ 1.0058e+00,  9.1108e-01, -4.6990e+00,  ..., -2.6179e+00,\n",
            "          -4.0500e+00, -4.4984e+00],\n",
            "         ...,\n",
            "         [-4.6903e+00, -1.9689e+00, -1.3283e+00,  ..., -1.6402e+00,\n",
            "          -3.2852e+00,  6.6735e-01],\n",
            "         [-6.1467e+00, -3.2965e+00, -3.6385e+00,  ..., -4.1803e+00,\n",
            "          -3.3152e+00, -4.5613e+00],\n",
            "         [ 1.1441e+00,  7.0741e-01,  9.4031e-02,  ..., -9.8508e-01,\n",
            "           6.2527e-01,  1.5946e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.2521,  -2.1329,  -4.4557,  ...,  -1.2020,  -1.2372,  -2.1672],\n",
            "         [ -8.1368,  -5.6100,  -6.4355,  ...,  -6.6600,  -5.4378,  -5.4259],\n",
            "         [ -2.6267,  -2.9656,  -8.8875,  ...,  -5.3431,  -7.4211,  -8.3609],\n",
            "         ...,\n",
            "         [ -7.8005,  -5.6931,  -5.3800,  ...,  -4.8868,  -7.5982,  -1.6281],\n",
            "         [ -9.3446,  -7.0416,  -7.5995,  ...,  -8.1370,  -8.0898,  -8.7243],\n",
            "         [ -1.8612,  -2.3286,  -2.7232,  ...,  -3.0712,  -2.9399,  -1.8504]],\n",
            "\n",
            "        [[ -2.5838,  -2.5186,  -4.4275,  ...,  -1.3251,  -1.4061,  -3.0063],\n",
            "         [ -7.4847,  -5.7566,  -6.3775,  ...,  -6.1090,  -4.5474,  -5.5835],\n",
            "         [ -2.7410,  -3.0596,  -8.1483,  ...,  -4.6639,  -6.7094,  -7.8631],\n",
            "         ...,\n",
            "         [ -7.0416,  -5.6229,  -5.0399,  ...,  -4.7552,  -7.3059,  -1.0977],\n",
            "         [ -8.5533,  -6.7620,  -7.0861,  ...,  -7.7016,  -7.7643,  -8.2357],\n",
            "         [ -1.3811,  -1.5813,  -1.7327,  ...,  -2.3296,  -2.3270,  -1.7462]],\n",
            "\n",
            "        [[ -2.3771,  -2.2600,  -4.3405,  ...,  -1.2358,  -1.2625,  -2.4884],\n",
            "         [ -7.7142,  -5.5338,  -6.2276,  ...,  -6.3154,  -4.9548,  -5.3545],\n",
            "         [ -2.6766,  -2.9834,  -8.3500,  ...,  -4.9097,  -6.9390,  -7.9351],\n",
            "         ...,\n",
            "         [ -7.2888,  -5.5059,  -5.0997,  ...,  -4.7351,  -7.2779,  -1.3492],\n",
            "         [ -8.7554,  -6.7435,  -7.1714,  ...,  -7.7489,  -7.7435,  -8.2696],\n",
            "         [ -1.6982,  -2.0664,  -2.3324,  ...,  -2.7414,  -2.7307,  -1.8369]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.5589,  -1.5861,  -4.3738,  ...,  -1.5709,  -1.6614,  -1.1123],\n",
            "         [ -8.4998,  -5.2693,  -6.6459,  ...,  -7.0914,  -7.1227,  -5.3516],\n",
            "         [ -2.5780,  -2.9558,  -9.4201,  ...,  -6.3821,  -8.4727,  -8.8022],\n",
            "         ...,\n",
            "         [ -8.6335,  -5.9470,  -5.9231,  ...,  -5.3515,  -7.5461,  -3.5747],\n",
            "         [-10.1286,  -7.4182,  -8.3709,  ...,  -7.8546,  -7.4024,  -8.8079],\n",
            "         [ -2.4025,  -3.2275,  -4.5098,  ...,  -4.7982,  -3.4566,  -2.4332]],\n",
            "\n",
            "        [[ -1.6674,  -1.6541,  -4.3087,  ...,  -1.4777,  -1.5160,  -1.2372],\n",
            "         [ -8.4504,  -5.2431,  -6.5548,  ...,  -6.9981,  -6.8317,  -5.2827],\n",
            "         [ -2.5258,  -2.9268,  -9.3260,  ...,  -6.2446,  -8.2364,  -8.7254],\n",
            "         ...,\n",
            "         [ -8.4743,  -5.9459,  -5.7849,  ...,  -5.2173,  -7.4957,  -3.2715],\n",
            "         [-10.0177,  -7.3141,  -8.1941,  ...,  -7.9435,  -7.5781,  -8.8213],\n",
            "         [ -2.4002,  -3.1182,  -4.2561,  ...,  -4.4911,  -3.3687,  -2.3379]],\n",
            "\n",
            "        [[ -1.6648,  -1.6579,  -4.1924,  ...,  -1.5144,  -1.5385,  -1.2403],\n",
            "         [ -8.2044,  -5.1115,  -6.3676,  ...,  -6.8164,  -6.6757,  -5.1554],\n",
            "         [ -2.5334,  -2.9030,  -8.9993,  ...,  -6.0926,  -8.0006,  -8.4391],\n",
            "         ...,\n",
            "         [ -8.2296,  -5.7829,  -5.6285,  ...,  -5.1148,  -7.2357,  -3.2733],\n",
            "         [ -9.6859,  -7.1106,  -7.9387,  ...,  -7.6550,  -7.2657,  -8.5020],\n",
            "         [ -2.3951,  -3.1067,  -4.2062,  ...,  -4.4597,  -3.3253,  -2.3461]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.1278,  0.1495, -1.1606,  ...,  1.8729,  1.5716,  2.1472],\n",
            "        [ 0.3206,  0.9420, -0.9162,  ...,  1.7351,  1.4603,  2.0647],\n",
            "        [ 0.4913,  0.9360, -0.5433,  ...,  1.0260,  0.8508,  1.4494],\n",
            "        ...,\n",
            "        [ 2.3663,  2.4854,  0.1981,  ..., -1.6843,  0.7063,  1.7758],\n",
            "        [ 0.1273,  0.4090, -1.0732,  ...,  1.8846,  1.5792,  2.1492],\n",
            "        [ 0.1969,  0.7306, -0.9317,  ...,  1.8312,  1.5182,  2.0705]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.1278,  0.1495, -1.1606,  ...,  1.7647,  1.0303, -0.5664],\n",
            "         [-3.4761, -2.6054, -2.8135,  ..., -1.7270, -0.9494, -2.3360],\n",
            "         [-0.2719,  0.2317, -3.3320,  ..., -0.8487, -2.5182, -3.5453],\n",
            "         ...,\n",
            "         [-2.8045, -1.6770, -1.6021,  ..., -1.1722, -3.2064,  2.5384],\n",
            "         [-4.0333, -3.3167, -2.9846,  ..., -3.2050, -3.6237, -3.7699],\n",
            "         [ 2.4833,  2.9756,  2.8925,  ...,  1.8729,  1.5716,  2.1472]],\n",
            "\n",
            "        [[ 0.3206,  0.9420, -0.9162,  ...,  2.4503,  1.9768,  0.1074],\n",
            "         [-4.8993, -2.6645, -3.2053,  ..., -2.5935, -1.0560, -2.6393],\n",
            "         [ 0.2221,  0.5534, -4.9196,  ..., -1.1164, -3.6080, -4.9808],\n",
            "         ...,\n",
            "         [-4.3564, -2.3901, -1.5152,  ..., -1.2499, -4.5166,  2.9179],\n",
            "         [-6.0858, -3.6923, -3.8047,  ..., -4.6564, -5.0896, -5.4036],\n",
            "         [ 2.1328,  2.6208,  2.7139,  ...,  1.7351,  1.4603,  2.0647]],\n",
            "\n",
            "        [[ 0.4913,  0.9360, -0.5433,  ...,  2.0099,  1.7620,  0.4457],\n",
            "         [-3.8420, -1.8997, -2.2899,  ..., -2.2146, -1.0694, -1.8222],\n",
            "         [ 0.2773,  0.4337, -3.7893,  ..., -0.9594, -2.9025, -3.7142],\n",
            "         ...,\n",
            "         [-3.3701, -1.8182, -1.1066,  ..., -1.0392, -3.3377,  2.0411],\n",
            "         [-4.7108, -2.8070, -2.8847,  ..., -3.4674, -3.7316, -4.0404],\n",
            "         [ 1.4407,  1.6337,  1.6587,  ...,  1.0260,  0.8508,  1.4494]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.3663,  2.4854,  0.1981,  ...,  1.8397,  2.3668,  3.3961],\n",
            "         [-4.9041, -1.4404, -2.1401,  ..., -3.7199, -3.3129, -1.1631],\n",
            "         [ 1.1734,  1.0016, -5.0158,  ..., -3.1214, -4.6610, -4.6751],\n",
            "         ...,\n",
            "         [-5.1548, -2.0704, -1.4408,  ..., -2.0537, -3.4770,  0.3672],\n",
            "         [-6.6582, -3.6910, -4.0220,  ..., -4.3011, -3.0413, -4.6478],\n",
            "         [ 1.4108,  0.6517, -0.1450,  ..., -1.6843,  0.7063,  1.7758]],\n",
            "\n",
            "        [[ 0.1273,  0.4090, -1.0732,  ...,  1.9655,  1.3201, -0.3913],\n",
            "         [-3.9398, -2.6213, -2.9704,  ..., -1.9740, -0.9534, -2.4916],\n",
            "         [-0.1305,  0.3775, -3.8814,  ..., -0.9088, -2.8687, -4.0247],\n",
            "         ...,\n",
            "         [-3.2900, -1.9661, -1.5800,  ..., -1.1670, -3.6598,  2.7078],\n",
            "         [-4.7364, -3.4289, -3.2365,  ..., -3.6810, -4.1761, -4.3053],\n",
            "         [ 2.3929,  2.8959,  2.9116,  ...,  1.8846,  1.5792,  2.1492]],\n",
            "\n",
            "        [[ 0.1969,  0.7306, -0.9317,  ...,  2.1971,  1.6922, -0.1290],\n",
            "         [-4.4643, -2.6059, -3.1370,  ..., -2.2797, -0.9504, -2.6110],\n",
            "         [ 0.0965,  0.5523, -4.5129,  ..., -0.9597, -3.2730, -4.5821],\n",
            "         ...,\n",
            "         [-3.8520, -2.2866, -1.5058,  ..., -1.1804, -4.1765,  2.8791],\n",
            "         [-5.5072, -3.5128, -3.5225,  ..., -4.1924, -4.7807, -4.8814],\n",
            "         [ 2.2503,  2.7428,  2.8123,  ...,  1.8312,  1.5182,  2.0705]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.9962,  -3.5131,  -4.7350,  ...,  -1.7618,  -2.0302,  -4.0854],\n",
            "         [ -6.6001,  -6.2679,  -6.3878,  ...,  -5.2535,  -4.0099,  -5.8551],\n",
            "         [ -3.3959,  -3.4309,  -6.9064,  ...,  -4.3752,  -5.5787,  -7.0643],\n",
            "         ...,\n",
            "         [ -5.9285,  -5.3396,  -5.1764,  ...,  -4.6987,  -6.2669,  -0.9806],\n",
            "         [ -7.1573,  -6.9793,  -6.5590,  ...,  -6.7315,  -6.6842,  -7.2890],\n",
            "         [ -0.6407,  -0.6870,  -0.6818,  ...,  -1.6536,  -1.4889,  -1.3719]],\n",
            "\n",
            "        [[ -2.8347,  -2.8274,  -4.9312,  ...,  -1.3145,  -1.5523,  -3.6292],\n",
            "         [ -8.0547,  -6.4339,  -7.2203,  ...,  -6.3583,  -4.5851,  -6.3758],\n",
            "         [ -2.9332,  -3.2160,  -8.9346,  ...,  -4.8812,  -7.1371,  -8.7174],\n",
            "         ...,\n",
            "         [ -7.5118,  -6.1595,  -5.5303,  ...,  -5.0147,  -8.0457,  -0.8187],\n",
            "         [ -9.2412,  -7.4617,  -7.8198,  ...,  -8.4213,  -8.6187,  -9.1402],\n",
            "         [ -1.0226,  -1.1487,  -1.3012,  ...,  -2.0297,  -2.0688,  -1.6719]],\n",
            "\n",
            "        [[ -2.4866,  -2.4428,  -3.9946,  ...,  -1.4251,  -1.4414,  -2.8349],\n",
            "         [ -6.8199,  -5.2785,  -5.7413,  ...,  -5.6496,  -4.2728,  -5.1028],\n",
            "         [ -2.7006,  -2.9451,  -7.2406,  ...,  -4.3944,  -6.1059,  -6.9949],\n",
            "         ...,\n",
            "         [ -6.3480,  -5.1971,  -4.5580,  ...,  -4.4743,  -6.5411,  -1.2395],\n",
            "         [ -7.6886,  -6.1858,  -6.3361,  ...,  -6.9025,  -6.9350,  -7.3211],\n",
            "         [ -1.5371,  -1.7451,  -1.7926,  ...,  -2.4090,  -2.3526,  -1.8312]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.4162,  -1.5084,  -4.4583,  ...,  -1.7094,  -1.9091,  -0.9445],\n",
            "         [ -8.6866,  -5.4342,  -6.7965,  ...,  -7.2690,  -7.5888,  -5.5036],\n",
            "         [ -2.6091,  -2.9922,  -9.6721,  ...,  -6.6705,  -8.9369,  -9.0156],\n",
            "         ...,\n",
            "         [ -8.9373,  -6.0641,  -6.0971,  ...,  -5.6028,  -7.7529,  -3.9734],\n",
            "         [-10.4407,  -7.6847,  -8.6783,  ...,  -7.8501,  -7.3171,  -8.9884],\n",
            "         [ -2.3717,  -3.3421,  -4.8014,  ...,  -5.2333,  -3.5696,  -2.5648]],\n",
            "\n",
            "        [[ -2.9916,  -3.2832,  -4.7834,  ...,  -1.6399,  -1.8636,  -3.9933],\n",
            "         [ -7.0587,  -6.3135,  -6.6806,  ...,  -5.5795,  -4.1371,  -6.0935],\n",
            "         [ -3.2494,  -3.3147,  -7.5916,  ...,  -4.5142,  -6.0524,  -7.6266],\n",
            "         ...,\n",
            "         [ -6.4089,  -5.6583,  -5.2902,  ...,  -4.7725,  -6.8435,  -0.8941],\n",
            "         [ -7.8553,  -7.1211,  -6.9467,  ...,  -7.2864,  -7.3598,  -7.9072],\n",
            "         [ -0.7261,  -0.7962,  -0.7986,  ...,  -1.7208,  -1.6045,  -1.4527]],\n",
            "\n",
            "        [[ -2.9364,  -3.0060,  -4.7994,  ...,  -1.4988,  -1.6724,  -3.8160],\n",
            "         [ -7.5976,  -6.3425,  -7.0048,  ...,  -5.9756,  -4.3151,  -6.2980],\n",
            "         [ -3.0368,  -3.1843,  -8.3807,  ...,  -4.6555,  -6.6377,  -8.2691],\n",
            "         ...,\n",
            "         [ -6.9853,  -6.0232,  -5.3736,  ...,  -4.8763,  -7.5412,  -0.8078],\n",
            "         [ -8.6405,  -7.2494,  -7.3903,  ...,  -7.8883,  -8.1454,  -8.5684],\n",
            "         [ -0.8829,  -0.9938,  -1.0555,  ...,  -1.8646,  -1.8465,  -1.6165]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.4031,  0.9054, -0.7429,  ...,  1.3904,  1.1525,  1.7113],\n",
            "        [ 1.8820,  2.1326,  0.1590,  ..., -0.9450,  0.6198,  1.5972],\n",
            "        [ 0.1750,  0.5980, -1.1088,  ...,  1.9500,  1.6768,  2.2332],\n",
            "        ...,\n",
            "        [ 0.2194,  0.5740, -0.8857,  ...,  1.6470,  1.3537,  1.8444],\n",
            "        [ 2.4665,  2.5629,  0.2474,  ..., -1.7878,  0.7410,  1.8355],\n",
            "        [ 2.0716,  2.2129,  0.1960,  ..., -1.2995,  0.5975,  1.6123]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 4.0306e-01,  9.0540e-01, -7.4293e-01,  ...,  2.2067e+00,\n",
            "           1.8163e+00,  2.0939e-01],\n",
            "         [-4.2938e+00, -2.2695e+00, -2.7398e+00,  ..., -2.3363e+00,\n",
            "          -1.0116e+00, -2.2364e+00],\n",
            "         [ 2.2360e-01,  4.7889e-01, -4.2828e+00,  ..., -1.0215e+00,\n",
            "          -3.2090e+00, -4.2367e+00],\n",
            "         ...,\n",
            "         [-3.7704e+00, -2.0998e+00, -1.2877e+00,  ..., -1.1395e+00,\n",
            "          -3.8886e+00,  2.4865e+00],\n",
            "         [-5.3041e+00, -3.2080e+00, -3.3006e+00,  ..., -3.9885e+00,\n",
            "          -4.3641e+00, -4.6430e+00],\n",
            "         [ 1.7758e+00,  2.1447e+00,  2.2067e+00,  ...,  1.3904e+00,\n",
            "           1.1525e+00,  1.7113e+00]],\n",
            "\n",
            "        [[ 1.8820e+00,  2.1326e+00,  1.5896e-01,  ...,  2.0327e+00,\n",
            "           2.4005e+00,  2.6711e+00],\n",
            "         [-4.6846e+00, -1.3179e+00, -2.0601e+00,  ..., -3.3158e+00,\n",
            "          -2.6847e+00, -1.2486e+00],\n",
            "         [ 1.0400e+00,  8.9678e-01, -4.7128e+00,  ..., -2.6641e+00,\n",
            "          -4.0354e+00, -4.4859e+00],\n",
            "         ...,\n",
            "         [-4.6529e+00, -2.0120e+00, -1.2723e+00,  ..., -1.6210e+00,\n",
            "          -3.3051e+00,  7.0316e-01],\n",
            "         [-6.1544e+00, -3.2985e+00, -3.6354e+00,  ..., -4.2110e+00,\n",
            "          -3.3805e+00, -4.6047e+00],\n",
            "         [ 1.1241e+00,  7.4072e-01,  1.5488e-01,  ..., -9.4505e-01,\n",
            "           6.1981e-01,  1.5972e+00]],\n",
            "\n",
            "        [[ 1.7502e-01,  5.9802e-01, -1.1088e+00,  ...,  2.1774e+00,\n",
            "           1.5967e+00, -2.8863e-01],\n",
            "         [-4.4808e+00, -2.7771e+00, -3.2845e+00,  ..., -2.2426e+00,\n",
            "          -1.0030e+00, -2.7463e+00],\n",
            "         [-6.4056e-02,  4.7968e-01, -4.4964e+00,  ..., -1.0293e+00,\n",
            "          -3.2707e+00, -4.5798e+00],\n",
            "         ...,\n",
            "         [-3.8223e+00, -2.2723e+00, -1.6627e+00,  ..., -1.2440e+00,\n",
            "          -4.1866e+00,  2.9978e+00],\n",
            "         [-5.4908e+00, -3.6873e+00, -3.5962e+00,  ..., -4.2565e+00,\n",
            "          -4.7939e+00, -4.9333e+00],\n",
            "         [ 2.4600e+00,  3.0392e+00,  3.0825e+00,  ...,  1.9500e+00,\n",
            "           1.6768e+00,  2.2332e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.1943e-01,  5.7401e-01, -8.8567e-01,  ...,  1.9504e+00,\n",
            "           1.4220e+00, -2.1396e-01],\n",
            "         [-3.8786e+00, -2.3539e+00, -2.7818e+00,  ..., -1.9659e+00,\n",
            "          -8.8569e-01, -2.3114e+00],\n",
            "         [-1.1369e-03,  4.7047e-01, -3.8770e+00,  ..., -8.7553e-01,\n",
            "          -2.8350e+00, -3.8939e+00],\n",
            "         ...,\n",
            "         [-3.2566e+00, -1.9780e+00, -1.3744e+00,  ..., -1.1064e+00,\n",
            "          -3.5795e+00,  2.5678e+00],\n",
            "         [-4.7045e+00, -3.1779e+00, -3.1138e+00,  ..., -3.5422e+00,\n",
            "          -4.1266e+00, -4.1604e+00],\n",
            "         [ 2.0677e+00,  2.5127e+00,  2.5329e+00,  ...,  1.6470e+00,\n",
            "           1.3537e+00,  1.8444e+00]],\n",
            "\n",
            "        [[ 2.4665e+00,  2.5629e+00,  2.4743e-01,  ...,  1.8796e+00,\n",
            "           2.3766e+00,  3.5251e+00],\n",
            "         [-5.0079e+00, -1.4861e+00, -2.1709e+00,  ..., -3.7982e+00,\n",
            "          -3.4112e+00, -1.1911e+00],\n",
            "         [ 1.2354e+00,  1.0093e+00, -5.1327e+00,  ..., -3.2564e+00,\n",
            "          -4.7936e+00, -4.7676e+00],\n",
            "         ...,\n",
            "         [-5.2768e+00, -2.1362e+00, -1.4447e+00,  ..., -2.1228e+00,\n",
            "          -3.5637e+00,  3.4352e-01],\n",
            "         [-6.8239e+00, -3.7916e+00, -4.1218e+00,  ..., -4.4002e+00,\n",
            "          -3.0795e+00, -4.7547e+00],\n",
            "         [ 1.4544e+00,  6.7800e-01, -1.4951e-01,  ..., -1.7878e+00,\n",
            "           7.4098e-01,  1.8355e+00]],\n",
            "\n",
            "        [[ 2.0716e+00,  2.2129e+00,  1.9599e-01,  ...,  1.8750e+00,\n",
            "           2.2663e+00,  2.9306e+00],\n",
            "         [-4.5694e+00, -1.3033e+00, -2.0114e+00,  ..., -3.3809e+00,\n",
            "          -2.8904e+00, -1.1520e+00],\n",
            "         [ 1.0621e+00,  8.9662e-01, -4.6225e+00,  ..., -2.7814e+00,\n",
            "          -4.1594e+00, -4.3336e+00],\n",
            "         ...,\n",
            "         [-4.6565e+00, -1.9452e+00, -1.2931e+00,  ..., -1.7699e+00,\n",
            "          -3.2033e+00,  4.8242e-01],\n",
            "         [-6.0851e+00, -3.3329e+00, -3.6641e+00,  ..., -4.0174e+00,\n",
            "          -3.0144e+00, -4.3489e+00],\n",
            "         [ 1.2138e+00,  6.4201e-01, -2.3977e-02,  ..., -1.2995e+00,\n",
            "           5.9752e-01,  1.6123e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.6282,  -2.6329,  -4.4238,  ...,  -1.3751,  -1.5114,  -3.2576],\n",
            "         [ -7.3251,  -5.8078,  -6.4207,  ...,  -5.9182,  -4.3393,  -5.7034],\n",
            "         [ -2.8077,  -3.0594,  -7.9637,  ...,  -4.6034,  -6.5368,  -7.7037],\n",
            "         ...,\n",
            "         [ -6.8017,  -5.6381,  -4.9686,  ...,  -4.7214,  -7.2164,  -0.9805],\n",
            "         [ -8.3354,  -6.7463,  -6.9815,  ...,  -7.5703,  -7.6919,  -8.1100],\n",
            "         [ -1.2555,  -1.3936,  -1.4743,  ...,  -2.1915,  -2.1753,  -1.7557]],\n",
            "\n",
            "        [[ -1.6467,  -1.6751,  -4.1149,  ...,  -1.4576,  -1.5387,  -1.2410],\n",
            "         [ -8.2133,  -5.1255,  -6.3340,  ...,  -6.8060,  -6.6239,  -5.1607],\n",
            "         [ -2.4887,  -2.9109,  -8.9867,  ...,  -6.1543,  -7.9746,  -8.3979],\n",
            "         ...,\n",
            "         [ -8.1816,  -5.8197,  -5.5461,  ...,  -5.1112,  -7.2443,  -3.2089],\n",
            "         [ -9.6832,  -7.1062,  -7.9092,  ...,  -7.7012,  -7.3197,  -8.5167],\n",
            "         [ -2.4046,  -3.0670,  -4.1190,  ...,  -4.4353,  -3.3194,  -2.3148]],\n",
            "\n",
            "        [[ -3.0122,  -3.2323,  -5.0555,  ...,  -1.5371,  -1.7718,  -4.0625],\n",
            "         [ -7.6680,  -6.6075,  -7.2312,  ...,  -5.9571,  -4.3714,  -6.5202],\n",
            "         [ -3.2513,  -3.3507,  -8.4431,  ...,  -4.7438,  -6.6392,  -8.3536],\n",
            "         ...,\n",
            "         [ -7.0095,  -6.1027,  -5.6094,  ...,  -4.9585,  -7.5550,  -0.7761],\n",
            "         [ -8.6781,  -7.5176,  -7.5429,  ...,  -7.9710,  -8.1623,  -8.7072],\n",
            "         [ -0.7273,  -0.7912,  -0.8642,  ...,  -1.7645,  -1.6917,  -1.5407]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.8043,  -2.9864,  -4.4578,  ...,  -1.5989,  -1.7453,  -3.6939],\n",
            "         [ -6.9024,  -5.9143,  -6.3539,  ...,  -5.5152,  -4.0530,  -5.7913],\n",
            "         [ -3.0249,  -3.0899,  -7.4491,  ...,  -4.4249,  -6.0024,  -7.3739],\n",
            "         ...,\n",
            "         [ -6.2803,  -5.5384,  -4.9465,  ...,  -4.6558,  -6.7468,  -0.9122],\n",
            "         [ -7.7282,  -6.7383,  -6.6859,  ...,  -7.0916,  -7.2940,  -7.6404],\n",
            "         [ -0.9561,  -1.0477,  -1.0392,  ...,  -1.9024,  -1.8136,  -1.6355]],\n",
            "\n",
            "        [[ -1.3665,  -1.4791,  -4.4916,  ...,  -1.7069,  -1.9803,  -0.8927],\n",
            "         [ -8.8409,  -5.5280,  -6.9099,  ...,  -7.3847,  -7.7680,  -5.6088],\n",
            "         [ -2.5977,  -3.0327,  -9.8718,  ...,  -6.8429,  -9.1505,  -9.1853],\n",
            "         ...,\n",
            "         [ -9.1098,  -6.1782,  -6.1838,  ...,  -5.7093,  -7.9206,  -4.0742],\n",
            "         [-10.6569,  -7.8336,  -8.8609,  ...,  -7.9867,  -7.4364,  -9.1725],\n",
            "         [ -2.3786,  -3.3639,  -4.8886,  ...,  -5.3743,  -3.6159,  -2.5822]],\n",
            "\n",
            "        [[ -1.5295,  -1.6078,  -4.1339,  ...,  -1.5811,  -1.7238,  -1.1002],\n",
            "         [ -8.1705,  -5.1240,  -6.3413,  ...,  -6.8369,  -6.8805,  -5.1828],\n",
            "         [ -2.5389,  -2.9241,  -8.9523,  ...,  -6.2375,  -8.1495,  -8.3644],\n",
            "         ...,\n",
            "         [ -8.2576,  -5.7659,  -5.6230,  ...,  -5.2260,  -7.1934,  -3.5484],\n",
            "         [ -9.6862,  -7.1536,  -7.9940,  ...,  -7.4735,  -7.0045,  -8.3797],\n",
            "         [ -2.3873,  -3.1787,  -4.3538,  ...,  -4.7556,  -3.3926,  -2.4186]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.8061,  2.0398,  0.1656,  ..., -0.8448,  0.5898,  1.5400],\n",
            "        [ 0.8658,  1.3230, -0.5218,  ...,  0.8206,  0.8104,  1.6546],\n",
            "        [ 0.6096,  1.0918, -0.7076,  ...,  1.2271,  1.0753,  1.7253],\n",
            "        ...,\n",
            "        [ 2.1815,  2.2789,  0.2337,  ..., -1.4039,  0.6214,  1.6663],\n",
            "        [ 1.7844,  2.0644,  0.1393,  ..., -0.7497,  0.6233,  1.5714],\n",
            "        [ 1.9148,  2.1683,  0.1750,  ..., -0.9016,  0.6525,  1.6425]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.8061,  2.0398,  0.1656,  ...,  2.0459,  2.3386,  2.5436],\n",
            "         [-4.5674, -1.3037, -2.0068,  ..., -3.2046, -2.5510, -1.2450],\n",
            "         [ 1.0174,  0.8666, -4.5814,  ..., -2.5744, -3.8952, -4.3472],\n",
            "         ...,\n",
            "         [-4.4786, -1.9876, -1.2142,  ..., -1.5568, -3.2239,  0.7407],\n",
            "         [-5.9660, -3.2021, -3.5189,  ..., -4.1027, -3.3613, -4.5024],\n",
            "         [ 1.0700,  0.7359,  0.1950,  ..., -0.8448,  0.5898,  1.5400]],\n",
            "\n",
            "        [[ 0.8658,  1.3230, -0.5218,  ...,  2.4636,  2.3158,  0.9963],\n",
            "         [-4.7462, -2.0751, -2.4996,  ..., -2.8090, -1.4301, -1.9981],\n",
            "         [ 0.4869,  0.5804, -4.6993,  ..., -1.4822, -3.5497, -4.5588],\n",
            "         ...,\n",
            "         [-4.2696, -2.0571, -1.2867,  ..., -1.2202, -3.9148,  2.2510],\n",
            "         [-5.8283, -3.3273, -3.4786,  ..., -4.3700, -4.3960, -4.9982],\n",
            "         [ 1.4720,  1.5392,  1.5755,  ...,  0.8206,  0.8104,  1.6546]],\n",
            "\n",
            "        [[ 0.6096,  1.0918, -0.7076,  ...,  2.3989,  2.0798,  0.5060],\n",
            "         [-4.6366, -2.2897, -2.7448,  ..., -2.6074, -1.1734, -2.2387],\n",
            "         [ 0.3414,  0.5170, -4.6268,  ..., -1.2437, -3.4791, -4.5233],\n",
            "         ...,\n",
            "         [-4.1450, -2.1805, -1.3308,  ..., -1.2206, -4.0852,  2.4899],\n",
            "         [-5.7492, -3.3667, -3.5085,  ..., -4.3374, -4.5630, -5.0132],\n",
            "         [ 1.7012,  1.9966,  2.0613,  ...,  1.2271,  1.0753,  1.7253]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.1815,  2.2789,  0.2337,  ...,  1.9265,  2.2774,  3.0721],\n",
            "         [-4.6765, -1.3526, -2.0448,  ..., -3.4814, -2.9909, -1.1817],\n",
            "         [ 1.1277,  0.9173, -4.7442,  ..., -2.9187, -4.3024, -4.4257],\n",
            "         ...,\n",
            "         [-4.7859, -2.0090, -1.3132,  ..., -1.8551, -3.2881,  0.4444],\n",
            "         [-6.2640, -3.4424, -3.7775,  ..., -4.1110, -3.0487, -4.4458],\n",
            "         [ 1.2561,  0.6534, -0.0375,  ..., -1.4039,  0.6214,  1.6663]],\n",
            "\n",
            "        [[ 1.7844,  2.0644,  0.1393,  ...,  2.1446,  2.4339,  2.5264],\n",
            "         [-4.7159, -1.3673, -2.0601,  ..., -3.2693, -2.5478, -1.3128],\n",
            "         [ 1.0303,  0.8989, -4.7349,  ..., -2.5974, -3.9663, -4.5068],\n",
            "         ...,\n",
            "         [-4.5983, -2.0674, -1.2421,  ..., -1.5639, -3.3582,  0.8328],\n",
            "         [-6.1678, -3.2934, -3.6089,  ..., -4.2747, -3.5873, -4.7135],\n",
            "         [ 1.0763,  0.7886,  0.2850,  ..., -0.7497,  0.6233,  1.5714]],\n",
            "\n",
            "        [[ 1.9148,  2.1683,  0.1750,  ...,  2.1554,  2.4757,  2.7039],\n",
            "         [-4.8502, -1.3783, -2.1182,  ..., -3.3950, -2.7000, -1.3228],\n",
            "         [ 1.0937,  0.9232, -4.8833,  ..., -2.7541, -4.1349, -4.6488],\n",
            "         ...,\n",
            "         [-4.7897, -2.1080, -1.2886,  ..., -1.6478, -3.4420,  0.7663],\n",
            "         [-6.3779, -3.4020, -3.7443,  ..., -4.3958, -3.5814, -4.8216],\n",
            "         [ 1.1288,  0.7923,  0.2179,  ..., -0.9016,  0.6525,  1.6425]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[-1.6722, -1.7134, -4.0023,  ..., -1.4197, -1.5138, -1.2843],\n",
            "         [-8.0457, -5.0569, -6.1748,  ..., -6.6702, -6.4033, -5.0729],\n",
            "         [-2.4609, -2.8865, -8.7493,  ..., -6.0400, -7.7475, -8.1751],\n",
            "         ...,\n",
            "         [-7.9568, -5.7407, -5.3821,  ..., -5.0224, -7.0763, -3.0872],\n",
            "         [-9.4442, -6.9553, -7.6868,  ..., -7.5683, -7.2136, -8.3303],\n",
            "         [-2.4083, -3.0172, -3.9729,  ..., -4.3104, -3.2625, -2.2879]],\n",
            "\n",
            "        [[-2.2998, -2.2604, -4.4289,  ..., -1.1542, -1.2767, -2.5181],\n",
            "         [-7.9117, -5.6585, -6.4067,  ..., -6.4268, -5.0226, -5.5125],\n",
            "         [-2.6786, -3.0030, -8.6064,  ..., -5.1000, -7.1423, -8.0731],\n",
            "         ...,\n",
            "         [-7.4352, -5.6405, -5.1938,  ..., -4.8380, -7.5073, -1.2633],\n",
            "         [-8.9938, -6.9107, -7.3857,  ..., -7.9878, -7.9885, -8.5126],\n",
            "         [-1.6935, -2.0442, -2.3316,  ..., -2.7972, -2.7821, -1.8597]],\n",
            "\n",
            "        [[-2.4845, -2.4939, -4.5478,  ..., -1.2391, -1.4033, -3.0143],\n",
            "         [-7.7307, -5.8755, -6.5849,  ..., -6.2454, -4.6566, -5.7590],\n",
            "         [-2.7527, -3.0688, -8.4669,  ..., -4.8817, -6.9623, -8.0436],\n",
            "         ...,\n",
            "         [-7.2391, -5.7663, -5.1709,  ..., -4.8586, -7.5683, -1.0304],\n",
            "         [-8.8433, -6.9524, -7.3486,  ..., -7.9754, -8.0462, -8.5335],\n",
            "         [-1.3929, -1.5892, -1.7789,  ..., -2.4108, -2.4079, -1.7949]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.4716, -1.5894, -4.1817,  ..., -1.5683, -1.7933, -1.0373],\n",
            "         [-8.3297, -5.2209, -6.4603,  ..., -6.9762, -7.0616, -5.2911],\n",
            "         [-2.5254, -2.9511, -9.1597,  ..., -6.4134, -8.3731, -8.5351],\n",
            "         ...,\n",
            "         [-8.4391, -5.8773, -5.7286,  ..., -5.3498, -7.3588, -3.6650],\n",
            "         [-9.9172, -7.3107, -8.1930,  ..., -7.6057, -7.1193, -8.5553],\n",
            "         [-2.3971, -3.2149, -4.4530,  ..., -4.8987, -3.4493, -2.4431]],\n",
            "\n",
            "        [[-1.7012, -1.7272, -4.0811,  ..., -1.3712, -1.4618, -1.3127],\n",
            "         [-8.2016, -5.1589, -6.2806,  ..., -6.7851, -6.4434, -5.1519],\n",
            "         [-2.4554, -2.8927, -8.9554,  ..., -6.1132, -7.8619, -8.3460],\n",
            "         ...,\n",
            "         [-8.0840, -5.8590, -5.4626,  ..., -5.0797, -7.2538, -3.0064],\n",
            "         [-9.6535, -7.0850, -7.8294,  ..., -7.7905, -7.4829, -8.5526],\n",
            "         [-2.4093, -3.0030, -3.9355,  ..., -4.2655, -3.2723, -2.2677]],\n",
            "\n",
            "        [[-1.6361, -1.6860, -4.1669,  ..., -1.3918, -1.5244, -1.2352],\n",
            "         [-8.4011, -5.2326, -6.4601,  ..., -6.9422, -6.7001, -5.2619],\n",
            "         [-2.4572, -2.9311, -9.2252,  ..., -6.3013, -8.1350, -8.5879],\n",
            "         ...,\n",
            "         [-8.3406, -5.9622, -5.6305,  ..., -5.1950, -7.4421, -3.1728],\n",
            "         [-9.9288, -7.2562, -8.0862,  ..., -7.9430, -7.5815, -8.7606],\n",
            "         [-2.4221, -3.0620, -4.1240,  ..., -4.4488, -3.3476, -2.2965]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.6137,  1.6580,  0.2315,  ..., -1.0025,  0.3827,  1.2117],\n",
            "        [ 0.6269,  0.9370, -0.3481,  ...,  0.6446,  0.5357,  1.1633],\n",
            "        [ 0.8010,  1.1848, -0.4468,  ...,  0.7316,  0.6900,  1.4563],\n",
            "        ...,\n",
            "        [ 2.2811,  2.3974,  0.2636,  ..., -1.3980,  0.6884,  1.7737],\n",
            "        [ 1.1968,  1.3737,  0.0888,  ..., -0.3982,  0.2941,  1.0262],\n",
            "        [ 2.2807,  2.3794,  0.2651,  ..., -1.4259,  0.6746,  1.7559]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.6137e+00,  1.6580e+00,  2.3151e-01,  ...,  1.4796e+00,\n",
            "           1.6810e+00,  2.2209e+00],\n",
            "         [-3.4559e+00, -9.9407e-01, -1.5668e+00,  ..., -2.5299e+00,\n",
            "          -2.1972e+00, -8.6747e-01],\n",
            "         [ 8.2526e-01,  6.2432e-01, -3.4141e+00,  ..., -2.0914e+00,\n",
            "          -3.1360e+00, -3.1454e+00],\n",
            "         ...,\n",
            "         [-3.3724e+00, -1.5082e+00, -9.1925e-01,  ..., -1.3339e+00,\n",
            "          -2.3362e+00,  4.4468e-01],\n",
            "         [-4.3958e+00, -2.4875e+00, -2.6976e+00,  ..., -2.9025e+00,\n",
            "          -2.1994e+00, -3.1647e+00],\n",
            "         [ 9.3248e-01,  4.7719e-01, -1.0267e-01,  ..., -1.0025e+00,\n",
            "           3.8272e-01,  1.2117e+00]],\n",
            "\n",
            "        [[ 6.2693e-01,  9.3697e-01, -3.4812e-01,  ...,  1.8449e+00,\n",
            "           1.6234e+00,  6.1914e-01],\n",
            "         [-3.3714e+00, -1.5444e+00, -1.9067e+00,  ..., -2.0148e+00,\n",
            "          -1.0579e+00, -1.4937e+00],\n",
            "         [ 3.0959e-01,  4.1240e-01, -3.2764e+00,  ..., -9.8027e-01,\n",
            "          -2.5773e+00, -3.0952e+00],\n",
            "         ...,\n",
            "         [-2.8683e+00, -1.5498e+00, -9.1564e-01,  ..., -9.3379e-01,\n",
            "          -2.7715e+00,  1.6849e+00],\n",
            "         [-4.0489e+00, -2.4305e+00, -2.4815e+00,  ..., -2.9161e+00,\n",
            "          -3.1142e+00, -3.3767e+00],\n",
            "         [ 1.1179e+00,  1.1645e+00,  1.1443e+00,  ...,  6.4463e-01,\n",
            "           5.3570e-01,  1.1633e+00]],\n",
            "\n",
            "        [[ 8.0097e-01,  1.1848e+00, -4.4676e-01,  ...,  2.2475e+00,\n",
            "           2.0543e+00,  8.7117e-01],\n",
            "         [-4.2347e+00, -1.8730e+00, -2.2747e+00,  ..., -2.5122e+00,\n",
            "          -1.2879e+00, -1.8133e+00],\n",
            "         [ 4.3503e-01,  5.1403e-01, -4.1677e+00,  ..., -1.3159e+00,\n",
            "          -3.1904e+00, -3.9959e+00],\n",
            "         ...,\n",
            "         [-3.7407e+00, -1.8700e+00, -1.1378e+00,  ..., -1.1133e+00,\n",
            "          -3.4835e+00,  2.0410e+00],\n",
            "         [-5.1626e+00, -2.9926e+00, -3.1050e+00,  ..., -3.8254e+00,\n",
            "          -3.9128e+00, -4.3884e+00],\n",
            "         [ 1.3227e+00,  1.3809e+00,  1.3904e+00,  ...,  7.3156e-01,\n",
            "           6.9001e-01,  1.4563e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.2811e+00,  2.3974e+00,  2.6357e-01,  ...,  2.1184e+00,\n",
            "           2.4337e+00,  3.2084e+00],\n",
            "         [-4.9945e+00, -1.4316e+00, -2.1735e+00,  ..., -3.6638e+00,\n",
            "          -3.1006e+00, -1.3025e+00],\n",
            "         [ 1.2282e+00,  9.4860e-01, -5.0789e+00,  ..., -3.1160e+00,\n",
            "          -4.5248e+00, -4.7610e+00],\n",
            "         ...,\n",
            "         [-5.0993e+00, -2.1635e+00, -1.3643e+00,  ..., -1.9168e+00,\n",
            "          -3.5460e+00,  5.1113e-01],\n",
            "         [-6.6997e+00, -3.6421e+00, -4.0136e+00,  ..., -4.4620e+00,\n",
            "          -3.3573e+00, -4.8248e+00],\n",
            "         [ 1.2786e+00,  7.4285e-01,  1.6832e-02,  ..., -1.3980e+00,\n",
            "           6.8841e-01,  1.7737e+00]],\n",
            "\n",
            "        [[ 1.1968e+00,  1.3737e+00,  8.8820e-02,  ...,  1.6180e+00,\n",
            "           1.7218e+00,  1.6524e+00],\n",
            "         [-3.2503e+00, -9.9714e-01, -1.4791e+00,  ..., -2.2621e+00,\n",
            "          -1.7260e+00, -9.3311e-01],\n",
            "         [ 6.3958e-01,  5.9701e-01, -3.1670e+00,  ..., -1.6486e+00,\n",
            "          -2.6954e+00, -2.9342e+00],\n",
            "         ...,\n",
            "         [-2.9546e+00, -1.4625e+00, -8.3620e-01,  ..., -1.0715e+00,\n",
            "          -2.2396e+00,  7.4203e-01],\n",
            "         [-4.0224e+00, -2.2514e+00, -2.4264e+00,  ..., -2.7652e+00,\n",
            "          -2.5059e+00, -3.0814e+00],\n",
            "         [ 7.5059e-01,  5.1087e-01,  2.0232e-01,  ..., -3.9823e-01,\n",
            "           2.9406e-01,  1.0262e+00]],\n",
            "\n",
            "        [[ 2.2807e+00,  2.3794e+00,  2.6507e-01,  ...,  2.0751e+00,\n",
            "           2.3877e+00,  3.2055e+00],\n",
            "         [-4.9270e+00, -1.4208e+00, -2.1438e+00,  ..., -3.6349e+00,\n",
            "          -3.0934e+00, -1.2755e+00],\n",
            "         [ 1.2189e+00,  9.4077e-01, -5.0100e+00,  ..., -3.0935e+00,\n",
            "          -4.4941e+00, -4.6845e+00],\n",
            "         ...,\n",
            "         [-5.0382e+00, -2.1351e+00, -1.3510e+00,  ..., -1.9185e+00,\n",
            "          -3.4909e+00,  4.8160e-01],\n",
            "         [-6.6148e+00, -3.6101e+00, -3.9718e+00,  ..., -4.3816e+00,\n",
            "          -3.2750e+00, -4.7369e+00],\n",
            "         [ 1.2826e+00,  7.2138e-01, -3.6614e-03,  ..., -1.4259e+00,\n",
            "           6.7462e-01,  1.7559e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.6893,  -1.7811,  -3.4034,  ...,  -1.6722,  -1.7283,  -1.3324],\n",
            "         [ -6.7589,  -4.4333,  -5.2017,  ...,  -5.6817,  -5.6064,  -4.4209],\n",
            "         [ -2.4777,  -2.8149,  -7.0490,  ...,  -5.2433,  -6.5453,  -6.6988],\n",
            "         ...,\n",
            "         [ -6.6754,  -4.9474,  -4.5541,  ...,  -4.4857,  -5.7455,  -3.1087],\n",
            "         [ -7.6988,  -5.9267,  -6.3325,  ...,  -6.0543,  -5.6087,  -6.7181],\n",
            "         [ -2.3705,  -2.9620,  -3.7375,  ...,  -4.1544,  -3.0266,  -2.3417]],\n",
            "\n",
            "        [[ -2.3180,  -2.3161,  -3.5964,  ...,  -1.4603,  -1.4566,  -2.5382],\n",
            "         [ -6.3163,  -4.7975,  -5.1550,  ...,  -5.3199,  -4.1379,  -4.6510],\n",
            "         [ -2.6353,  -2.8407,  -6.5247,  ...,  -4.2854,  -5.6572,  -6.2525],\n",
            "         ...,\n",
            "         [ -5.8133,  -4.8028,  -4.1639,  ...,  -4.2389,  -5.8514,  -1.4725],\n",
            "         [ -6.9939,  -5.6836,  -5.7298,  ...,  -6.2212,  -6.1941,  -6.5341],\n",
            "         [ -1.8271,  -2.0886,  -2.1040,  ...,  -2.6605,  -2.5443,  -1.9941]],\n",
            "\n",
            "        [[ -2.2747,  -2.2618,  -4.0911,  ...,  -1.2419,  -1.3335,  -2.4979],\n",
            "         [ -7.3104,  -5.3196,  -5.9191,  ...,  -6.0016,  -4.6757,  -5.1824],\n",
            "         [ -2.6407,  -2.9326,  -7.8121,  ...,  -4.8053,  -6.5782,  -7.3650],\n",
            "         ...,\n",
            "         [ -6.8164,  -5.3166,  -4.7822,  ...,  -4.6027,  -6.8713,  -1.3281],\n",
            "         [ -8.2383,  -6.4393,  -6.7494,  ...,  -7.3147,  -7.3006,  -7.7575],\n",
            "         [ -1.7530,  -2.0658,  -2.2540,  ...,  -2.7578,  -2.6978,  -1.9128]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.4351,  -1.5770,  -4.3252,  ...,  -1.4862,  -1.7871,  -0.9989],\n",
            "         [ -8.7107,  -5.4061,  -6.7623,  ...,  -7.2683,  -7.3215,  -5.5098],\n",
            "         [ -2.4880,  -3.0259,  -9.6677,  ...,  -6.7205,  -8.7457,  -8.9683],\n",
            "         ...,\n",
            "         [ -8.8155,  -6.1380,  -5.9531,  ...,  -5.5214,  -7.7668,  -3.6962],\n",
            "         [-10.4159,  -7.6165,  -8.6024,  ...,  -8.0665,  -7.5782,  -9.0321],\n",
            "         [ -2.4376,  -3.2316,  -4.5719,  ...,  -5.0026,  -3.5325,  -2.4335]],\n",
            "\n",
            "        [[ -1.9370,  -1.9569,  -3.2998,  ...,  -1.5578,  -1.4783,  -1.6677],\n",
            "         [ -6.3841,  -4.3277,  -4.8677,  ...,  -5.4379,  -4.9261,  -4.2532],\n",
            "         [ -2.4942,  -2.7335,  -6.5556,  ...,  -4.8244,  -5.8955,  -6.2544],\n",
            "         ...,\n",
            "         [ -6.0884,  -4.7930,  -4.2248,  ...,  -4.2473,  -5.4397,  -2.5781],\n",
            "         [ -7.1562,  -5.5820,  -5.8150,  ...,  -5.9410,  -5.7060,  -6.4015],\n",
            "         [ -2.3832,  -2.8197,  -3.1863,  ...,  -3.5740,  -2.9060,  -2.2940]],\n",
            "\n",
            "        [[ -1.4296,  -1.5752,  -4.2930,  ...,  -1.5074,  -1.8092,  -0.9929],\n",
            "         [ -8.6373,  -5.3755,  -6.7019,  ...,  -7.2174,  -7.2902,  -5.4739],\n",
            "         [ -2.4914,  -3.0139,  -9.5681,  ...,  -6.6760,  -8.6909,  -8.8829],\n",
            "         ...,\n",
            "         [ -8.7485,  -6.0898,  -5.9091,  ...,  -5.5010,  -7.6877,  -3.7168],\n",
            "         [-10.3251,  -7.5647,  -8.5299,  ...,  -7.9641,  -7.4718,  -8.9353],\n",
            "         [ -2.4277,  -3.2333,  -4.5618,  ...,  -5.0084,  -3.5222,  -2.4424]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.4529,  1.6255,  0.1337,  ..., -0.5641,  0.4106,  1.2270],\n",
            "        [ 1.7398,  1.9527,  0.1636,  ..., -0.7129,  0.5693,  1.4911],\n",
            "        [ 0.1001, -0.9687, -2.4852,  ...,  2.6357,  2.7098,  3.2391],\n",
            "        ...,\n",
            "        [ 0.8166,  1.1592, -0.4183,  ...,  0.6753,  0.6391,  1.3941],\n",
            "        [ 1.3681,  1.6170,  0.0207,  ..., -0.2619,  0.4539,  1.3449],\n",
            "        [ 1.9205,  2.2078,  0.1299,  ..., -0.6589,  0.7111,  1.7571]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.4529,  1.6255,  0.1337,  ...,  1.8260,  1.9615,  2.0129],\n",
            "         [-3.7901, -1.1348, -1.6926,  ..., -2.6371, -2.0299, -1.0853],\n",
            "         [ 0.8220,  0.6854, -3.7443,  ..., -2.0465, -3.1740, -3.4966],\n",
            "         ...,\n",
            "         [-3.5363, -1.6982, -0.9661,  ..., -1.2618, -2.6493,  0.7566],\n",
            "         [-4.8106, -2.6388, -2.8673,  ..., -3.3179, -2.8860, -3.6731],\n",
            "         [ 0.8666,  0.6111,  0.2097,  ..., -0.5641,  0.4106,  1.2270]],\n",
            "\n",
            "        [[ 1.7398,  1.9527,  0.1636,  ...,  2.1138,  2.3089,  2.4294],\n",
            "         [-4.5174, -1.3298, -1.9787,  ..., -3.1270, -2.4080, -1.2918],\n",
            "         [ 1.0281,  0.8246, -4.5215,  ..., -2.5193, -3.7906, -4.2693],\n",
            "         ...,\n",
            "         [-4.3299, -2.0119, -1.1516,  ..., -1.4947, -3.2122,  0.8223],\n",
            "         [-5.8681, -3.1533, -3.4475,  ..., -4.0732, -3.4532, -4.4957],\n",
            "         [ 1.0168,  0.7583,  0.2679,  ..., -0.7129,  0.5693,  1.4911]],\n",
            "\n",
            "        [[ 0.1001, -0.9687, -2.4852,  ...,  1.4638,  0.9526, -1.5222],\n",
            "         [-4.1384, -4.2369, -4.2804,  ..., -2.0425, -1.4921, -3.2246],\n",
            "         [-0.9229, -0.5170, -3.8458,  ..., -0.9986, -3.3163, -4.5080],\n",
            "         ...,\n",
            "         [-2.9645, -1.9675, -2.7965,  ..., -2.0902, -3.9777,  3.7194],\n",
            "         [-4.5379, -4.7944, -4.0111,  ..., -4.3951, -3.6753, -4.4936],\n",
            "         [ 4.2927,  5.4176,  4.6129,  ...,  2.6357,  2.7098,  3.2391]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.8166,  1.1592, -0.4183,  ...,  2.2025,  2.0091,  0.8803],\n",
            "         [-4.1224, -1.8137, -2.2115,  ..., -2.4543, -1.2590, -1.7662],\n",
            "         [ 0.4410,  0.4958, -4.0483,  ..., -1.3098, -3.1135, -3.8531],\n",
            "         ...,\n",
            "         [-3.5975, -1.8188, -1.0965,  ..., -1.0863, -3.3733,  1.9788],\n",
            "         [-5.0098, -2.9132, -3.0180,  ..., -3.7007, -3.7910, -4.2433],\n",
            "         [ 1.2678,  1.3105,  1.3080,  ...,  0.6753,  0.6391,  1.3941]],\n",
            "\n",
            "        [[ 1.3681,  1.6170,  0.0207,  ...,  2.0536,  2.1856,  1.8801],\n",
            "         [-4.1355, -1.3485, -1.8366,  ..., -2.7934, -1.9268, -1.3098],\n",
            "         [ 0.8388,  0.7520, -4.1122,  ..., -2.0576, -3.3140, -3.9005],\n",
            "         ...,\n",
            "         [-3.8250, -1.8346, -1.0508,  ..., -1.2223, -3.0244,  1.0730],\n",
            "         [-5.2399, -2.8569, -3.0778,  ..., -3.7437, -3.4549, -4.2190],\n",
            "         [ 0.9362,  0.7844,  0.5090,  ..., -0.2619,  0.4539,  1.3449]],\n",
            "\n",
            "        [[ 1.9205,  2.2078,  0.1299,  ...,  2.4553,  2.7107,  2.6747],\n",
            "         [-5.2630, -1.5959, -2.2718,  ..., -3.6009, -2.6406, -1.5742],\n",
            "         [ 1.2010,  0.9744, -5.3300,  ..., -2.9062, -4.3387, -5.1001],\n",
            "         ...,\n",
            "         [-5.1087, -2.3395, -1.3409,  ..., -1.6426, -3.8532,  1.0385],\n",
            "         [-6.9189, -3.6687, -4.0112,  ..., -4.8986, -4.2133, -5.4426],\n",
            "         [ 1.1647,  0.9696,  0.4750,  ..., -0.6589,  0.7111,  1.7571]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.8036,  -1.8566,  -3.5373,  ...,  -1.4586,  -1.4766,  -1.4834],\n",
            "         [ -7.0467,  -4.6169,  -5.3636,  ...,  -5.9216,  -5.4680,  -4.5817],\n",
            "         [ -2.4345,  -2.7968,  -7.4153,  ...,  -5.3310,  -6.6122,  -6.9929],\n",
            "         ...,\n",
            "         [ -6.7928,  -5.1804,  -4.6371,  ...,  -4.5463,  -6.0874,  -2.7397],\n",
            "         [ -8.0671,  -6.1209,  -6.5383,  ...,  -6.6025,  -6.3241,  -7.1694],\n",
            "         [ -2.3899,  -2.8711,  -3.4613,  ...,  -3.8486,  -3.0275,  -2.2694]],\n",
            "\n",
            "        [[ -1.6899,  -1.7636,  -3.9208,  ...,  -1.3584,  -1.4784,  -1.3213],\n",
            "         [ -7.9472,  -5.0460,  -6.0632,  ...,  -6.5992,  -6.1953,  -5.0425],\n",
            "         [ -2.4017,  -2.8917,  -8.6059,  ...,  -5.9915,  -7.5779,  -8.0200],\n",
            "         ...,\n",
            "         [ -7.7596,  -5.7282,  -5.2361,  ...,  -4.9668,  -6.9995,  -2.9284],\n",
            "         [ -9.2978,  -6.8696,  -7.5320,  ...,  -7.5453,  -7.2406,  -8.2464],\n",
            "         [ -2.4130,  -2.9579,  -3.8166,  ...,  -4.1851,  -3.2180,  -2.2595]],\n",
            "\n",
            "        [[ -4.2982,  -6.4584,  -7.3125,  ...,  -2.2546,  -2.7536,  -5.9913],\n",
            "         [ -8.5366,  -9.7267,  -9.1077,  ...,  -5.7609,  -5.1983,  -7.6937],\n",
            "         [ -5.3212,  -6.0068,  -8.6730,  ...,  -4.7170,  -7.0225,  -8.9771],\n",
            "         ...,\n",
            "         [ -7.3628,  -7.4572,  -7.6237,  ...,  -5.8087,  -7.6840,  -0.7497],\n",
            "         [ -8.9362, -10.2841,  -8.8384,  ...,  -8.1135,  -7.3815,  -8.9627],\n",
            "         [ -0.1056,  -0.0721,  -0.2143,  ...,  -1.0827,  -0.9965,  -1.2299]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.2437,  -2.2573,  -4.0076,  ...,  -1.2580,  -1.3399,  -2.4570],\n",
            "         [ -7.1827,  -5.2302,  -5.8009,  ...,  -5.9148,  -4.6081,  -5.1035],\n",
            "         [ -2.6194,  -2.9207,  -7.6377,  ...,  -4.7703,  -6.4625,  -7.1904],\n",
            "         ...,\n",
            "         [ -6.6578,  -5.2353,  -4.6859,  ...,  -4.5468,  -6.7224,  -1.3585],\n",
            "         [ -8.0701,  -6.3297,  -6.6074,  ...,  -7.1612,  -7.1400,  -7.5806],\n",
            "         [ -1.7926,  -2.1060,  -2.2813,  ...,  -2.7852,  -2.7100,  -1.9432]],\n",
            "\n",
            "        [[ -1.8912,  -1.9291,  -3.7375,  ...,  -1.3400,  -1.3481,  -1.6199],\n",
            "         [ -7.3948,  -4.8947,  -5.5948,  ...,  -6.1870,  -5.4605,  -4.8098],\n",
            "         [ -2.4205,  -2.7941,  -7.8704,  ...,  -5.4512,  -6.8477,  -7.4006],\n",
            "         ...,\n",
            "         [ -7.0843,  -5.3807,  -4.8090,  ...,  -4.6159,  -6.5582,  -2.4271],\n",
            "         [ -8.4992,  -6.4030,  -6.8360,  ...,  -7.1373,  -6.9886,  -7.7190],\n",
            "         [ -2.3231,  -2.7617,  -3.2492,  ...,  -3.6556,  -3.0798,  -2.1551]],\n",
            "\n",
            "        [[ -1.6598,  -1.7578,  -4.3518,  ...,  -1.2482,  -1.4317,  -1.2872],\n",
            "         [ -8.8432,  -5.5615,  -6.7535,  ...,  -7.3044,  -6.7831,  -5.5362],\n",
            "         [ -2.3793,  -2.9912,  -9.8117,  ...,  -6.6098,  -8.4811,  -9.0621],\n",
            "         ...,\n",
            "         [ -8.6889,  -6.3051,  -5.8226,  ...,  -5.3462,  -7.9956,  -2.9235],\n",
            "         [-10.4991,  -7.6343,  -8.4929,  ...,  -8.6021,  -8.3557,  -9.4046],\n",
            "         [ -2.4156,  -2.9959,  -4.0067,  ...,  -4.3624,  -3.4313,  -2.2049]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.1766,  2.2348,  0.2967,  ..., -1.2519,  0.6413,  1.6829],\n",
            "        [ 0.5358,  0.8702, -0.6624,  ...,  1.1651,  0.9584,  1.4729],\n",
            "        [ 0.3409,  0.5075, -0.8468,  ...,  1.4603,  1.1640,  1.6119],\n",
            "        ...,\n",
            "        [ 0.3533,  0.6630, -1.0046,  ...,  1.6944,  1.4373,  1.9170],\n",
            "        [ 2.4018,  2.4915,  0.3174,  ..., -1.3751,  0.7626,  1.8829],\n",
            "        [ 0.3204,  0.4602, -0.9357,  ...,  1.5553,  1.2571,  1.7318]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.1766e+00,  2.2348e+00,  2.9672e-01,  ...,  2.0991e+00,\n",
            "           2.3555e+00,  3.0308e+00],\n",
            "         [-4.8051e+00, -1.3713e+00, -2.1029e+00,  ..., -3.4832e+00,\n",
            "          -2.8835e+00, -1.2971e+00],\n",
            "         [ 1.2207e+00,  8.4338e-01, -4.8633e+00,  ..., -3.0003e+00,\n",
            "          -4.2820e+00, -4.5511e+00],\n",
            "         ...,\n",
            "         [-4.7853e+00, -2.1130e+00, -1.2649e+00,  ..., -1.7903e+00,\n",
            "          -3.4023e+00,  5.3727e-01],\n",
            "         [-6.3743e+00, -3.4603e+00, -3.8197e+00,  ..., -4.2963e+00,\n",
            "          -3.2968e+00, -4.6496e+00],\n",
            "         [ 1.1952e+00,  7.4326e-01,  3.5088e-02,  ..., -1.2519e+00,\n",
            "           6.4130e-01,  1.6829e+00]],\n",
            "\n",
            "        [[ 5.3577e-01,  8.7022e-01, -6.6242e-01,  ...,  2.1131e+00,\n",
            "           1.7422e+00,  2.8509e-01],\n",
            "         [-4.0203e+00, -2.0784e+00, -2.5519e+00,  ..., -2.1986e+00,\n",
            "          -9.3334e-01, -2.0904e+00],\n",
            "         [ 2.5844e-01,  4.2716e-01, -3.9904e+00,  ..., -1.0537e+00,\n",
            "          -3.0405e+00, -3.8109e+00],\n",
            "         ...,\n",
            "         [-3.4281e+00, -1.9787e+00, -1.1707e+00,  ..., -1.0874e+00,\n",
            "          -3.6024e+00,  2.3088e+00],\n",
            "         [-4.9308e+00, -2.9960e+00, -3.0724e+00,  ..., -3.6726e+00,\n",
            "          -4.0379e+00, -4.2773e+00],\n",
            "         [ 1.5629e+00,  1.8853e+00,  1.9166e+00,  ...,  1.1651e+00,\n",
            "           9.5835e-01,  1.4729e+00]],\n",
            "\n",
            "        [[ 3.4090e-01,  5.0753e-01, -8.4678e-01,  ...,  1.8230e+00,\n",
            "           1.2865e+00, -1.9543e-01],\n",
            "         [-3.5515e+00, -2.1733e+00, -2.5762e+00,  ..., -1.7760e+00,\n",
            "          -7.8839e-01, -2.1525e+00],\n",
            "         [-2.9195e-03,  4.1740e-01, -3.5139e+00,  ..., -8.9593e-01,\n",
            "          -2.6181e+00, -3.4105e+00],\n",
            "         ...,\n",
            "         [-2.8705e+00, -1.7957e+00, -1.2743e+00,  ..., -1.0409e+00,\n",
            "          -3.2480e+00,  2.3837e+00],\n",
            "         [-4.2299e+00, -2.9830e+00, -2.8875e+00,  ..., -3.1629e+00,\n",
            "          -3.7452e+00, -3.7336e+00],\n",
            "         [ 1.8998e+00,  2.2830e+00,  2.2802e+00,  ...,  1.4603e+00,\n",
            "           1.1640e+00,  1.6119e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 3.5328e-01,  6.6301e-01, -1.0046e+00,  ...,  2.1402e+00,\n",
            "           1.6207e+00, -1.5273e-01],\n",
            "         [-4.3552e+00, -2.5621e+00, -3.1359e+00,  ..., -2.1692e+00,\n",
            "          -8.9165e-01, -2.6219e+00],\n",
            "         [ 3.3139e-02,  4.9984e-01, -4.3879e+00,  ..., -1.0825e+00,\n",
            "          -3.2063e+00, -4.2854e+00],\n",
            "         ...,\n",
            "         [-3.6387e+00, -2.2211e+00, -1.5155e+00,  ..., -1.1866e+00,\n",
            "          -4.0440e+00,  2.8730e+00],\n",
            "         [-5.3209e+00, -3.5035e+00, -3.4715e+00,  ..., -4.0646e+00,\n",
            "          -4.6518e+00, -4.7153e+00],\n",
            "         [ 2.1818e+00,  2.7088e+00,  2.7366e+00,  ...,  1.6944e+00,\n",
            "           1.4373e+00,  1.9170e+00]],\n",
            "\n",
            "        [[ 2.4018e+00,  2.4915e+00,  3.1739e-01,  ...,  2.3297e+00,\n",
            "           2.6269e+00,  3.3653e+00],\n",
            "         [-5.3560e+00, -1.5231e+00, -2.3226e+00,  ..., -3.8636e+00,\n",
            "          -3.1858e+00, -1.4590e+00],\n",
            "         [ 1.3680e+00,  9.4221e-01, -5.4570e+00,  ..., -3.3641e+00,\n",
            "          -4.7616e+00, -5.1339e+00],\n",
            "         ...,\n",
            "         [-5.3898e+00, -2.3535e+00, -1.4113e+00,  ..., -1.9788e+00,\n",
            "          -3.8417e+00,  5.8163e-01],\n",
            "         [-7.1829e+00, -3.8605e+00, -4.2740e+00,  ..., -4.8682e+00,\n",
            "          -3.7285e+00, -5.2631e+00],\n",
            "         [ 1.3063e+00,  8.5270e-01,  7.8312e-02,  ..., -1.3751e+00,\n",
            "           7.6255e-01,  1.8829e+00]],\n",
            "\n",
            "        [[ 3.2036e-01,  4.6023e-01, -9.3567e-01,  ...,  1.8420e+00,\n",
            "           1.2668e+00, -2.5748e-01],\n",
            "         [-3.6241e+00, -2.2922e+00, -2.6852e+00,  ..., -1.7954e+00,\n",
            "          -8.1819e-01, -2.2538e+00],\n",
            "         [-5.9841e-02,  3.8741e-01, -3.5687e+00,  ..., -9.3181e-01,\n",
            "          -2.6712e+00, -3.4935e+00],\n",
            "         ...,\n",
            "         [-2.9253e+00, -1.8160e+00, -1.3686e+00,  ..., -1.0714e+00,\n",
            "          -3.3263e+00,  2.4712e+00],\n",
            "         [-4.3042e+00, -3.1113e+00, -2.9715e+00,  ..., -3.2684e+00,\n",
            "          -3.8178e+00, -3.8438e+00],\n",
            "         [ 2.0403e+00,  2.4532e+00,  2.4525e+00,  ...,  1.5553e+00,\n",
            "           1.2571e+00,  1.7318e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.4536,  -1.6425,  -4.1196,  ...,  -1.4557,  -1.7197,  -1.0350],\n",
            "         [ -8.4352,  -5.2487,  -6.5192,  ...,  -7.0380,  -6.9587,  -5.3629],\n",
            "         [ -2.4094,  -3.0339,  -9.2796,  ...,  -6.5551,  -8.3573,  -8.6168],\n",
            "         ...,\n",
            "         [ -8.4155,  -5.9903,  -5.6812,  ...,  -5.3451,  -7.4775,  -3.5285],\n",
            "         [-10.0044,  -7.3376,  -8.2360,  ...,  -7.8511,  -7.3721,  -8.7153],\n",
            "         [ -2.4349,  -3.1341,  -4.3812,  ...,  -4.8067,  -3.4339,  -2.3828]],\n",
            "\n",
            "        [[ -2.4398,  -2.5641,  -4.1920,  ...,  -1.3872,  -1.4979,  -3.0702],\n",
            "         [ -6.9959,  -5.5128,  -6.0815,  ...,  -5.6989,  -4.1734,  -5.4458],\n",
            "         [ -2.7171,  -3.0072,  -7.5200,  ...,  -4.5540,  -6.2806,  -7.1662],\n",
            "         ...,\n",
            "         [ -6.4037,  -5.4130,  -4.7003,  ...,  -4.5877,  -6.8424,  -1.0465],\n",
            "         [ -7.9064,  -6.4304,  -6.6020,  ...,  -7.1729,  -7.2779,  -7.6326],\n",
            "         [ -1.4127,  -1.5491,  -1.6130,  ...,  -2.3352,  -2.2817,  -1.8824]],\n",
            "\n",
            "        [[ -2.6130,  -2.9263,  -4.2356,  ...,  -1.6383,  -1.7732,  -3.5484],\n",
            "         [ -6.5054,  -5.6071,  -5.9650,  ...,  -5.2372,  -3.8480,  -5.5054],\n",
            "         [ -2.9569,  -3.0164,  -6.9028,  ...,  -4.3572,  -5.6778,  -6.7635],\n",
            "         ...,\n",
            "         [ -5.8244,  -5.2295,  -4.6632,  ...,  -4.5022,  -6.3076,  -0.9693],\n",
            "         [ -7.1838,  -6.4168,  -6.2763,  ...,  -6.6241,  -6.8048,  -7.0866],\n",
            "         [ -1.0541,  -1.1508,  -1.1086,  ...,  -2.0009,  -1.8956,  -1.7411]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.7340,  -3.0242,  -4.8007,  ...,  -1.5041,  -1.7035,  -3.8046],\n",
            "         [ -7.4425,  -6.2494,  -6.9321,  ...,  -5.8135,  -4.2159,  -6.2738],\n",
            "         [ -3.0541,  -3.1874,  -8.1841,  ...,  -4.7268,  -6.5305,  -7.9373],\n",
            "         ...,\n",
            "         [ -6.7260,  -5.9083,  -5.3116,  ...,  -4.8309,  -7.3682,  -0.7789],\n",
            "         [ -8.4082,  -7.1907,  -7.2677,  ...,  -7.7089,  -7.9760,  -8.3671],\n",
            "         [ -0.9055,  -0.9784,  -1.0595,  ...,  -1.9499,  -1.8869,  -1.7348]],\n",
            "\n",
            "        [[ -1.3816,  -1.5992,  -4.4606,  ...,  -1.4118,  -1.7556,  -0.9440],\n",
            "         [ -9.1394,  -5.6138,  -7.1006,  ...,  -7.6051,  -7.5684,  -5.7683],\n",
            "         [ -2.4154,  -3.1485, -10.2349,  ...,  -7.1056,  -9.1441,  -9.4431],\n",
            "         ...,\n",
            "         [ -9.1732,  -6.4442,  -6.1893,  ...,  -5.7203,  -8.2242,  -3.7277],\n",
            "         [-10.9663,  -7.9512,  -9.0519,  ...,  -8.6097,  -8.1111,  -9.5724],\n",
            "         [ -2.4771,  -3.2380,  -4.6997,  ...,  -5.1166,  -3.6200,  -2.4263]],\n",
            "\n",
            "        [[ -2.6657,  -3.0237,  -4.3887,  ...,  -1.6450,  -1.8110,  -3.6650],\n",
            "         [ -6.6102,  -5.7761,  -6.1382,  ...,  -5.2824,  -3.8960,  -5.6613],\n",
            "         [ -3.0459,  -3.0965,  -7.0217,  ...,  -4.4188,  -5.7490,  -6.9010],\n",
            "         ...,\n",
            "         [ -5.9113,  -5.2999,  -4.8216,  ...,  -4.5584,  -6.4041,  -0.9363],\n",
            "         [ -7.2903,  -6.5952,  -6.4245,  ...,  -6.7555,  -6.8956,  -7.2513],\n",
            "         [ -0.9457,  -1.0308,  -1.0005,  ...,  -1.9317,  -1.8207,  -1.6756]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.9924,  1.2646, -0.4024,  ...,  0.5872,  0.6367,  1.4574],\n",
            "        [ 0.3987,  0.5643, -0.7108,  ...,  1.2682,  0.9852,  1.4004],\n",
            "        [ 0.9058,  1.1145, -0.2377,  ...,  0.3470,  0.4154,  1.1729],\n",
            "        ...,\n",
            "        [ 2.2321,  2.1716,  0.3397,  ..., -1.3910,  0.6028,  1.6362],\n",
            "        [ 0.3210,  0.4371, -1.2308,  ...,  1.8725,  1.5943,  2.1403],\n",
            "        [ 1.9989,  2.0558,  0.2876,  ..., -1.0014,  0.5940,  1.5729]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.9924,  1.2646, -0.4024,  ...,  2.3562,  2.2224,  1.1071],\n",
            "         [-4.4783, -1.8911, -2.3369,  ..., -2.6829, -1.3836, -1.8603],\n",
            "         [ 0.5427,  0.5172, -4.4173,  ..., -1.5713, -3.3837, -4.1778],\n",
            "         ...,\n",
            "         [-3.9153, -1.9271, -1.1814,  ..., -1.1699, -3.6229,  2.0436],\n",
            "         [-5.4593, -3.1231, -3.2701,  ..., -4.0767, -4.0831, -4.6394],\n",
            "         [ 1.2812,  1.3003,  1.2855,  ...,  0.5872,  0.6367,  1.4574]],\n",
            "\n",
            "        [[ 0.3987,  0.5643, -0.7108,  ...,  1.7774,  1.3323, -0.0657],\n",
            "         [-3.4171, -1.9618, -2.3936,  ..., -1.7231, -0.7302, -1.9946],\n",
            "         [ 0.0817,  0.4169, -3.3748,  ..., -0.8535, -2.5209, -3.2070],\n",
            "         ...,\n",
            "         [-2.7299, -1.7251, -1.1354,  ..., -0.9916, -3.0852,  2.2256],\n",
            "         [-4.0619, -2.7631, -2.7171,  ..., -2.9693, -3.5733, -3.5235],\n",
            "         [ 1.6617,  1.9817,  1.9817,  ...,  1.2682,  0.9852,  1.4004]],\n",
            "\n",
            "        [[ 0.9058,  1.1145, -0.2377,  ...,  1.9785,  1.8775,  1.0705],\n",
            "         [-3.6834, -1.4809, -1.8908,  ..., -2.2968, -1.2844, -1.4515],\n",
            "         [ 0.4774,  0.4656, -3.5943,  ..., -1.3580, -2.8238, -3.3397],\n",
            "         ...,\n",
            "         [-3.1443, -1.5845, -0.9602,  ..., -1.0026, -2.8650,  1.5752],\n",
            "         [-4.4182, -2.5572, -2.6710,  ..., -3.2285, -3.2495, -3.6640],\n",
            "         [ 0.9988,  0.9328,  0.8768,  ...,  0.3470,  0.4154,  1.1729]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.2321,  2.1716,  0.3397,  ...,  1.9457,  2.2006,  3.0805],\n",
            "         [-4.6011, -1.3557, -2.0094,  ..., -3.4151, -2.8946, -1.2193],\n",
            "         [ 1.2277,  0.7855, -4.6605,  ..., -2.9907, -4.2265, -4.3087],\n",
            "         ...,\n",
            "         [-4.5974, -2.0342, -1.2225,  ..., -1.8369, -3.2368,  0.3998],\n",
            "         [-6.1338, -3.3882, -3.7131,  ..., -4.0417, -3.0128, -4.3688],\n",
            "         [ 1.2334,  0.6760, -0.0530,  ..., -1.3910,  0.6028,  1.6362]],\n",
            "\n",
            "        [[ 0.3210,  0.4371, -1.2308,  ...,  2.0573,  1.4412, -0.3542],\n",
            "         [-4.2678, -2.7804, -3.2730,  ..., -2.0570, -0.9404, -2.7626],\n",
            "         [-0.1649,  0.3407, -4.2124,  ..., -1.1527, -3.1490, -4.1733],\n",
            "         ...,\n",
            "         [-3.4853, -2.0855, -1.7325,  ..., -1.2265, -3.9769,  2.9589],\n",
            "         [-5.1165, -3.7150, -3.5122,  ..., -4.0417, -4.5203, -4.6713],\n",
            "         [ 2.5096,  3.0681,  3.0876,  ...,  1.8725,  1.5943,  2.1403]],\n",
            "\n",
            "        [[ 1.9989,  2.0558,  0.2876,  ...,  2.0926,  2.3269,  2.7431],\n",
            "         [-4.6479, -1.3313, -2.0404,  ..., -3.2847, -2.6233, -1.3000],\n",
            "         [ 1.1660,  0.7753, -4.6727,  ..., -2.8091, -4.0173, -4.3860],\n",
            "         ...,\n",
            "         [-4.5066, -2.0575, -1.1874,  ..., -1.6382, -3.2835,  0.6477],\n",
            "         [-6.0852, -3.2826, -3.6155,  ..., -4.1735, -3.3435, -4.5534],\n",
            "         [ 1.0957,  0.7508,  0.1109,  ..., -1.0014,  0.5940,  1.5729]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[-2.1407, -2.2425, -4.1706,  ..., -1.1870, -1.2775, -2.3211],\n",
            "         [-7.6114, -5.3983, -6.1052,  ..., -6.2261, -4.8835, -5.2884],\n",
            "         [-2.5904, -2.9900, -8.1856,  ..., -5.1144, -6.8836, -7.6060],\n",
            "         ...,\n",
            "         [-7.0484, -5.4343, -4.9497,  ..., -4.7130, -7.1228, -1.3845],\n",
            "         [-8.5924, -6.6303, -7.0384,  ..., -7.6199, -7.5830, -8.0675],\n",
            "         [-1.8519, -2.2069, -2.4828,  ..., -2.9559, -2.8632, -1.9707]],\n",
            "\n",
            "        [[-2.5135, -2.7893, -3.9960,  ..., -1.6366, -1.6936, -3.3320],\n",
            "         [-6.3292, -5.3154, -5.6787,  ..., -5.1372, -3.7562, -5.2609],\n",
            "         [-2.8304, -2.9366, -6.6599,  ..., -4.2675, -5.5469, -6.4733],\n",
            "         ...,\n",
            "         [-5.6420, -5.0787, -4.4205,  ..., -4.4056, -6.1112, -1.0407],\n",
            "         [-6.9740, -6.1167, -6.0022,  ..., -6.3833, -6.5993, -6.7898],\n",
            "         [-1.2505, -1.3719, -1.3034,  ..., -2.1458, -2.0408, -1.8659]],\n",
            "\n",
            "        [[-2.1335, -2.2096, -3.6449,  ..., -1.3609, -1.3458, -2.1791],\n",
            "         [-6.7227, -4.8049, -5.2979,  ..., -5.6362, -4.5078, -4.7011],\n",
            "         [-2.5619, -2.8585, -7.0015,  ..., -4.6974, -6.0471, -6.5893],\n",
            "         ...,\n",
            "         [-6.1836, -4.9085, -4.3674,  ..., -4.3420, -6.0884, -1.6744],\n",
            "         [-7.4575, -5.8812, -6.0782,  ..., -6.5679, -6.4729, -6.9135],\n",
            "         [-2.0405, -2.3913, -2.5304,  ..., -2.9924, -2.8079, -2.0767]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.4001, -1.6487, -4.0008,  ..., -1.5476, -1.8189, -0.9848],\n",
            "         [-8.2332, -5.1761, -6.3500,  ..., -6.9084, -6.9141, -5.2845],\n",
            "         [-2.4044, -3.0348, -9.0011,  ..., -6.4841, -8.2460, -8.3740],\n",
            "         ...,\n",
            "         [-8.2296, -5.8546, -5.5630,  ..., -5.3302, -7.2563, -3.6654],\n",
            "         [-9.7659, -7.2086, -8.0536,  ..., -7.5350, -7.0323, -8.4341],\n",
            "         [-2.3987, -3.1443, -4.3936,  ..., -4.8843, -3.4166, -2.4291]],\n",
            "\n",
            "        [[-2.8545, -3.3486, -5.1009,  ..., -1.5960, -1.8428, -4.0818],\n",
            "         [-7.4433, -6.5661, -7.1430,  ..., -5.7103, -4.2244, -6.4902],\n",
            "         [-3.3404, -3.4450, -8.0824,  ..., -4.8060, -6.4329, -7.9009],\n",
            "         ...,\n",
            "         [-6.6608, -5.8712, -5.6025,  ..., -4.8798, -7.2609, -0.7687],\n",
            "         [-8.2920, -7.5007, -7.3822,  ..., -7.6950, -7.8043, -8.3989],\n",
            "         [-0.6659, -0.7176, -0.7825,  ..., -1.7808, -1.6897, -1.5873]],\n",
            "\n",
            "        [[-1.5292, -1.7253, -3.9461,  ..., -1.4143, -1.5923, -1.1513],\n",
            "         [-8.1759, -5.1123, -6.2742,  ..., -6.7916, -6.5425, -5.1943],\n",
            "         [-2.3620, -3.0057, -8.9065,  ..., -6.3160, -7.9365, -8.2803],\n",
            "         ...,\n",
            "         [-8.0346, -5.8385, -5.4212,  ..., -5.1451, -7.2027, -3.2466],\n",
            "         [-9.6132, -7.0636, -7.8492,  ..., -7.6804, -7.2627, -8.4477],\n",
            "         [-2.4324, -3.0303, -4.1229,  ..., -4.5083, -3.3252, -2.3215]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.0158,  1.2296, -0.3290,  ...,  0.4649,  0.5520,  1.3673],\n",
            "        [ 2.5233,  2.4620,  0.4054,  ..., -1.5167,  0.7616,  1.8893],\n",
            "        [ 2.5075,  2.3852,  0.4095,  ..., -1.6141,  0.7098,  1.8206],\n",
            "        ...,\n",
            "        [ 0.9999,  1.2716, -0.5179,  ...,  0.7798,  0.7781,  1.5806],\n",
            "        [ 0.3656,  0.3701, -0.8691,  ...,  1.3999,  1.0873,  1.5357],\n",
            "        [ 0.4393,  0.6640, -0.8746,  ...,  1.4911,  1.2261,  1.6675]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.0158e+00,  1.2296e+00, -3.2895e-01,  ...,  2.2585e+00,\n",
            "           2.1566e+00,  1.1606e+00],\n",
            "         [-4.2893e+00, -1.7658e+00, -2.2147e+00,  ..., -2.6033e+00,\n",
            "          -1.3822e+00, -1.7346e+00],\n",
            "         [ 5.6242e-01,  5.0993e-01, -4.2227e+00,  ..., -1.5866e+00,\n",
            "          -3.2626e+00, -3.9623e+00],\n",
            "         ...,\n",
            "         [-3.7020e+00, -1.8151e+00, -1.1188e+00,  ..., -1.1278e+00,\n",
            "          -3.4190e+00,  1.8854e+00],\n",
            "         [-5.2136e+00, -2.9800e+00, -3.1241e+00,  ..., -3.8751e+00,\n",
            "          -3.8635e+00, -4.3977e+00],\n",
            "         [ 1.1747e+00,  1.1560e+00,  1.1164e+00,  ...,  4.6494e-01,\n",
            "           5.5197e-01,  1.3673e+00]],\n",
            "\n",
            "        [[ 2.5233e+00,  2.4620e+00,  4.0542e-01,  ...,  2.2652e+00,\n",
            "           2.5854e+00,  3.4936e+00],\n",
            "         [-5.3453e+00, -1.5599e+00, -2.3119e+00,  ..., -3.9044e+00,\n",
            "          -3.2550e+00, -1.4559e+00],\n",
            "         [ 1.4535e+00,  8.8147e-01, -5.4577e+00,  ..., -3.4992e+00,\n",
            "          -4.8426e+00, -5.0913e+00],\n",
            "         ...,\n",
            "         [-5.3409e+00, -2.3363e+00, -1.3848e+00,  ..., -2.0556e+00,\n",
            "          -3.8348e+00,  4.7205e-01],\n",
            "         [-7.2052e+00, -3.9117e+00, -4.3114e+00,  ..., -4.8278e+00,\n",
            "          -3.6345e+00, -5.2132e+00],\n",
            "         [ 1.3565e+00,  8.3448e-01,  2.7333e-03,  ..., -1.5167e+00,\n",
            "           7.6163e-01,  1.8893e+00]],\n",
            "\n",
            "        [[ 2.5075e+00,  2.3852e+00,  4.0950e-01,  ...,  2.0870e+00,\n",
            "           2.3938e+00,  3.4694e+00],\n",
            "         [-5.0631e+00, -1.5130e+00, -2.1876e+00,  ..., -3.7802e+00,\n",
            "          -3.2204e+00, -1.3445e+00],\n",
            "         [ 1.4105e+00,  8.4951e-01, -5.1691e+00,  ..., -3.3935e+00,\n",
            "          -4.7061e+00, -4.7780e+00],\n",
            "         ...,\n",
            "         [-5.0906e+00, -2.2195e+00, -1.3283e+00,  ..., -2.0557e+00,\n",
            "          -3.6053e+00,  3.5264e-01],\n",
            "         [-6.8474e+00, -3.7735e+00, -4.1336e+00,  ..., -4.4955e+00,\n",
            "          -3.2990e+00, -4.8505e+00],\n",
            "         [ 1.3736e+00,  7.5247e-01, -7.1347e-02,  ..., -1.6141e+00,\n",
            "           7.0980e-01,  1.8206e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 9.9990e-01,  1.2716e+00, -5.1789e-01,  ...,  2.5293e+00,\n",
            "           2.3637e+00,  1.0105e+00],\n",
            "         [-4.8578e+00, -2.1500e+00, -2.6194e+00,  ..., -2.8170e+00,\n",
            "          -1.3496e+00, -2.1194e+00],\n",
            "         [ 5.5668e-01,  5.1337e-01, -4.8108e+00,  ..., -1.6333e+00,\n",
            "          -3.6486e+00, -4.5687e+00],\n",
            "         ...,\n",
            "         [-4.2209e+00, -2.1009e+00, -1.2903e+00,  ..., -1.2405e+00,\n",
            "          -4.0498e+00,  2.3534e+00],\n",
            "         [-5.9605e+00, -3.4249e+00, -3.5753e+00,  ..., -4.4875e+00,\n",
            "          -4.5424e+00, -5.1296e+00],\n",
            "         [ 1.4583e+00,  1.5687e+00,  1.5752e+00,  ...,  7.7984e-01,\n",
            "           7.7808e-01,  1.5806e+00]],\n",
            "\n",
            "        [[ 3.6559e-01,  3.7008e-01, -8.6913e-01,  ...,  1.6746e+00,\n",
            "           1.1389e+00, -2.5237e-01],\n",
            "         [-3.2607e+00, -2.1029e+00, -2.4457e+00,  ..., -1.5946e+00,\n",
            "          -7.5795e-01, -2.0363e+00],\n",
            "         [-6.7539e-02,  3.2751e-01, -3.1702e+00,  ..., -8.9179e-01,\n",
            "          -2.4154e+00, -3.0563e+00],\n",
            "         ...,\n",
            "         [-2.5306e+00, -1.5777e+00, -1.2707e+00,  ..., -9.9829e-01,\n",
            "          -2.9648e+00,  2.2473e+00],\n",
            "         [-3.7994e+00, -2.8843e+00, -2.7125e+00,  ..., -2.8568e+00,\n",
            "          -3.4035e+00, -3.3899e+00],\n",
            "         [ 1.8915e+00,  2.2311e+00,  2.2126e+00,  ...,  1.3999e+00,\n",
            "           1.0873e+00,  1.5357e+00]],\n",
            "\n",
            "        [[ 4.3932e-01,  6.6396e-01, -8.7456e-01,  ...,  2.0422e+00,\n",
            "           1.6081e+00, -5.5660e-02],\n",
            "         [-4.1279e+00, -2.3446e+00, -2.9203e+00,  ..., -2.0449e+00,\n",
            "          -8.1159e-01, -2.4240e+00],\n",
            "         [ 1.0841e-01,  4.8322e-01, -4.1439e+00,  ..., -1.0651e+00,\n",
            "          -3.0482e+00, -3.9675e+00],\n",
            "         ...,\n",
            "         [-3.3615e+00, -2.0612e+00, -1.3783e+00,  ..., -1.1147e+00,\n",
            "          -3.8076e+00,  2.6833e+00],\n",
            "         [-5.0107e+00, -3.2718e+00, -3.2659e+00,  ..., -3.7758e+00,\n",
            "          -4.3806e+00, -4.3991e+00],\n",
            "         [ 1.9503e+00,  2.3927e+00,  2.4162e+00,  ...,  1.4911e+00,\n",
            "           1.2261e+00,  1.6675e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.1017,  -2.2316,  -4.0086,  ...,  -1.2293,  -1.2809,  -2.2218],\n",
            "         [ -7.4068,  -5.2270,  -5.8944,  ...,  -6.0912,  -4.8198,  -5.1169],\n",
            "         [ -2.5551,  -2.9512,  -7.9023,  ...,  -5.0745,  -6.7001,  -7.3446],\n",
            "         ...,\n",
            "         [ -6.8196,  -5.2762,  -4.7985,  ...,  -4.6156,  -6.8565,  -1.4969],\n",
            "         [ -8.3311,  -6.4411,  -6.8038,  ...,  -7.3629,  -7.3010,  -7.7800],\n",
            "         [ -1.9428,  -2.3051,  -2.5633,  ...,  -3.0229,  -2.8856,  -2.0150]],\n",
            "\n",
            "        [[ -1.3034,  -1.6235,  -4.3952,  ...,  -1.4849,  -1.8276,  -0.8739],\n",
            "         [ -9.1720,  -5.6454,  -7.1126,  ...,  -7.6546,  -7.6681,  -5.8233],\n",
            "         [ -2.3733,  -3.2041, -10.2583,  ...,  -7.2493,  -9.2557,  -9.4588],\n",
            "         ...,\n",
            "         [ -9.1676,  -6.4219,  -6.1854,  ...,  -5.8057,  -8.2479,  -3.8954],\n",
            "         [-11.0320,  -7.9973,  -9.1121,  ...,  -8.5780,  -8.0476,  -9.5807],\n",
            "         [ -2.4702,  -3.2511,  -4.7979,  ...,  -5.2669,  -3.6514,  -2.4782]],\n",
            "\n",
            "        [[ -1.2907,  -1.6136,  -4.2593,  ...,  -1.5685,  -1.9156,  -0.8578],\n",
            "         [ -8.8613,  -5.5119,  -6.8564,  ...,  -7.4357,  -7.5298,  -5.6717],\n",
            "         [ -2.3877,  -3.1493,  -9.8379,  ...,  -7.0490,  -9.0155,  -9.1052],\n",
            "         ...,\n",
            "         [ -8.8887,  -6.2183,  -5.9971,  ...,  -5.7112,  -7.9146,  -3.9746],\n",
            "         [-10.6456,  -7.7723,  -8.8024,  ...,  -8.1510,  -7.6084,  -9.1777],\n",
            "         [ -2.4246,  -3.2464,  -4.7402,  ...,  -5.2696,  -3.5996,  -2.5066]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.1658,  -2.3281,  -4.4679,  ...,  -1.1266,  -1.2638,  -2.5203],\n",
            "         [ -8.0235,  -5.7497,  -6.5694,  ...,  -6.4729,  -4.9772,  -5.6501],\n",
            "         [ -2.6091,  -3.0864,  -8.7608,  ...,  -5.2893,  -7.2762,  -8.0994],\n",
            "         ...,\n",
            "         [ -7.3866,  -5.7006,  -5.2403,  ...,  -4.8964,  -7.6774,  -1.1773],\n",
            "         [ -9.1262,  -7.0246,  -7.5252,  ...,  -8.1434,  -8.1700,  -8.6603],\n",
            "         [ -1.7075,  -2.0311,  -2.3748,  ...,  -2.8761,  -2.8495,  -1.9502]],\n",
            "\n",
            "        [[ -2.5594,  -2.9932,  -4.1360,  ...,  -1.7306,  -1.8269,  -3.5289],\n",
            "         [ -6.1857,  -5.4662,  -5.7126,  ...,  -4.9998,  -3.7237,  -5.3128],\n",
            "         [ -2.9926,  -3.0358,  -6.4371,  ...,  -4.2970,  -5.3811,  -6.3328],\n",
            "         ...,\n",
            "         [ -5.4556,  -4.9409,  -4.5376,  ...,  -4.4035,  -5.9306,  -1.0292],\n",
            "         [ -6.7245,  -6.2476,  -5.9794,  ...,  -6.2621,  -6.3693,  -6.6665],\n",
            "         [ -1.0336,  -1.1322,  -1.0543,  ...,  -2.0053,  -1.8785,  -1.7409]],\n",
            "\n",
            "        [[ -2.5794,  -2.8948,  -4.5095,  ...,  -1.5289,  -1.6379,  -3.5768],\n",
            "         [ -7.1466,  -5.9034,  -6.5552,  ...,  -5.6160,  -4.0576,  -5.9452],\n",
            "         [ -2.9103,  -3.0756,  -7.7789,  ...,  -4.6362,  -6.2942,  -7.4887],\n",
            "         ...,\n",
            "         [ -6.3802,  -5.6200,  -5.0132,  ...,  -4.6859,  -7.0536,  -0.8379],\n",
            "         [ -8.0294,  -6.8306,  -6.9009,  ...,  -7.3469,  -7.6266,  -7.9202],\n",
            "         [ -1.0684,  -1.1660,  -1.2188,  ...,  -2.0800,  -2.0199,  -1.8537]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.7315,  1.7786,  0.2431,  ..., -0.6931,  0.5064,  1.3868],\n",
            "        [ 2.3601,  2.2641,  0.4059,  ..., -1.3811,  0.6826,  1.7551],\n",
            "        [ 0.5149,  0.7987, -0.9198,  ...,  1.5574,  1.2975,  1.7910],\n",
            "        ...,\n",
            "        [ 2.3922,  2.2697,  0.4132,  ..., -1.4501,  0.6785,  1.7565],\n",
            "        [ 1.0131,  1.1704, -0.1972,  ...,  0.2531,  0.4062,  1.2040],\n",
            "        [ 2.1553,  2.0799,  0.3751,  ..., -1.2089,  0.6018,  1.6119]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.7315,  1.7786,  0.2431,  ...,  2.0288,  2.2357,  2.3350],\n",
            "         [-4.3209, -1.2954, -1.9092,  ..., -2.9824, -2.2555, -1.2602],\n",
            "         [ 1.0557,  0.6902, -4.3097,  ..., -2.4922, -3.6216, -4.0256],\n",
            "         ...,\n",
            "         [-3.9832, -1.8845, -1.0521,  ..., -1.4160, -3.0694,  0.7798],\n",
            "         [-5.5680, -3.0180, -3.2901,  ..., -3.8734, -3.3195, -4.2764],\n",
            "         [ 0.9490,  0.7167,  0.2028,  ..., -0.6931,  0.5064,  1.3868]],\n",
            "\n",
            "        [[ 2.3601,  2.2641,  0.4059,  ...,  2.1297,  2.4469,  3.2273],\n",
            "         [-5.0035, -1.4598, -2.1829,  ..., -3.6418, -3.0121, -1.3640],\n",
            "         [ 1.3741,  0.7891, -5.0831,  ..., -3.2661, -4.5036, -4.7309],\n",
            "         ...,\n",
            "         [-4.9073, -2.1361, -1.2695,  ..., -1.8797, -3.5661,  0.4722],\n",
            "         [-6.6789, -3.6395, -4.0092,  ..., -4.4895, -3.4139, -4.8520],\n",
            "         [ 1.2482,  0.7753, -0.0213,  ..., -1.3811,  0.6826,  1.7551]],\n",
            "\n",
            "        [[ 0.5149,  0.7987, -0.9198,  ...,  2.2803,  1.8611,  0.0444],\n",
            "         [-4.6513, -2.5506, -3.2294,  ..., -2.3070, -0.8597, -2.6535],\n",
            "         [ 0.2001,  0.5263, -4.6714,  ..., -1.2375, -3.4572, -4.4795],\n",
            "         ...,\n",
            "         [-3.8162, -2.2508, -1.4825,  ..., -1.1636, -4.3203,  2.9527],\n",
            "         [-5.6962, -3.5873, -3.6279,  ..., -4.3458, -4.9060, -5.0286],\n",
            "         [ 2.0301,  2.5146,  2.5799,  ...,  1.5574,  1.2975,  1.7910]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.3922,  2.2697,  0.4132,  ...,  2.0818,  2.4002,  3.2739],\n",
            "         [-4.9608, -1.4636, -2.1600,  ..., -3.6470, -3.0476, -1.3382],\n",
            "         [ 1.3798,  0.7889, -5.0447,  ..., -3.2790, -4.5200, -4.6785],\n",
            "         ...,\n",
            "         [-4.8884, -2.1201, -1.2662,  ..., -1.9125, -3.5300,  0.4203],\n",
            "         [-6.6439, -3.6415, -4.0010,  ..., -4.4260, -3.3245, -4.7808],\n",
            "         [ 1.2763,  0.7547, -0.0503,  ..., -1.4501,  0.6785,  1.7565]],\n",
            "\n",
            "        [[ 1.0131,  1.1704, -0.1972,  ...,  2.0276,  1.9756,  1.2127],\n",
            "         [-3.8382, -1.5079, -1.9322,  ..., -2.4054, -1.3555, -1.4676],\n",
            "         [ 0.5725,  0.4825, -3.7590,  ..., -1.5341, -2.9608, -3.4765],\n",
            "         ...,\n",
            "         [-3.2485, -1.5899, -0.9800,  ..., -1.0255, -2.9734,  1.5583],\n",
            "         [-4.6394, -2.6642, -2.7915,  ..., -3.3927, -3.3667, -3.8414],\n",
            "         [ 0.9784,  0.9048,  0.8184,  ...,  0.2531,  0.4062,  1.2040]],\n",
            "\n",
            "        [[ 2.1553,  2.0799,  0.3751,  ...,  2.0229,  2.3058,  2.9308],\n",
            "         [-4.6584, -1.3448, -2.0517,  ..., -3.3634, -2.7557, -1.2769],\n",
            "         [ 1.2549,  0.7259, -4.7022,  ..., -2.9816, -4.1396, -4.3769],\n",
            "         ...,\n",
            "         [-4.5059, -1.9879, -1.1726,  ..., -1.7072, -3.2928,  0.5046],\n",
            "         [-6.1406, -3.3494, -3.6926,  ..., -4.1538, -3.2090, -4.4955],\n",
            "         [ 1.1374,  0.7216, -0.0134,  ..., -1.2089,  0.6018,  1.6119]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.6492,  -1.8517,  -3.7057,  ...,  -1.3984,  -1.4463,  -1.3303],\n",
            "         [ -7.7017,  -4.9258,  -5.8579,  ...,  -6.4096,  -5.9375,  -4.9254],\n",
            "         [ -2.3250,  -2.9402,  -8.2584,  ...,  -5.9193,  -7.3037,  -7.6908],\n",
            "         ...,\n",
            "         [ -7.3640,  -5.5149,  -5.0008,  ...,  -4.8432,  -6.7515,  -2.8854],\n",
            "         [ -8.9488,  -6.6484,  -7.2388,  ...,  -7.3006,  -7.0016,  -7.9416],\n",
            "         [ -2.4318,  -2.9136,  -3.7459,  ...,  -4.1203,  -3.1757,  -2.2785]],\n",
            "\n",
            "        [[ -1.3518,  -1.6734,  -4.1431,  ...,  -1.5028,  -1.7495,  -0.9489],\n",
            "         [ -8.7154,  -5.3973,  -6.7318,  ...,  -7.2744,  -7.2085,  -5.5402],\n",
            "         [ -2.3379,  -3.1484,  -9.6320,  ...,  -6.8987,  -8.7000,  -8.9072],\n",
            "         ...,\n",
            "         [ -8.6193,  -6.0736,  -5.8184,  ...,  -5.5123,  -7.7626,  -3.7040],\n",
            "         [-10.3909,  -7.5771,  -8.5581,  ...,  -8.1221,  -7.6104,  -9.0282],\n",
            "         [ -2.4637,  -3.1622,  -4.5703,  ...,  -5.0137,  -3.5138,  -2.4211]],\n",
            "\n",
            "        [[ -2.5707,  -2.8768,  -4.7969,  ...,  -1.4077,  -1.5611,  -3.6498],\n",
            "         [ -7.7369,  -6.2260,  -7.1065,  ...,  -5.9950,  -4.2819,  -6.3478],\n",
            "         [ -2.8855,  -3.1492,  -8.5485,  ...,  -4.9256,  -6.8793,  -8.1738],\n",
            "         ...,\n",
            "         [ -6.9018,  -5.9263,  -5.3596,  ...,  -4.8517,  -7.7425,  -0.7415],\n",
            "         [ -8.7817,  -7.2628,  -7.5050,  ...,  -8.0339,  -8.3282,  -8.7228],\n",
            "         [ -1.0555,  -1.1609,  -1.2973,  ...,  -2.1307,  -2.1247,  -1.9033]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.3326,  -1.6626,  -4.1342,  ...,  -1.5377,  -1.7986,  -0.9249],\n",
            "         [ -8.6856,  -5.3959,  -6.7073,  ...,  -7.2664,  -7.2464,  -5.5370],\n",
            "         [ -2.3450,  -3.1434,  -9.5920,  ...,  -6.8984,  -8.7188,  -8.8772],\n",
            "         ...,\n",
            "         [ -8.6132,  -6.0523,  -5.8135,  ...,  -5.5319,  -7.7288,  -3.7785],\n",
            "         [-10.3687,  -7.5737,  -8.5483,  ...,  -8.0455,  -7.5233,  -8.9796],\n",
            "         [ -2.4485,  -3.1776,  -4.5976,  ...,  -5.0695,  -3.5203,  -2.4423]],\n",
            "\n",
            "        [[ -2.0621,  -2.1932,  -3.6815,  ...,  -1.3367,  -1.3161,  -2.0797],\n",
            "         [ -6.9133,  -4.8714,  -5.4165,  ...,  -5.7697,  -4.6473,  -4.7600],\n",
            "         [ -2.5026,  -2.8811,  -7.2432,  ...,  -4.8985,  -6.2526,  -6.7689],\n",
            "         ...,\n",
            "         [ -6.3237,  -4.9535,  -4.4643,  ...,  -4.3899,  -6.2652,  -1.7341],\n",
            "         [ -7.7145,  -6.0278,  -6.2758,  ...,  -6.7571,  -6.6585,  -7.1338],\n",
            "         [ -2.0968,  -2.4588,  -2.6659,  ...,  -3.1113,  -2.8856,  -2.0884]],\n",
            "\n",
            "        [[ -1.4329,  -1.7189,  -3.9243,  ...,  -1.4942,  -1.6748,  -1.0512],\n",
            "         [ -8.2465,  -5.1436,  -6.3511,  ...,  -6.8806,  -6.7363,  -5.2590],\n",
            "         [ -2.3333,  -3.0729,  -9.0016,  ...,  -6.4988,  -8.1201,  -8.3590],\n",
            "         ...,\n",
            "         [ -8.0940,  -5.7867,  -5.4720,  ...,  -5.2243,  -7.2734,  -3.4775],\n",
            "         [ -9.7287,  -7.1482,  -7.9920,  ...,  -7.6709,  -7.1896,  -8.4776],\n",
            "         [ -2.4507,  -3.0772,  -4.3128,  ...,  -4.7260,  -3.3788,  -2.3702]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.4941,  2.2950,  0.4804,  ..., -1.6611,  0.7113,  1.7765],\n",
            "        [ 2.5561,  2.4168,  0.4618,  ..., -1.5305,  0.7633,  1.8865],\n",
            "        [ 0.4033,  0.3693, -0.8765,  ...,  1.3521,  1.0558,  1.4941],\n",
            "        ...,\n",
            "        [ 0.3719, -0.0267, -1.4707,  ...,  1.8325,  1.5771,  2.1001],\n",
            "        [ 0.5916,  0.9043, -1.0495,  ...,  1.7142,  1.4674,  1.9911],\n",
            "        [ 0.7773,  0.9929, -0.6181,  ...,  0.9776,  0.8622,  1.4497]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.4941,  2.2950,  0.4804,  ...,  1.8854,  2.2612,  3.4116],\n",
            "         [-4.8261, -1.4814, -2.0974,  ..., -3.6255, -3.1572, -1.2421],\n",
            "         [ 1.4377,  0.7478, -4.9266,  ..., -3.3588, -4.5721, -4.5175],\n",
            "         ...,\n",
            "         [-4.7954, -2.0296, -1.2215,  ..., -1.9546, -3.4401,  0.2704],\n",
            "         [-6.5002, -3.6394, -3.9521,  ..., -4.2469, -3.0381, -4.5858],\n",
            "         [ 1.3497,  0.7138, -0.1760,  ..., -1.6611,  0.7113,  1.7765]],\n",
            "\n",
            "        [[ 2.5561,  2.4168,  0.4618,  ...,  2.1964,  2.5716,  3.4799],\n",
            "         [-5.2940, -1.5673, -2.2962,  ..., -3.8839, -3.2308, -1.4324],\n",
            "         [ 1.5179,  0.8215, -5.4048,  ..., -3.5448, -4.8198, -5.0227],\n",
            "         ...,\n",
            "         [-5.2094, -2.2157, -1.3367,  ..., -1.9854, -3.7989,  0.4239],\n",
            "         [-7.1333, -3.8915, -4.2811,  ..., -4.7713, -3.5818, -5.1496],\n",
            "         [ 1.3347,  0.8140, -0.0523,  ..., -1.5305,  0.7633,  1.8865]],\n",
            "\n",
            "        [[ 0.4033,  0.3693, -0.8765,  ...,  1.6514,  1.1589, -0.2236],\n",
            "         [-3.2699, -2.0859, -2.4576,  ..., -1.5875, -0.7401, -1.9955],\n",
            "         [-0.0424,  0.3339, -3.1802,  ..., -0.9206, -2.4304, -3.0295],\n",
            "         ...,\n",
            "         [-2.4908, -1.5327, -1.2794,  ..., -0.9711, -2.9706,  2.2466],\n",
            "         [-3.8030, -2.8868, -2.7197,  ..., -2.8593, -3.4104, -3.3880],\n",
            "         [ 1.8485,  2.1852,  2.1643,  ...,  1.3521,  1.0558,  1.4941]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.3719, -0.0267, -1.4707,  ...,  1.6650,  1.1157, -0.5936],\n",
            "         [-3.6909, -2.8494, -3.1690,  ..., -1.7136, -0.9477, -2.5136],\n",
            "         [-0.3660,  0.0727, -3.5528,  ..., -1.0997, -2.7505, -3.5886],\n",
            "         ...,\n",
            "         [-2.7943, -1.6242, -1.8345,  ..., -1.2560, -3.3943,  2.7806],\n",
            "         [-4.2011, -3.6336, -3.2362,  ..., -3.4780, -3.7494, -3.9657],\n",
            "         [ 2.7381,  3.3006,  3.1230,  ...,  1.8325,  1.5771,  2.1001]],\n",
            "\n",
            "        [[ 0.5916,  0.9043, -1.0495,  ...,  2.5238,  2.0961,  0.0799],\n",
            "         [-5.2626, -2.8587, -3.6305,  ..., -2.5908, -0.9207, -2.9542],\n",
            "         [ 0.2451,  0.5881, -5.2985,  ..., -1.4473, -3.9106, -5.0949],\n",
            "         ...,\n",
            "         [-4.3400, -2.4783, -1.6743,  ..., -1.2371, -4.9208,  3.3248],\n",
            "         [-6.4895, -4.0190, -4.1011,  ..., -5.0153, -5.5504, -5.7668],\n",
            "         [ 2.2194,  2.7765,  2.8824,  ...,  1.7142,  1.4674,  1.9911]],\n",
            "\n",
            "        [[ 0.7773,  0.9929, -0.6181,  ...,  2.2563,  2.0167,  0.5605],\n",
            "         [-4.3793, -2.1314, -2.6400,  ..., -2.4297, -1.0411, -2.0973],\n",
            "         [ 0.4117,  0.4278, -4.3422,  ..., -1.3383, -3.3241, -4.0821],\n",
            "         ...,\n",
            "         [-3.6688, -1.9688, -1.2316,  ..., -1.1134, -3.8374,  2.3623],\n",
            "         [-5.3754, -3.1930, -3.3079,  ..., -4.0356, -4.2861, -4.6584],\n",
            "         [ 1.4740,  1.7376,  1.7444,  ...,  0.9776,  0.8622,  1.4497]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.2712,  -1.6141,  -4.0586,  ...,  -1.6852,  -1.9392,  -0.8540],\n",
            "         [ -8.5913,  -5.3905,  -6.6364,  ...,  -7.1960,  -7.3576,  -5.5078],\n",
            "         [ -2.3275,  -3.1613,  -9.4656,  ...,  -6.9294,  -8.7725,  -8.7831],\n",
            "         ...,\n",
            "         [ -8.5606,  -5.9387,  -5.7605,  ...,  -5.5252,  -7.6405,  -3.9952],\n",
            "         [-10.2654,  -7.5485,  -8.4911,  ...,  -7.8175,  -7.2385,  -8.8514],\n",
            "         [ -2.4155,  -3.1953,  -4.7149,  ...,  -5.2316,  -3.4892,  -2.4892]],\n",
            "\n",
            "        [[ -1.2707,  -1.6359,  -4.3005,  ...,  -1.5429,  -1.8117,  -0.8688],\n",
            "         [ -9.1208,  -5.6200,  -7.0585,  ...,  -7.6232,  -7.6141,  -5.7812],\n",
            "         [ -2.3089,  -3.2312, -10.1671,  ...,  -7.2841,  -9.2031,  -9.3715],\n",
            "         ...,\n",
            "         [ -9.0362,  -6.2684,  -6.0990,  ...,  -5.7247,  -8.1822,  -3.9249],\n",
            "         [-10.9601,  -7.9443,  -9.0434,  ...,  -8.5105,  -7.9651,  -9.4984],\n",
            "         [ -2.4921,  -3.2387,  -4.8146,  ...,  -5.2698,  -3.6200,  -2.4622]],\n",
            "\n",
            "        [[ -2.5117,  -2.9806,  -4.1304,  ...,  -1.7456,  -1.8059,  -3.4950],\n",
            "         [ -6.1849,  -5.4358,  -5.7116,  ...,  -4.9846,  -3.7049,  -5.2668],\n",
            "         [ -2.9573,  -3.0160,  -6.4341,  ...,  -4.3176,  -5.3953,  -6.3008],\n",
            "         ...,\n",
            "         [ -5.4057,  -4.8826,  -4.5333,  ...,  -4.3681,  -5.9355,  -1.0247],\n",
            "         [ -6.7179,  -6.2367,  -5.9736,  ...,  -6.2563,  -6.3752,  -6.6594],\n",
            "         [ -1.0665,  -1.1647,  -1.0896,  ...,  -2.0449,  -1.9090,  -1.7772]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.8727,  -3.8432,  -5.1953,  ...,  -1.8515,  -2.0316,  -4.2191],\n",
            "         [ -6.9354,  -6.6658,  -6.8935,  ...,  -5.2301,  -4.0950,  -6.1391],\n",
            "         [ -3.6106,  -3.7437,  -7.2774,  ...,  -4.6163,  -5.8978,  -7.2141],\n",
            "         ...,\n",
            "         [ -6.0388,  -5.4407,  -5.5591,  ...,  -4.7725,  -6.5416,  -0.8449],\n",
            "         [ -7.4456,  -7.4500,  -6.9607,  ...,  -6.9945,  -6.8966,  -7.5911],\n",
            "         [ -0.5064,  -0.5158,  -0.6015,  ...,  -1.6840,  -1.5701,  -1.5253]],\n",
            "\n",
            "        [[ -2.5973,  -2.9497,  -5.2478,  ...,  -1.3243,  -1.5439,  -3.8666],\n",
            "         [ -8.4515,  -6.7127,  -7.8288,  ...,  -6.4389,  -4.5606,  -6.9007],\n",
            "         [ -2.9438,  -3.2659,  -9.4968,  ...,  -5.2954,  -7.5506,  -9.0414],\n",
            "         ...,\n",
            "         [ -7.5288,  -6.3323,  -5.8726,  ...,  -5.0852,  -8.5608,  -0.6217],\n",
            "         [ -9.6784,  -7.8730,  -8.2994,  ...,  -8.8634,  -9.1904,  -9.7132],\n",
            "         [ -0.9694,  -1.0775,  -1.3159,  ...,  -2.1339,  -2.1726,  -1.9554]],\n",
            "\n",
            "        [[ -2.2578,  -2.4897,  -4.3049,  ...,  -1.2957,  -1.3700,  -2.8599],\n",
            "         [ -7.4144,  -5.6141,  -6.3268,  ...,  -5.9817,  -4.4278,  -5.5177],\n",
            "         [ -2.6233,  -3.0549,  -8.0289,  ...,  -4.8903,  -6.7108,  -7.5025],\n",
            "         ...,\n",
            "         [ -6.7039,  -5.4514,  -4.9183,  ...,  -4.6654,  -7.2241,  -1.0581],\n",
            "         [ -8.4105,  -6.6756,  -6.9946,  ...,  -7.5876,  -7.6728,  -8.0787],\n",
            "         [ -1.5611,  -1.7451,  -1.9424,  ...,  -2.5744,  -2.5245,  -1.9707]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.4597,  0.4799, -0.7464,  ...,  1.2116,  0.9368,  1.3380],\n",
            "        [ 0.8230,  1.0054, -0.5727,  ...,  0.8893,  0.8000,  1.4157],\n",
            "        [ 1.1740,  1.3236, -0.2950,  ...,  0.3640,  0.5648,  1.4446],\n",
            "        ...,\n",
            "        [ 1.7266,  1.7607,  0.2365,  ..., -0.5881,  0.5180,  1.4239],\n",
            "        [ 0.4898,  0.5915, -0.8075,  ...,  1.2955,  1.0555,  1.4661],\n",
            "        [ 0.4756,  0.5517, -0.9435,  ...,  1.4468,  1.2043,  1.6427]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.4597,  0.4799, -0.7464,  ...,  1.6915,  1.2693, -0.0948],\n",
            "         [-3.3207, -1.9565, -2.3900,  ..., -1.6423, -0.7058, -1.9005],\n",
            "         [ 0.0794,  0.4304, -3.2739,  ..., -0.9175, -2.4703, -3.0617],\n",
            "         ...,\n",
            "         [-2.5409, -1.5737, -1.1651,  ..., -0.9369, -3.0037,  2.2074],\n",
            "         [-3.9108, -2.7731, -2.6969,  ..., -2.8694, -3.4782, -3.4076],\n",
            "         [ 1.6318,  1.9461,  1.9255,  ...,  1.2116,  0.9368,  1.3380]],\n",
            "\n",
            "        [[ 0.8230,  1.0054, -0.5727,  ...,  2.2452,  2.0326,  0.6332],\n",
            "         [-4.3522, -2.0792, -2.5839,  ..., -2.4362, -1.0704, -2.0235],\n",
            "         [ 0.4412,  0.4591, -4.3042,  ..., -1.3786, -3.3051, -4.0290],\n",
            "         ...,\n",
            "         [-3.6155, -1.9100, -1.2145,  ..., -1.0808, -3.7718,  2.3090],\n",
            "         [-5.3265, -3.1579, -3.2676,  ..., -3.9895, -4.2159, -4.5999],\n",
            "         [ 1.4054,  1.6314,  1.6295,  ...,  0.8893,  0.8000,  1.4157]],\n",
            "\n",
            "        [[ 1.1740,  1.3236, -0.2950,  ...,  2.3573,  2.3220,  1.3467],\n",
            "         [-4.5801, -1.8469, -2.3257,  ..., -2.7929, -1.4878, -1.7734],\n",
            "         [ 0.7086,  0.5656, -4.5283,  ..., -1.8544, -3.5056, -4.2255],\n",
            "         ...,\n",
            "         [-3.9061, -1.8254, -1.1813,  ..., -1.1274, -3.6437,  1.9214],\n",
            "         [-5.6142, -3.1826, -3.3479,  ..., -4.1836, -4.1094, -4.7349],\n",
            "         [ 1.1525,  1.1359,  1.0600,  ...,  0.3640,  0.5648,  1.4446]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.7266,  1.7607,  0.2365,  ...,  2.0984,  2.3405,  2.2799],\n",
            "         [-4.4475, -1.3807, -1.9685,  ..., -3.0477, -2.2044, -1.3315],\n",
            "         [ 1.1150,  0.7206, -4.4508,  ..., -2.5566, -3.6735, -4.1680],\n",
            "         ...,\n",
            "         [-4.0276, -1.8792, -1.0713,  ..., -1.3239, -3.2127,  0.8868],\n",
            "         [-5.7231, -3.1007, -3.3693,  ..., -4.0395, -3.5448, -4.4872],\n",
            "         [ 0.9339,  0.7583,  0.2690,  ..., -0.5881,  0.5180,  1.4239]],\n",
            "\n",
            "        [[ 0.4898,  0.5915, -0.8075,  ...,  1.8781,  1.4964, -0.0247],\n",
            "         [-3.7895, -2.1361, -2.6884,  ..., -1.8717, -0.7464, -2.1458],\n",
            "         [ 0.1318,  0.4816, -3.7764,  ..., -1.0278, -2.8083, -3.5401],\n",
            "         ...,\n",
            "         [-2.9618, -1.8096, -1.2810,  ..., -1.0068, -3.4541,  2.4689],\n",
            "         [-4.5427, -3.0327, -3.0074,  ..., -3.3818, -3.9902, -3.9610],\n",
            "         [ 1.7296,  2.1145,  2.1152,  ...,  1.2955,  1.0555,  1.4661]],\n",
            "\n",
            "        [[ 0.4756,  0.5517, -0.9435,  ...,  1.9373,  1.5124, -0.1085],\n",
            "         [-3.9940, -2.3466, -2.9137,  ..., -1.9479, -0.8009, -2.3261],\n",
            "         [ 0.0673,  0.4736, -3.9889,  ..., -1.1095, -2.9653, -3.7811],\n",
            "         ...,\n",
            "         [-3.1450, -1.8900, -1.4335,  ..., -1.0627, -3.6780,  2.6560],\n",
            "         [-4.8008, -3.2805, -3.2177,  ..., -3.6434, -4.2325, -4.2430],\n",
            "         [ 1.9456,  2.3929,  2.3938,  ...,  1.4468,  1.2043,  1.6427]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[-2.4336, -2.8427, -3.9810,  ..., -1.6960, -1.7196, -3.3412],\n",
            "         [-6.2140, -5.2790, -5.6246,  ..., -5.0297, -3.6947, -5.1469],\n",
            "         [-2.8139, -2.8922, -6.5085,  ..., -4.3050, -5.4592, -6.3081],\n",
            "         ...,\n",
            "         [-5.4342, -4.8963, -4.3997,  ..., -4.3243, -5.9927, -1.0389],\n",
            "         [-6.8040, -6.0957, -5.9315,  ..., -6.2568, -6.4672, -6.6540],\n",
            "         [-1.2614, -1.3765, -1.3091,  ..., -2.1758, -2.0521, -1.9083]],\n",
            "\n",
            "        [[-2.2136, -2.4601, -4.2425,  ..., -1.2892, -1.3516, -2.7707],\n",
            "         [-7.3889, -5.5446, -6.2537,  ..., -5.9705, -4.4545, -5.4274],\n",
            "         [-2.5954, -3.0063, -7.9739,  ..., -4.9130, -6.6893, -7.4329],\n",
            "         ...,\n",
            "         [-6.6522, -5.3754, -4.8843,  ..., -4.6152, -7.1560, -1.0949],\n",
            "         [-8.3631, -6.6233, -6.9374,  ..., -7.5239, -7.6001, -8.0038],\n",
            "         [-1.6312, -1.8340, -2.0402,  ..., -2.6450, -2.5841, -1.9882]],\n",
            "\n",
            "        [[-2.0049, -2.2131, -4.1238,  ..., -1.1923, -1.2437, -2.1098],\n",
            "         [-7.7590, -5.3836, -6.1545,  ..., -6.3426, -5.0535, -5.2299],\n",
            "         [-2.4703, -2.9711, -8.3571,  ..., -5.4041, -7.0712, -7.6819],\n",
            "         ...,\n",
            "         [-7.0850, -5.3621, -5.0101,  ..., -4.6771, -7.2093, -1.5351],\n",
            "         [-8.7930, -6.7193, -7.1767,  ..., -7.7332, -7.6750, -8.1914],\n",
            "         [-2.0264, -2.4008, -2.7689,  ..., -3.1856, -3.0009, -2.0119]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.6583, -1.8881, -3.7401,  ..., -1.3673, -1.3781, -1.3757],\n",
            "         [-7.8325, -5.0295, -5.9450,  ..., -6.5135, -5.9230, -4.9871],\n",
            "         [-2.2699, -2.9281, -8.4274,  ..., -6.0224, -7.3920, -7.8236],\n",
            "         ...,\n",
            "         [-7.4126, -5.5280, -5.0479,  ..., -4.7897, -6.9313, -2.7689],\n",
            "         [-9.1081, -6.7494, -7.3459,  ..., -7.5053, -7.2633, -8.1428],\n",
            "         [-2.4510, -2.8904, -3.7076,  ..., -4.0539, -3.2006, -2.2317]],\n",
            "\n",
            "        [[-2.4566, -2.8415, -4.2474,  ..., -1.5990, -1.6357, -3.4123],\n",
            "         [-6.7358, -5.5691, -6.1284,  ..., -5.3488, -3.8785, -5.5334],\n",
            "         [-2.8145, -2.9514, -7.2163,  ..., -4.5049, -5.9403, -6.9277],\n",
            "         ...,\n",
            "         [-5.9082, -5.2426, -4.7209,  ..., -4.4839, -6.5862, -0.9187],\n",
            "         [-7.4890, -6.4657, -6.4473,  ..., -6.8590, -7.1222, -7.3487],\n",
            "         [-1.2167, -1.3185, -1.3247,  ..., -2.1817, -2.0766, -1.9215]],\n",
            "\n",
            "        [[-2.5176, -2.9702, -4.5128,  ..., -1.5953, -1.6792, -3.6049],\n",
            "         [-6.9872, -5.8686, -6.4829,  ..., -5.4804, -3.9925, -5.8225],\n",
            "         [-2.9259, -3.0484, -7.5581,  ..., -4.6420, -6.1570, -7.2775],\n",
            "         ...,\n",
            "         [-6.1382, -5.4120, -5.0028,  ..., -4.5952, -6.8696, -0.8404],\n",
            "         [-7.7940, -6.8025, -6.7869,  ..., -7.1760, -7.4242, -7.7395],\n",
            "         [-1.0476, -1.1290, -1.1755,  ..., -2.0857, -1.9874, -1.8537]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.6553,  0.9190, -1.2298,  ...,  1.8892,  1.6625,  2.2344],\n",
            "        [ 2.3556,  2.2062,  0.4739,  ..., -1.3334,  0.6964,  1.7788],\n",
            "        [ 0.6507,  0.9065, -1.1561,  ...,  1.7879,  1.5614,  2.1155],\n",
            "        ...,\n",
            "        [ 2.1032,  1.9893,  0.4247,  ..., -1.1136,  0.5980,  1.6028],\n",
            "        [ 0.6948,  0.8844, -0.8193,  ...,  1.2556,  1.0839,  1.6151],\n",
            "        [ 0.5156,  0.6117, -0.8312,  ...,  1.2990,  1.0735,  1.4952]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 6.5532e-01,  9.1904e-01, -1.2298e+00,  ...,  2.7064e+00,\n",
            "           2.2745e+00,  5.2270e-02],\n",
            "         [-5.8458e+00, -3.2138e+00, -4.1217e+00,  ..., -2.8131e+00,\n",
            "          -9.7867e-01, -3.2939e+00],\n",
            "         [ 2.5606e-01,  7.6645e-01, -5.9199e+00,  ..., -1.6330e+00,\n",
            "          -4.3661e+00, -5.6854e+00],\n",
            "         ...,\n",
            "         [-4.7925e+00, -2.7104e+00, -1.9299e+00,  ..., -1.2733e+00,\n",
            "          -5.5223e+00,  3.7825e+00],\n",
            "         [-7.2413e+00, -4.4953e+00, -4.5832e+00,  ..., -5.6688e+00,\n",
            "          -6.2277e+00, -6.4832e+00],\n",
            "         [ 2.4837e+00,  3.1182e+00,  3.2570e+00,  ...,  1.8892e+00,\n",
            "           1.6625e+00,  2.2344e+00]],\n",
            "\n",
            "        [[ 2.3556e+00,  2.2062e+00,  4.7387e-01,  ...,  2.1174e+00,\n",
            "           2.4937e+00,  3.1837e+00],\n",
            "         [-5.0218e+00, -1.4789e+00, -2.2070e+00,  ..., -3.6387e+00,\n",
            "          -2.9823e+00, -1.3775e+00],\n",
            "         [ 1.4618e+00,  8.1400e-01, -5.0984e+00,  ..., -3.3323e+00,\n",
            "          -4.4931e+00, -4.7417e+00],\n",
            "         ...,\n",
            "         [-4.8120e+00, -2.0358e+00, -1.2216e+00,  ..., -1.6909e+00,\n",
            "          -3.5904e+00,  4.6690e-01],\n",
            "         [-6.6819e+00, -3.6415e+00, -4.0122e+00,  ..., -4.5247e+00,\n",
            "          -3.4711e+00, -4.8887e+00],\n",
            "         [ 1.2028e+00,  7.7213e-01, -4.9776e-02,  ..., -1.3334e+00,\n",
            "           6.9638e-01,  1.7788e+00]],\n",
            "\n",
            "        [[ 6.5072e-01,  9.0655e-01, -1.1561e+00,  ...,  2.6320e+00,\n",
            "           2.2071e+00,  7.7575e-02],\n",
            "         [-5.6270e+00, -3.0661e+00, -3.9318e+00,  ..., -2.7214e+00,\n",
            "          -9.5539e-01, -3.1366e+00],\n",
            "         [ 2.6261e-01,  7.3567e-01, -5.6816e+00,  ..., -1.5713e+00,\n",
            "          -4.1948e+00, -5.4416e+00],\n",
            "         ...,\n",
            "         [-4.5965e+00, -2.5963e+00, -1.8314e+00,  ..., -1.2348e+00,\n",
            "          -5.2907e+00,  3.6062e+00],\n",
            "         [-6.9533e+00, -4.3087e+00, -4.3971e+00,  ..., -5.4159e+00,\n",
            "          -5.9643e+00, -6.2044e+00],\n",
            "         [ 2.3448e+00,  2.9471e+00,  3.0747e+00,  ...,  1.7879e+00,\n",
            "           1.5614e+00,  2.1155e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.1032e+00,  1.9893e+00,  4.2473e-01,  ...,  2.0035e+00,\n",
            "           2.3303e+00,  2.8201e+00],\n",
            "         [-4.6226e+00, -1.3461e+00, -2.0530e+00,  ..., -3.3076e+00,\n",
            "          -2.6673e+00, -1.2790e+00],\n",
            "         [ 1.3105e+00,  7.4226e-01, -4.6550e+00,  ..., -2.9815e+00,\n",
            "          -4.0598e+00, -4.3323e+00],\n",
            "         ...,\n",
            "         [-4.3473e+00, -1.8778e+00, -1.1130e+00,  ..., -1.5000e+00,\n",
            "          -3.2733e+00,  5.2553e-01],\n",
            "         [-6.0556e+00, -3.2998e+00, -3.6373e+00,  ..., -4.1383e+00,\n",
            "          -3.2517e+00, -4.4857e+00],\n",
            "         [ 1.0705e+00,  7.1226e-01, -2.5522e-02,  ..., -1.1136e+00,\n",
            "           5.9802e-01,  1.6028e+00]],\n",
            "\n",
            "        [[ 6.9485e-01,  8.8443e-01, -8.1926e-01,  ...,  2.3264e+00,\n",
            "           1.9980e+00,  3.0421e-01],\n",
            "         [-4.6832e+00, -2.4235e+00, -3.0624e+00,  ..., -2.4323e+00,\n",
            "          -9.3532e-01, -2.4055e+00],\n",
            "         [ 3.4846e-01,  5.5146e-01, -4.6760e+00,  ..., -1.3517e+00,\n",
            "          -3.5302e+00, -4.4069e+00],\n",
            "         ...,\n",
            "         [-3.8455e+00, -2.1223e+00, -1.4077e+00,  ..., -1.1096e+00,\n",
            "          -4.2567e+00,  2.7640e+00],\n",
            "         [-5.7547e+00, -3.5075e+00, -3.6138e+00,  ..., -4.3823e+00,\n",
            "          -4.7807e+00, -5.0615e+00],\n",
            "         [ 1.7196e+00,  2.1389e+00,  2.1732e+00,  ...,  1.2556e+00,\n",
            "           1.0839e+00,  1.6151e+00]],\n",
            "\n",
            "        [[ 5.1558e-01,  6.1167e-01, -8.3115e-01,  ...,  1.9247e+00,\n",
            "           1.5586e+00,  7.7414e-04],\n",
            "         [-3.9404e+00, -2.1947e+00, -2.7919e+00,  ..., -1.9290e+00,\n",
            "          -7.6176e-01, -2.2075e+00],\n",
            "         [ 1.5504e-01,  5.4015e-01, -3.9355e+00,  ..., -1.0600e+00,\n",
            "          -2.9229e+00, -3.6791e+00],\n",
            "         ...,\n",
            "         [-3.0764e+00, -1.8650e+00, -1.3243e+00,  ..., -1.0029e+00,\n",
            "          -3.5997e+00,  2.5591e+00],\n",
            "         [-4.7394e+00, -3.1235e+00, -3.1118e+00,  ..., -3.5442e+00,\n",
            "          -4.1530e+00, -4.1364e+00],\n",
            "         [ 1.7453e+00,  2.1465e+00,  2.1549e+00,  ...,  1.2990e+00,\n",
            "           1.0735e+00,  1.4952e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.6623,  -3.1453,  -5.7737,  ...,  -1.3034,  -1.5840,  -4.2224],\n",
            "         [ -9.1634,  -7.2782,  -8.6656,  ...,  -6.8229,  -4.8372,  -7.5685],\n",
            "         [ -3.0615,  -3.2979, -10.4638,  ...,  -5.6428,  -8.2246,  -9.9600],\n",
            "         ...,\n",
            "         [ -8.1101,  -6.7747,  -6.4737,  ...,  -5.2831,  -9.3808,  -0.4922],\n",
            "         [-10.5589,  -8.5596,  -9.1271,  ...,  -9.6785, -10.0861, -10.7579],\n",
            "         [ -0.8339,  -0.9461,  -1.2869,  ...,  -2.1206,  -2.1960,  -2.0403]],\n",
            "\n",
            "        [[ -1.3494,  -1.7075,  -4.0580,  ...,  -1.5170,  -1.6912,  -0.9663],\n",
            "         [ -8.7268,  -5.3927,  -6.7389,  ...,  -7.2730,  -7.1672,  -5.5274],\n",
            "         [ -2.2432,  -3.0998,  -9.6302,  ...,  -6.9667,  -8.6780,  -8.8916],\n",
            "         ...,\n",
            "         [ -8.5170,  -5.9496,  -5.7535,  ...,  -5.3252,  -7.7752,  -3.6830],\n",
            "         [-10.3869,  -7.5553,  -8.5440,  ...,  -8.1591,  -7.6560,  -9.0387],\n",
            "         [ -2.5022,  -3.1416,  -4.5816,  ...,  -4.9677,  -3.4885,  -2.3712]],\n",
            "\n",
            "        [[ -2.6037,  -3.0598,  -5.5573,  ...,  -1.3079,  -1.5657,  -4.0639],\n",
            "         [ -8.8814,  -7.0325,  -8.3330,  ...,  -6.6614,  -4.7282,  -7.2781],\n",
            "         [ -2.9918,  -3.2307, -10.0828,  ...,  -5.5113,  -7.9677,  -9.5831],\n",
            "         ...,\n",
            "         [ -7.8509,  -6.5627,  -6.2326,  ...,  -5.1748,  -9.0635,  -0.5353],\n",
            "         [-10.2078,  -8.2751,  -8.7983,  ...,  -9.3559,  -9.7371, -10.3459],\n",
            "         [ -0.9096,  -1.0193,  -1.3265,  ...,  -2.1520,  -2.2114,  -2.0260]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.4522,  -1.7663,  -3.8123,  ...,  -1.4966,  -1.6001,  -1.0982],\n",
            "         [ -8.1780,  -5.1018,  -6.2900,  ...,  -6.8077,  -6.5977,  -5.1973],\n",
            "         [ -2.2449,  -3.0134,  -8.8920,  ...,  -6.4816,  -7.9903,  -8.2506],\n",
            "         ...,\n",
            "         [ -7.9028,  -5.6335,  -5.3500,  ...,  -5.0001,  -7.2037,  -3.3928],\n",
            "         [ -9.6111,  -7.0555,  -7.8743,  ...,  -7.6384,  -7.1822,  -8.4039],\n",
            "         [ -2.4849,  -3.0434,  -4.2625,  ...,  -4.6137,  -3.3324,  -2.3155]],\n",
            "\n",
            "        [[ -2.3586,  -2.7065,  -4.6602,  ...,  -1.3210,  -1.4572,  -3.2902],\n",
            "         [ -7.7366,  -6.0144,  -6.9033,  ...,  -6.0797,  -4.3905,  -5.9999],\n",
            "         [ -2.7049,  -3.0394,  -8.5169,  ...,  -4.9991,  -6.9854,  -8.0013],\n",
            "         ...,\n",
            "         [ -6.8989,  -5.7132,  -5.2486,  ...,  -4.7570,  -7.7119,  -0.8303],\n",
            "         [ -8.8081,  -7.0984,  -7.4547,  ...,  -8.0297,  -8.2359,  -8.6559],\n",
            "         [ -1.3338,  -1.4520,  -1.6677,  ...,  -2.3918,  -2.3713,  -1.9793]],\n",
            "\n",
            "        [[ -2.4461,  -2.8526,  -4.3364,  ...,  -1.5782,  -1.6195,  -3.4363],\n",
            "         [ -6.9021,  -5.6590,  -6.2971,  ...,  -5.4320,  -3.9399,  -5.6446],\n",
            "         [ -2.8067,  -2.9241,  -7.4408,  ...,  -4.5629,  -6.1010,  -7.1163],\n",
            "         ...,\n",
            "         [ -6.0381,  -5.3293,  -4.8295,  ...,  -4.5059,  -6.7778,  -0.8781],\n",
            "         [ -7.7011,  -6.5878,  -6.6171,  ...,  -7.0472,  -7.3311,  -7.5735],\n",
            "         [ -1.2164,  -1.3177,  -1.3503,  ...,  -2.2040,  -2.1046,  -1.9419]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.1938,  2.0701,  0.4678,  ..., -1.1761,  0.6447,  1.6882],\n",
            "        [ 0.4499,  0.3852, -1.3094,  ...,  1.7155,  1.4909,  2.0365],\n",
            "        [ 0.4634,  0.4193, -1.0614,  ...,  1.4703,  1.2273,  1.7100],\n",
            "        ...,\n",
            "        [ 0.4970,  0.5171, -0.8323,  ...,  1.2601,  1.0149,  1.4347],\n",
            "        [ 0.7800,  0.9436, -0.7349,  ...,  1.0817,  0.9551,  1.5155],\n",
            "        [ 0.5665,  0.6968, -0.6693,  ...,  1.0676,  0.8618,  1.3306]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.1938,  2.0701,  0.4678,  ...,  2.0768,  2.4568,  2.9611],\n",
            "         [-4.8508, -1.4199, -2.1497,  ..., -3.4682, -2.8024, -1.3502],\n",
            "         [ 1.3995,  0.8018, -4.9019,  ..., -3.1622, -4.2663, -4.5674],\n",
            "         ...,\n",
            "         [-4.5654, -1.9467, -1.1521,  ..., -1.5012, -3.4583,  0.5229],\n",
            "         [-6.3905, -3.4724, -3.8297,  ..., -4.3747, -3.4279, -4.7375],\n",
            "         [ 1.1108,  0.7494, -0.0275,  ..., -1.1761,  0.6447,  1.6882]],\n",
            "\n",
            "        [[ 0.4499,  0.3852, -1.3094,  ...,  1.9861,  1.4796, -0.2814],\n",
            "         [-4.3650, -2.7912, -3.3964,  ..., -2.0244, -0.9345, -2.6866],\n",
            "         [-0.1294,  0.4759, -4.3035,  ..., -1.2494, -3.2535, -4.1374],\n",
            "         ...,\n",
            "         [-3.3953, -1.9641, -1.8340,  ..., -1.1344, -4.0629,  3.0333],\n",
            "         [-5.1992, -3.8093, -3.6010,  ..., -4.1335, -4.6110, -4.7501],\n",
            "         [ 2.4199,  2.9778,  3.0011,  ...,  1.7155,  1.4909,  2.0365]],\n",
            "\n",
            "        [[ 0.4634,  0.4193, -1.0614,  ...,  1.8386,  1.3754, -0.1979],\n",
            "         [-3.8922, -2.4138, -2.9475,  ..., -1.8382, -0.8357, -2.3183],\n",
            "         [-0.0353,  0.4847, -3.8369,  ..., -1.0957, -2.9011, -3.6399],\n",
            "         ...,\n",
            "         [-2.9935, -1.7732, -1.5401,  ..., -1.0269, -3.5838,  2.6631],\n",
            "         [-4.6108, -3.3453, -3.1954,  ..., -3.5605, -4.0980, -4.1389],\n",
            "         [ 2.0501,  2.4966,  2.5006,  ...,  1.4703,  1.2273,  1.7100]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.4970,  0.5171, -0.8323,  ...,  1.7876,  1.3902, -0.0792],\n",
            "         [-3.6596, -2.1234, -2.6478,  ..., -1.7720, -0.7569, -2.0644],\n",
            "         [ 0.0964,  0.5353, -3.6394,  ..., -0.9998, -2.7251, -3.3957],\n",
            "         ...,\n",
            "         [-2.8127, -1.7054, -1.2929,  ..., -0.9498, -3.3396,  2.4259],\n",
            "         [-4.3555, -3.0103, -2.9542,  ..., -3.2482, -3.8585, -3.8126],\n",
            "         [ 1.7125,  2.0842,  2.0754,  ...,  1.2601,  1.0149,  1.4347]],\n",
            "\n",
            "        [[ 0.7800,  0.9436, -0.7349,  ...,  2.3247,  2.0680,  0.4583],\n",
            "         [-4.6367, -2.3202, -2.9048,  ..., -2.4874, -1.0082, -2.2565],\n",
            "         [ 0.4204,  0.5537, -4.6246,  ..., -1.3890, -3.5267, -4.3230],\n",
            "         ...,\n",
            "         [-3.8286, -2.0551, -1.3464,  ..., -1.0747, -4.1541,  2.6019],\n",
            "         [-5.7168, -3.4108, -3.5473,  ..., -4.3395, -4.6342, -5.0009],\n",
            "         [ 1.5500,  1.9068,  1.9274,  ...,  1.0817,  0.9551,  1.5155]],\n",
            "\n",
            "        [[ 0.5665,  0.6968, -0.6693,  ...,  1.9188,  1.6174,  0.1804],\n",
            "         [-3.8157, -2.0038, -2.5857,  ..., -1.9477, -0.8049, -2.0008],\n",
            "         [ 0.2510,  0.5118, -3.7725,  ..., -1.0474, -2.8795, -3.4930],\n",
            "         ...,\n",
            "         [-2.9797, -1.7633, -1.1716,  ..., -0.9309, -3.4362,  2.3299],\n",
            "         [-4.6006, -2.9175, -2.9272,  ..., -3.4018, -3.9046, -3.9767],\n",
            "         [ 1.4587,  1.7940,  1.8035,  ...,  1.0676,  0.8618,  1.3306]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.4244,  -1.7614,  -3.9095,  ...,  -1.4918,  -1.5974,  -1.0534],\n",
            "         [ -8.4689,  -5.2514,  -6.5270,  ...,  -7.0367,  -6.8566,  -5.3646],\n",
            "         [ -2.2186,  -3.0297,  -9.2792,  ...,  -6.7307,  -8.3206,  -8.5818],\n",
            "         ...,\n",
            "         [ -8.1836,  -5.7781,  -5.5294,  ...,  -5.0698,  -7.5125,  -3.4915],\n",
            "         [-10.0086,  -7.3039,  -8.2070,  ...,  -7.9432,  -7.4822,  -8.7520],\n",
            "         [ -2.5073,  -3.0820,  -4.4048,  ...,  -4.7446,  -3.4095,  -2.3262]],\n",
            "\n",
            "        [[ -2.6873,  -3.3566,  -5.1671,  ...,  -1.6449,  -1.8209,  -4.0286],\n",
            "         [ -7.5023,  -6.5330,  -7.2541,  ...,  -5.6554,  -4.2350,  -6.4338],\n",
            "         [ -3.2667,  -3.2659,  -8.1612,  ...,  -4.8804,  -6.5540,  -7.8846],\n",
            "         ...,\n",
            "         [ -6.5325,  -5.7060,  -5.6917,  ...,  -4.7654,  -7.3634,  -0.7139],\n",
            "         [ -8.3365,  -7.5511,  -7.4587,  ...,  -7.7645,  -7.9115,  -8.4973],\n",
            "         [ -0.7174,  -0.7640,  -0.8566,  ...,  -1.9155,  -1.8096,  -1.7107]],\n",
            "\n",
            "        [[ -2.5329,  -3.0971,  -4.6059,  ...,  -1.6708,  -1.7699,  -3.6958],\n",
            "         [ -6.8885,  -5.9302,  -6.4920,  ...,  -5.3476,  -3.9810,  -5.8162],\n",
            "         [ -3.0316,  -3.0317,  -7.3814,  ...,  -4.6051,  -6.0464,  -7.1379],\n",
            "         ...,\n",
            "         [ -5.9898,  -5.2896,  -5.0846,  ...,  -4.5363,  -6.7291,  -0.8349],\n",
            "         [ -7.6071,  -6.8617,  -6.7399,  ...,  -7.0700,  -7.2433,  -7.6368],\n",
            "         [ -0.9462,  -1.0198,  -1.0438,  ...,  -2.0391,  -1.9180,  -1.7879]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.4294,  -2.8826,  -4.2138,  ...,  -1.6572,  -1.6939,  -3.4354],\n",
            "         [ -6.5860,  -5.5231,  -6.0293,  ...,  -5.2168,  -3.8410,  -5.4205],\n",
            "         [ -2.8299,  -2.8644,  -7.0209,  ...,  -4.4446,  -5.8092,  -6.7519],\n",
            "         ...,\n",
            "         [ -5.7391,  -5.1051,  -4.6744,  ...,  -4.3946,  -6.4237,  -0.9302],\n",
            "         [ -7.2819,  -6.4100,  -6.3357,  ...,  -6.6930,  -6.9426,  -7.1687],\n",
            "         [ -1.2139,  -1.3155,  -1.3061,  ...,  -2.1847,  -2.0692,  -1.9214]],\n",
            "\n",
            "        [[ -2.2699,  -2.6031,  -4.5505,  ...,  -1.2918,  -1.3934,  -3.0630],\n",
            "         [ -7.6866,  -5.8668,  -6.7203,  ...,  -6.1039,  -4.4696,  -5.7778],\n",
            "         [ -2.6295,  -2.9930,  -8.4401,  ...,  -5.0054,  -6.9881,  -7.8444],\n",
            "         ...,\n",
            "         [ -6.8785,  -5.6017,  -5.1620,  ...,  -4.6912,  -7.6155,  -0.9195],\n",
            "         [ -8.7667,  -6.9574,  -7.3628,  ...,  -7.9560,  -8.0956,  -8.5222],\n",
            "         [ -1.4999,  -1.6398,  -1.8882,  ...,  -2.5348,  -2.5063,  -2.0058]],\n",
            "\n",
            "        [[ -2.3576,  -2.6774,  -4.0774,  ...,  -1.5237,  -1.5295,  -3.1481],\n",
            "         [ -6.7399,  -5.3781,  -5.9938,  ...,  -5.3902,  -3.9518,  -5.3294],\n",
            "         [ -2.6732,  -2.8624,  -7.1806,  ...,  -4.4899,  -6.0264,  -6.8215],\n",
            "         ...,\n",
            "         [ -5.9039,  -5.1376,  -4.5797,  ...,  -4.3733,  -6.5831,  -0.9986],\n",
            "         [ -7.5247,  -6.2917,  -6.3353,  ...,  -6.8443,  -7.0515,  -7.3052],\n",
            "         [ -1.4655,  -1.5803,  -1.6046,  ...,  -2.3748,  -2.2851,  -1.9979]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.5261,  0.5890, -0.9335,  ...,  1.3495,  1.1359,  1.5793],\n",
            "        [ 0.4979,  0.5747, -0.4838,  ...,  0.8032,  0.5892,  1.0131],\n",
            "        [ 1.1214,  1.2709, -0.5366,  ...,  0.7160,  0.7632,  1.6049],\n",
            "        ...,\n",
            "        [ 1.7839,  1.7073,  0.3849,  ..., -0.8524,  0.4770,  1.3929],\n",
            "        [ 0.4510,  0.3599, -1.1638,  ...,  1.5239,  1.2825,  1.7993],\n",
            "        [ 0.5145,  0.6015, -0.7031,  ...,  1.0758,  0.8593,  1.2946]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.5261,  0.5890, -0.9335,  ...,  1.9283,  1.5635, -0.0623],\n",
            "         [-4.1014, -2.3440, -2.9758,  ..., -1.9666, -0.8181, -2.3052],\n",
            "         [ 0.1124,  0.6129, -4.1128,  ..., -1.1033, -3.0551, -3.8460],\n",
            "         ...,\n",
            "         [-3.1935, -1.9032, -1.4522,  ..., -0.9943, -3.7748,  2.6994],\n",
            "         [-4.9412, -3.3143, -3.2830,  ..., -3.7436, -4.3510, -4.3468],\n",
            "         [ 1.8334,  2.2784,  2.2845,  ...,  1.3495,  1.1359,  1.5793]],\n",
            "\n",
            "        [[ 0.4979,  0.5747, -0.4838,  ...,  1.5699,  1.3126,  0.1769],\n",
            "         [-3.0009, -1.5662, -2.0261,  ..., -1.5675, -0.7170, -1.5526],\n",
            "         [ 0.1984,  0.4396, -2.9193,  ..., -0.7924, -2.2766, -2.6156],\n",
            "         ...,\n",
            "         [-2.2213, -1.4086, -0.9132,  ..., -0.7866, -2.6189,  1.8129],\n",
            "         [-3.5403, -2.3165, -2.2759,  ..., -2.4853, -3.0091, -2.9611],\n",
            "         [ 1.1317,  1.3477,  1.3258,  ...,  0.8032,  0.5892,  1.0131]],\n",
            "\n",
            "        [[ 1.1214,  1.2709, -0.5366,  ...,  2.6024,  2.5321,  1.0579],\n",
            "         [-5.1872, -2.2984, -2.8432,  ..., -2.9457, -1.3834, -2.1898],\n",
            "         [ 0.6690,  0.6679, -5.1448,  ..., -1.8160, -3.9043, -4.8204],\n",
            "         ...,\n",
            "         [-4.3369, -2.0733, -1.3842,  ..., -1.0924, -4.3513,  2.5280],\n",
            "         [-6.3643, -3.6603, -3.8263,  ..., -4.8328, -4.8798, -5.5067],\n",
            "         [ 1.3990,  1.5419,  1.5313,  ...,  0.7160,  0.7632,  1.6049]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.7839,  1.7073,  0.3849,  ...,  1.8510,  2.1656,  2.3856],\n",
            "         [-4.1713, -1.2458, -1.8786,  ..., -2.9397, -2.3091, -1.1845],\n",
            "         [ 1.1513,  0.7084, -4.1574,  ..., -2.5877, -3.5847, -3.8529],\n",
            "         ...,\n",
            "         [-3.7740, -1.6815, -0.9697,  ..., -1.1865, -2.9345,  0.5945],\n",
            "         [-5.3618, -2.9419, -3.2200,  ..., -3.6970, -3.0453, -4.0417],\n",
            "         [ 0.9173,  0.6305,  0.0139,  ..., -0.8524,  0.4770,  1.3929]],\n",
            "\n",
            "        [[ 0.4510,  0.3599, -1.1638,  ...,  1.8056,  1.3233, -0.2602],\n",
            "         [-3.9220, -2.5140, -3.0426,  ..., -1.8187, -0.8733, -2.3823],\n",
            "         [-0.1100,  0.4775, -3.8398,  ..., -1.1005, -2.9302, -3.6549],\n",
            "         ...,\n",
            "         [-2.9926, -1.7532, -1.6510,  ..., -1.0304, -3.6187,  2.7237],\n",
            "         [-4.6152, -3.4586, -3.2545,  ..., -3.6176, -4.1178, -4.1912],\n",
            "         [ 2.1626,  2.6238,  2.6349,  ...,  1.5239,  1.2825,  1.7993]],\n",
            "\n",
            "        [[ 0.5145,  0.6015, -0.7031,  ...,  1.7870,  1.4714,  0.0694],\n",
            "         [-3.6119, -1.9585, -2.5218,  ..., -1.7882, -0.7391, -1.9517],\n",
            "         [ 0.1855,  0.5410, -3.5699,  ..., -0.9527, -2.6931, -3.2823],\n",
            "         ...,\n",
            "         [-2.7621, -1.6820, -1.1727,  ..., -0.9001, -3.2435,  2.2846],\n",
            "         [-4.3049, -2.8367, -2.8169,  ..., -3.1592, -3.7489, -3.7192],\n",
            "         [ 1.4660,  1.8014,  1.7911,  ...,  1.0758,  0.8593,  1.2946]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[-2.4547, -2.9242, -4.5260,  ..., -1.6034, -1.6596, -3.5767],\n",
            "         [-7.0822, -5.8572, -6.5683,  ..., -5.4983, -4.0412, -5.8196],\n",
            "         [-2.8684, -2.9003, -7.7053,  ..., -4.6350, -6.2782, -7.3604],\n",
            "         ...,\n",
            "         [-6.1743, -5.4163, -5.0447,  ..., -4.5260, -6.9980, -0.8150],\n",
            "         [-7.9221, -6.8275, -6.8755,  ..., -7.2753, -7.5741, -7.8612],\n",
            "         [-1.1474, -1.2348, -1.3080,  ..., -2.1822, -2.0873, -1.9351]],\n",
            "\n",
            "        [[-2.3437, -2.6214, -3.5465,  ..., -1.7099, -1.6042, -2.9198],\n",
            "         [-5.8425, -4.7624, -5.0888,  ..., -4.8473, -3.6338, -4.6492],\n",
            "         [-2.6431, -2.7565, -5.9819,  ..., -4.0722, -5.1934, -5.7122],\n",
            "         ...,\n",
            "         [-5.0628, -4.6047, -3.9759,  ..., -4.0664, -5.5357, -1.2837],\n",
            "         [-6.3818, -5.5127, -5.3385,  ..., -5.7652, -5.9260, -6.0577],\n",
            "         [-1.7098, -1.8485, -1.7369,  ..., -2.4767, -2.3277, -2.0836]],\n",
            "\n",
            "        [[-2.0853, -2.3919, -4.6510,  ..., -1.1119, -1.2233, -2.5582],\n",
            "         [-8.3938, -5.9611, -6.9575,  ..., -6.6600, -5.1388, -5.8059],\n",
            "         [-2.5377, -2.9949, -9.2592,  ..., -5.5303, -7.6597, -8.4365],\n",
            "         ...,\n",
            "         [-7.5435, -5.7361, -5.4985,  ..., -4.8067, -8.1067, -1.0881],\n",
            "         [-9.5710, -7.3231, -7.9406,  ..., -8.5471, -8.6352, -9.1228],\n",
            "         [-1.8076, -2.1208, -2.5830,  ..., -2.9983, -2.9922, -2.0112]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.6052, -1.8762, -3.5211,  ..., -1.5091, -1.4880, -1.2844],\n",
            "         [-7.5603, -4.8292, -5.7846,  ..., -6.2998, -5.9627, -4.8545],\n",
            "         [-2.2377, -2.8751, -8.0633,  ..., -5.9478, -7.2382, -7.5230],\n",
            "         ...,\n",
            "         [-7.1630, -5.2649, -4.8757,  ..., -4.5466, -6.5880, -3.0755],\n",
            "         [-8.7509, -6.5254, -7.1260,  ..., -7.0571, -6.6988, -7.7118],\n",
            "         [-2.4718, -2.9530, -3.8920,  ..., -4.2124, -3.1765, -2.2771]],\n",
            "\n",
            "        [[-2.5710, -3.1905, -4.7499,  ..., -1.7123, -1.8248, -3.7980],\n",
            "         [-6.9440, -6.0645, -6.6288,  ..., -5.3366, -4.0214, -5.9202],\n",
            "         [-3.1320, -3.0730, -7.4259,  ..., -4.6183, -6.0783, -7.1928],\n",
            "         ...,\n",
            "         [-6.0145, -5.3036, -5.2372,  ..., -4.5483, -6.7667, -0.8142],\n",
            "         [-7.6371, -7.0090, -6.8406,  ..., -7.1355, -7.2659, -7.7290],\n",
            "         [-0.8594, -0.9267, -0.9512,  ..., -1.9939, -1.8656, -1.7385]],\n",
            "\n",
            "        [[-2.3862, -2.7452, -4.0251,  ..., -1.6224, -1.6023, -3.2229],\n",
            "         [-6.5126, -5.3052, -5.8438,  ..., -5.1976, -3.8128, -5.2441],\n",
            "         [-2.7152, -2.8057, -6.8919,  ..., -4.3621, -5.7669, -6.5746],\n",
            "         ...,\n",
            "         [-5.6629, -5.0287, -4.4946,  ..., -4.3095, -6.3173, -1.0077],\n",
            "         [-7.2056, -6.1834, -6.1389,  ..., -6.5685, -6.8226, -7.0115],\n",
            "         [-1.4347, -1.5454, -1.5309,  ..., -2.3335, -2.2144, -1.9977]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.1897,  2.0949,  0.5068,  ..., -1.1504,  0.6605,  1.7267],\n",
            "        [ 0.7173,  0.8577, -0.6651,  ...,  0.9762,  0.8351,  1.3672],\n",
            "        [ 1.5575,  1.5681,  0.2697,  ..., -0.5254,  0.4205,  1.2991],\n",
            "        ...,\n",
            "        [ 1.4079,  1.5003, -0.0897,  ...,  0.0159,  0.5172,  1.5299],\n",
            "        [ 2.0688,  1.8702,  0.5356,  ..., -1.3699,  0.5696,  1.5361],\n",
            "        [ 0.7423,  0.9356, -0.9104,  ...,  1.2974,  1.1431,  1.7170]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.1897e+00,  2.0949e+00,  5.0681e-01,  ...,  2.1397e+00,\n",
            "           2.6051e+00,  2.9776e+00],\n",
            "         [-5.0429e+00, -1.4941e+00, -2.2375e+00,  ..., -3.5735e+00,\n",
            "          -2.8513e+00, -1.4351e+00],\n",
            "         [ 1.4613e+00,  8.7980e-01, -5.1005e+00,  ..., -3.2744e+00,\n",
            "          -4.3913e+00, -4.7632e+00],\n",
            "         ...,\n",
            "         [-4.6682e+00, -1.9994e+00, -1.1708e+00,  ..., -1.3982e+00,\n",
            "          -3.6179e+00,  5.6325e-01],\n",
            "         [-6.6495e+00, -3.5966e+00, -3.9605e+00,  ..., -4.5890e+00,\n",
            "          -3.6504e+00, -4.9839e+00],\n",
            "         [ 1.1140e+00,  7.8153e-01, -3.6193e-03,  ..., -1.1504e+00,\n",
            "           6.6048e-01,  1.7267e+00]],\n",
            "\n",
            "        [[ 7.1730e-01,  8.5767e-01, -6.6508e-01,  ...,  2.1139e+00,\n",
            "           1.9007e+00,  3.7903e-01],\n",
            "         [-4.2670e+00, -2.1521e+00, -2.7296e+00,  ..., -2.2701e+00,\n",
            "          -9.5151e-01, -2.0846e+00],\n",
            "         [ 3.6914e-01,  5.7804e-01, -4.2361e+00,  ..., -1.2319e+00,\n",
            "          -3.2610e+00, -3.9191e+00],\n",
            "         ...,\n",
            "         [-3.4210e+00, -1.8955e+00, -1.2641e+00,  ..., -9.5239e-01,\n",
            "          -3.8182e+00,  2.4145e+00],\n",
            "         [-5.2224e+00, -3.1641e+00, -3.2626e+00,  ..., -3.9286e+00,\n",
            "          -4.2683e+00, -4.5414e+00],\n",
            "         [ 1.4083e+00,  1.7286e+00,  1.7402e+00,  ...,  9.7622e-01,\n",
            "           8.3511e-01,  1.3672e+00]],\n",
            "\n",
            "        [[ 1.5575e+00,  1.5681e+00,  2.6974e-01,  ...,  1.9408e+00,\n",
            "           2.2391e+00,  2.0550e+00],\n",
            "         [-4.1432e+00, -1.3199e+00, -1.8686e+00,  ..., -2.8322e+00,\n",
            "          -2.0447e+00, -1.2610e+00],\n",
            "         [ 1.0498e+00,  7.5506e-01, -4.1246e+00,  ..., -2.3693e+00,\n",
            "          -3.4094e+00, -3.8341e+00],\n",
            "         ...,\n",
            "         [-3.6064e+00, -1.6956e+00, -9.6359e-01,  ..., -1.0247e+00,\n",
            "          -2.9882e+00,  8.5004e-01],\n",
            "         [-5.2684e+00, -2.8872e+00, -3.1235e+00,  ..., -3.7299e+00,\n",
            "          -3.3346e+00, -4.1509e+00],\n",
            "         [ 8.3580e-01,  6.6830e-01,  2.1331e-01,  ..., -5.2541e-01,\n",
            "           4.2050e-01,  1.2991e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.4079e+00,  1.5003e+00, -8.9693e-02,  ...,  2.3974e+00,\n",
            "           2.5555e+00,  1.7466e+00],\n",
            "         [-4.9020e+00, -1.8303e+00, -2.3388e+00,  ..., -3.0876e+00,\n",
            "          -1.8201e+00, -1.7425e+00],\n",
            "         [ 9.7127e-01,  8.0213e-01, -4.8569e+00,  ..., -2.2699e+00,\n",
            "          -3.8138e+00, -4.5349e+00],\n",
            "         ...,\n",
            "         [-4.1540e+00, -1.8660e+00, -1.2199e+00,  ..., -1.0287e+00,\n",
            "          -3.8003e+00,  1.6796e+00],\n",
            "         [-6.1207e+00, -3.3936e+00, -3.6114e+00,  ..., -4.5216e+00,\n",
            "          -4.3016e+00, -5.0878e+00],\n",
            "         [ 1.0648e+00,  9.8934e-01,  7.9928e-01,  ...,  1.5888e-02,\n",
            "           5.1716e-01,  1.5299e+00]],\n",
            "\n",
            "        [[ 2.0688e+00,  1.8702e+00,  5.3555e-01,  ...,  1.5912e+00,\n",
            "           2.0276e+00,  2.8383e+00],\n",
            "         [-4.1571e+00, -1.2964e+00, -1.8621e+00,  ..., -3.0925e+00,\n",
            "          -2.7018e+00, -1.1029e+00],\n",
            "         [ 1.2948e+00,  6.9873e-01, -4.1911e+00,  ..., -2.9067e+00,\n",
            "          -3.8958e+00, -3.8287e+00],\n",
            "         ...,\n",
            "         [-3.9185e+00, -1.6525e+00, -9.6107e-01,  ..., -1.3506e+00,\n",
            "          -2.9239e+00,  2.5523e-01],\n",
            "         [-5.4612e+00, -3.1011e+00, -3.3465e+00,  ..., -3.6045e+00,\n",
            "          -2.6323e+00, -3.9061e+00],\n",
            "         [ 1.1374e+00,  6.0355e-01, -2.1827e-01,  ..., -1.3699e+00,\n",
            "           5.6958e-01,  1.5361e+00]],\n",
            "\n",
            "        [[ 7.4233e-01,  9.3565e-01, -9.1038e-01,  ...,  2.4354e+00,\n",
            "           2.1528e+00,  2.9491e-01],\n",
            "         [-5.1200e+00, -2.6538e+00, -3.3848e+00,  ..., -2.5964e+00,\n",
            "          -9.9595e-01, -2.6122e+00],\n",
            "         [ 3.7327e-01,  7.2316e-01, -5.1266e+00,  ..., -1.4588e+00,\n",
            "          -3.8559e+00, -4.8191e+00],\n",
            "         ...,\n",
            "         [-4.1579e+00, -2.2632e+00, -1.5788e+00,  ..., -1.0814e+00,\n",
            "          -4.6826e+00,  3.0260e+00],\n",
            "         [-6.3031e+00, -3.8357e+00, -3.9678e+00,  ..., -4.8556e+00,\n",
            "          -5.2587e+00, -5.5827e+00],\n",
            "         [ 1.7898e+00,  2.2572e+00,  2.3111e+00,  ...,  1.2974e+00,\n",
            "           1.1431e+00,  1.7170e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.4525,  -1.7837,  -3.9552,  ...,  -1.4770,  -1.5241,  -1.0714],\n",
            "         [ -8.6851,  -5.3726,  -6.6995,  ...,  -7.1902,  -6.9805,  -5.4841],\n",
            "         [ -2.1809,  -2.9987,  -9.5625,  ...,  -6.8911,  -8.5205,  -8.8122],\n",
            "         ...,\n",
            "         [ -8.3105,  -5.8780,  -5.6328,  ...,  -5.0149,  -7.7471,  -3.4858],\n",
            "         [-10.2917,  -7.4751,  -8.4225,  ...,  -8.2057,  -7.7796,  -9.0330],\n",
            "         [ -2.5282,  -3.0970,  -4.4656,  ...,  -4.7671,  -3.4687,  -2.3224]],\n",
            "\n",
            "        [[ -2.2714,  -2.5898,  -4.2904,  ...,  -1.3996,  -1.4198,  -3.0266],\n",
            "         [ -7.2558,  -5.5997,  -6.3549,  ...,  -5.7836,  -4.2721,  -5.4903],\n",
            "         [ -2.6196,  -2.8695,  -7.8615,  ...,  -4.7454,  -6.5815,  -7.3248],\n",
            "         ...,\n",
            "         [ -6.4098,  -5.3430,  -4.8895,  ...,  -4.4659,  -7.1388,  -0.9912],\n",
            "         [ -8.2111,  -6.6116,  -6.8880,  ...,  -7.4421,  -7.5889,  -7.9470],\n",
            "         [ -1.5804,  -1.7189,  -1.8851,  ...,  -2.5373,  -2.4855,  -2.0385]],\n",
            "\n",
            "        [[ -1.7440,  -1.9735,  -3.5227,  ...,  -1.4271,  -1.3298,  -1.4825],\n",
            "         [ -7.4447,  -4.8615,  -5.6610,  ...,  -6.2001,  -5.6136,  -4.7985],\n",
            "         [ -2.2517,  -2.7865,  -7.9170,  ...,  -5.7373,  -6.9784,  -7.3716],\n",
            "         ...,\n",
            "         [ -6.9078,  -5.2372,  -4.7560,  ...,  -4.3926,  -6.5571,  -2.6874],\n",
            "         [ -8.5699,  -6.4288,  -6.9159,  ...,  -7.0979,  -6.9035,  -7.6884],\n",
            "         [ -2.4657,  -2.8733,  -3.5791,  ...,  -3.8934,  -3.1485,  -2.2384]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.8968,  -2.1601,  -4.1237,  ...,  -1.2042,  -1.2136,  -1.8211],\n",
            "         [ -8.2068,  -5.4907,  -6.3728,  ...,  -6.6893,  -5.5892,  -5.3102],\n",
            "         [ -2.3334,  -2.8583,  -8.8909,  ...,  -5.8716,  -7.5828,  -8.1026],\n",
            "         ...,\n",
            "         [ -7.4588,  -5.5264,  -5.2539,  ...,  -4.6304,  -7.5694,  -1.8881],\n",
            "         [ -9.4254,  -7.0540,  -7.6454,  ...,  -8.1233,  -8.0706,  -8.6555],\n",
            "         [ -2.2399,  -2.6710,  -3.2347,  ...,  -3.5858,  -3.2519,  -2.0378]],\n",
            "\n",
            "        [[ -1.4552,  -1.7637,  -3.5301,  ...,  -1.7361,  -1.7670,  -1.0555],\n",
            "         [ -7.6810,  -4.9303,  -5.9278,  ...,  -6.4199,  -6.4964,  -4.9967],\n",
            "         [ -2.2292,  -2.9352,  -8.2567,  ...,  -6.2341,  -7.6903,  -7.7225],\n",
            "         ...,\n",
            "         [ -7.4425,  -5.2864,  -5.0268,  ...,  -4.6780,  -6.7184,  -3.6385],\n",
            "         [ -8.9852,  -6.7350,  -7.4122,  ...,  -6.9318,  -6.4268,  -7.7999],\n",
            "         [ -2.3866,  -3.0303,  -4.2840,  ...,  -4.6972,  -3.2249,  -2.3577]],\n",
            "\n",
            "        [[ -2.3663,  -2.7605,  -4.9768,  ...,  -1.3008,  -1.4567,  -3.4619],\n",
            "         [ -8.2286,  -6.3499,  -7.4512,  ...,  -6.3326,  -4.6055,  -6.3690],\n",
            "         [ -2.7353,  -2.9730,  -9.1930,  ...,  -5.1949,  -7.4654,  -8.5759],\n",
            "         ...,\n",
            "         [ -7.2665,  -5.9593,  -5.6452,  ...,  -4.8176,  -8.2921,  -0.7308],\n",
            "         [ -9.4117,  -7.5318,  -8.0343,  ...,  -8.5917,  -8.8682,  -9.3395],\n",
            "         [ -1.3188,  -1.4389,  -1.7554,  ...,  -2.4388,  -2.4664,  -2.0398]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.7649,  1.6258,  0.4638,  ..., -1.0711,  0.4234,  1.3257],\n",
            "        [ 2.3511,  2.1378,  0.6246,  ..., -1.6570,  0.6953,  1.7576],\n",
            "        [ 1.9529,  1.8105,  0.4909,  ..., -1.1578,  0.4956,  1.4822],\n",
            "        ...,\n",
            "        [ 2.0918,  1.9312,  0.5233,  ..., -1.2806,  0.5516,  1.5839],\n",
            "        [ 0.4562,  0.3508, -0.7007,  ...,  1.0240,  0.7349,  1.1505],\n",
            "        [ 0.9545,  1.1194, -0.6791,  ...,  0.9136,  0.8705,  1.5794]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.7649,  1.6258,  0.4638,  ...,  1.5296,  1.9000,  2.3887],\n",
            "         [-3.7520, -1.1443, -1.7160,  ..., -2.7578, -2.3293, -1.0230],\n",
            "         [ 1.1192,  0.6435, -3.7343,  ..., -2.5133, -3.4053, -3.4110],\n",
            "         ...,\n",
            "         [-3.3972, -1.4822, -0.8625,  ..., -1.1092, -2.5945,  0.3370],\n",
            "         [-4.8083, -2.7271, -2.9602,  ..., -3.2173, -2.4613, -3.4890],\n",
            "         [ 0.9632,  0.5283, -0.1680,  ..., -1.0711,  0.4234,  1.3257]],\n",
            "\n",
            "        [[ 2.3511,  2.1378,  0.6246,  ...,  1.6934,  2.2373,  3.2675],\n",
            "         [-4.6479, -1.4817, -2.0571,  ..., -3.4996, -3.1064, -1.2384],\n",
            "         [ 1.5005,  0.8035, -4.7387,  ..., -3.3721, -4.4451, -4.3340],\n",
            "         ...,\n",
            "         [-4.4516, -1.8368, -1.0736,  ..., -1.5115, -3.3251,  0.1612],\n",
            "         [-6.2303, -3.5336, -3.8045,  ..., -4.0851, -2.8981, -4.4166],\n",
            "         [ 1.3159,  0.6834, -0.2617,  ..., -1.6570,  0.6953,  1.7576]],\n",
            "\n",
            "        [[ 1.9529,  1.8105,  0.4909,  ...,  1.7371,  2.1484,  2.6504],\n",
            "         [-4.2167, -1.2773, -1.9036,  ..., -3.0976, -2.5672, -1.1730],\n",
            "         [ 1.2583,  0.7411, -4.2318,  ..., -2.8277, -3.7997, -3.8921],\n",
            "         ...,\n",
            "         [-3.8626, -1.6587, -0.9832,  ..., -1.2273, -2.9557,  0.3572],\n",
            "         [-5.4980, -3.0658, -3.3537,  ..., -3.6925, -2.8453, -3.9925],\n",
            "         [ 1.0432,  0.6003, -0.1302,  ..., -1.1578,  0.4956,  1.4822]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.0918,  1.9312,  0.5233,  ...,  1.7984,  2.2465,  2.8549],\n",
            "         [-4.4483, -1.3604, -1.9927,  ..., -3.2909, -2.7481, -1.2339],\n",
            "         [ 1.3497,  0.7878, -4.4888,  ..., -3.0335, -4.0517, -4.1290],\n",
            "         ...,\n",
            "         [-4.1240, -1.7482, -1.0417,  ..., -1.3231, -3.1404,  0.3212],\n",
            "         [-5.8626, -3.2663, -3.5706,  ..., -3.9167, -2.9776, -4.2297],\n",
            "         [ 1.1232,  0.6359, -0.1407,  ..., -1.2806,  0.5516,  1.5839]],\n",
            "\n",
            "        [[ 0.4562,  0.3508, -0.7007,  ...,  1.4247,  1.0149, -0.1493],\n",
            "         [-2.8372, -1.7515, -2.1033,  ..., -1.3609, -0.6891, -1.6063],\n",
            "         [ 0.0159,  0.4808, -2.7311,  ..., -0.7473, -2.1304, -2.4985],\n",
            "         ...,\n",
            "         [-2.0205, -1.2801, -1.1008,  ..., -0.7896, -2.5245,  1.9200],\n",
            "         [-3.2226, -2.5094, -2.3688,  ..., -2.3316, -2.9222, -2.8105],\n",
            "         [ 1.4550,  1.6748,  1.6521,  ...,  1.0240,  0.7349,  1.1505]],\n",
            "\n",
            "        [[ 0.9545,  1.1194, -0.6791,  ...,  2.4964,  2.3744,  0.7085],\n",
            "         [-5.1077, -2.4211, -3.0404,  ..., -2.7839, -1.2137, -2.3304],\n",
            "         [ 0.5520,  0.7128, -5.0891,  ..., -1.6212, -3.8674, -4.7474],\n",
            "         ...,\n",
            "         [-4.1728, -2.1340, -1.4588,  ..., -1.0376, -4.4612,  2.6831],\n",
            "         [-6.2904, -3.6875, -3.8499,  ..., -4.8022, -4.9875, -5.4959],\n",
            "         [ 1.4879,  1.7682,  1.7873,  ...,  0.9136,  0.8705,  1.5794]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[-1.5979, -1.8622, -3.3016,  ..., -1.6937, -1.6358, -1.2532],\n",
            "         [-7.1148, -4.6323, -5.4814,  ..., -5.9810, -5.8651, -4.6648],\n",
            "         [-2.2436, -2.8445, -7.4997,  ..., -5.7365, -6.9410, -7.0529],\n",
            "         ...,\n",
            "         [-6.7600, -4.9702, -4.6279,  ..., -4.3324, -6.1303, -3.3048],\n",
            "         [-8.1711, -6.2151, -6.7257,  ..., -6.4405, -5.9971, -7.1308],\n",
            "         [-2.3997, -2.9597, -3.9335,  ..., -4.2943, -3.1124, -2.3162]],\n",
            "\n",
            "        [[-1.3534, -1.6730, -3.7928,  ..., -1.7869, -1.8682, -0.9147],\n",
            "         [-8.3525, -5.2925, -6.4745,  ..., -6.9799, -7.2118, -5.4206],\n",
            "         [-2.2040, -3.0073, -9.1561,  ..., -6.8523, -8.5505, -8.5162],\n",
            "         ...,\n",
            "         [-8.1562, -5.6476, -5.4910,  ..., -4.9917, -7.4305, -4.0210],\n",
            "         [-9.9349, -7.3444, -8.2220,  ..., -7.5654, -7.0035, -8.5988],\n",
            "         [-2.3887, -3.1274, -4.6791,  ..., -5.1372, -3.4101, -2.4246]],\n",
            "\n",
            "        [[-1.5224, -1.8149, -3.5339,  ..., -1.6234, -1.6105, -1.1592],\n",
            "         [-7.6919, -4.9026, -5.9284,  ..., -6.4581, -6.3260, -4.9826],\n",
            "         [-2.2169, -2.8843, -8.2566,  ..., -6.1882, -7.5586, -7.7017],\n",
            "         ...,\n",
            "         [-7.3378, -5.2841, -5.0081,  ..., -4.5878, -6.7145, -3.4524],\n",
            "         [-8.9732, -6.6911, -7.3785,  ..., -7.0529, -6.6041, -7.8021],\n",
            "         [-2.4320, -3.0250, -4.1550,  ..., -4.5183, -3.2632, -2.3274]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.4646, -1.7765, -3.6622,  ..., -1.6323, -1.6518, -1.0808],\n",
            "         [-8.0048, -5.0681, -6.1782,  ..., -6.7216, -6.6464, -5.1696],\n",
            "         [-2.2068, -2.9199, -8.6742,  ..., -6.4642, -7.9500, -8.0647],\n",
            "         ...,\n",
            "         [-7.6805, -5.4559, -5.2272,  ..., -4.7537, -7.0387, -3.6144],\n",
            "         [-9.4191, -6.9739, -7.7561,  ..., -7.3473, -6.8759, -8.1653],\n",
            "         [-2.4333, -3.0718, -4.3262,  ..., -4.7112, -3.3467, -2.3518]],\n",
            "\n",
            "        [[-2.3795, -2.8470, -3.7212,  ..., -1.8666, -1.8341, -3.2580],\n",
            "         [-5.6729, -4.9494, -5.1238,  ..., -4.6522, -3.5381, -4.7150],\n",
            "         [-2.8199, -2.7171, -5.7516,  ..., -4.0386, -4.9795, -5.6073],\n",
            "         ...,\n",
            "         [-4.8562, -4.4780, -4.1213,  ..., -4.0810, -5.3735, -1.1887],\n",
            "         [-6.0584, -5.7073, -5.3893,  ..., -5.6230, -5.7713, -5.9193],\n",
            "         [-1.3807, -1.5231, -1.3684,  ..., -2.2673, -2.1141, -1.9583]],\n",
            "\n",
            "        [[-2.1876, -2.5186, -4.7381,  ..., -1.1981, -1.2957, -2.9164],\n",
            "         [-8.2498, -6.0591, -7.0994,  ..., -6.4783, -4.8838, -5.9554],\n",
            "         [-2.5901, -2.9253, -9.1480,  ..., -5.3157, -7.5375, -8.3723],\n",
            "         ...,\n",
            "         [-7.3149, -5.7720, -5.5178,  ..., -4.7321, -8.1313, -0.9419],\n",
            "         [-9.4325, -7.3255, -7.9088,  ..., -8.4966, -8.6576, -9.1208],\n",
            "         [-1.6542, -1.8698, -2.2716,  ..., -2.7808, -2.7996, -2.0456]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.4690,  0.4133, -0.8179,  ...,  1.1360,  0.8755,  1.3131],\n",
            "        [ 2.0940,  1.9657,  0.5493,  ..., -1.2925,  0.5642,  1.6089],\n",
            "        [ 2.4643,  2.2606,  0.6996,  ..., -1.8422,  0.7739,  1.8616],\n",
            "        ...,\n",
            "        [ 0.7482,  0.9352, -0.7460,  ...,  1.0399,  0.9100,  1.4726],\n",
            "        [ 0.6395,  0.8414, -0.8979,  ...,  1.2839,  1.0964,  1.6323],\n",
            "        [ 0.6819,  0.8531, -0.7211,  ...,  1.0318,  0.8777,  1.4102]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.4690,  0.4133, -0.8179,  ...,  1.5752,  1.1776, -0.1518],\n",
            "         [-3.2860, -1.9876, -2.4459,  ..., -1.5585, -0.7547, -1.8592],\n",
            "         [ 0.0147,  0.5458, -3.2073,  ..., -0.8322, -2.4646, -2.9571],\n",
            "         ...,\n",
            "         [-2.3927, -1.4829, -1.2875,  ..., -0.8398, -2.9691,  2.1984],\n",
            "         [-3.8112, -2.8357, -2.7109,  ..., -2.8398, -3.4211, -3.3561],\n",
            "         [ 1.6116,  1.9076,  1.9074,  ...,  1.1360,  0.8755,  1.3131]],\n",
            "\n",
            "        [[ 2.0940,  1.9657,  0.5493,  ...,  1.8444,  2.2921,  2.8751],\n",
            "         [-4.5367, -1.3906, -2.0158,  ..., -3.3549, -2.7918, -1.2685],\n",
            "         [ 1.3757,  0.8163, -4.5834,  ..., -3.0910, -4.1241, -4.2227],\n",
            "         ...,\n",
            "         [-4.1818, -1.7784, -1.0619,  ..., -1.2970, -3.2144,  0.3130],\n",
            "         [-5.9870, -3.3296, -3.6415,  ..., -4.0132, -3.0571, -4.3317],\n",
            "         [ 1.1338,  0.6449, -0.1431,  ..., -1.2925,  0.5642,  1.6089]],\n",
            "\n",
            "        [[ 2.4643,  2.2606,  0.6996,  ...,  1.6867,  2.2672,  3.4662],\n",
            "         [-4.8146, -1.5648, -2.0995,  ..., -3.6520, -3.3084, -1.2782],\n",
            "         [ 1.5936,  0.8365, -4.9329,  ..., -3.5780, -4.6868, -4.5108],\n",
            "         ...,\n",
            "         [-4.6466, -1.9036, -1.1042,  ..., -1.5623, -3.4705,  0.0716],\n",
            "         [-6.5108, -3.7119, -3.9732,  ..., -4.2459, -2.9334, -4.5917],\n",
            "         [ 1.4159,  0.7119, -0.3192,  ..., -1.8422,  0.7739,  1.8616]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.7482,  0.9352, -0.7460,  ...,  2.2735,  2.0552,  0.3731],\n",
            "         [-4.6885, -2.3594, -3.0082,  ..., -2.4654, -1.0045, -2.2854],\n",
            "         [ 0.3961,  0.6781, -4.6712,  ..., -1.3121, -3.5749, -4.3341],\n",
            "         ...,\n",
            "         [-3.7452, -2.0566, -1.4255,  ..., -0.9601, -4.2243,  2.6424],\n",
            "         [-5.7611, -3.4715, -3.6020,  ..., -4.3906, -4.7176, -5.0512],\n",
            "         [ 1.4962,  1.8554,  1.8915,  ...,  1.0399,  0.9100,  1.4726]],\n",
            "\n",
            "        [[ 0.6395,  0.8414, -0.8979,  ...,  2.2525,  1.9587,  0.1368],\n",
            "         [-4.8230, -2.5382, -3.3167,  ..., -2.3649, -0.9179, -2.5297],\n",
            "         [ 0.2869,  0.7669, -4.8182,  ..., -1.2587, -3.6235, -4.5000],\n",
            "         ...,\n",
            "         [-3.7679, -2.1608, -1.5682,  ..., -0.9758, -4.4345,  2.9513],\n",
            "         [-5.8814, -3.6764, -3.7428,  ..., -4.5046, -5.0174, -5.1934],\n",
            "         [ 1.7440,  2.1980,  2.2695,  ...,  1.2839,  1.0964,  1.6323]],\n",
            "\n",
            "        [[ 0.6819,  0.8531, -0.7211,  ...,  2.1335,  1.9018,  0.2890],\n",
            "         [-4.4003, -2.2415, -2.8881,  ..., -2.2793, -0.9392, -2.1892],\n",
            "         [ 0.3416,  0.6568, -4.3728,  ..., -1.1968, -3.3479, -4.0444],\n",
            "         ...,\n",
            "         [-3.4560, -1.9543, -1.3609,  ..., -0.9199, -3.9674,  2.5427],\n",
            "         [-5.3694, -3.2954, -3.3802,  ..., -4.0600, -4.4562, -4.6899],\n",
            "         [ 1.4637,  1.8128,  1.8449,  ...,  1.0318,  0.8777,  1.4102]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.4058,  -2.8803,  -4.0200,  ...,  -1.7869,  -1.7807,  -3.3888],\n",
            "         [ -6.1609,  -5.2811,  -5.6480,  ...,  -4.9205,  -3.7130,  -5.0961],\n",
            "         [ -2.8601,  -2.7478,  -6.4094,  ...,  -4.1942,  -5.4229,  -6.1941],\n",
            "         ...,\n",
            "         [ -5.2676,  -4.7764,  -4.4896,  ...,  -4.2018,  -5.9274,  -1.0386],\n",
            "         [ -6.6861,  -6.1292,  -5.9130,  ...,  -6.2018,  -6.3794,  -6.5931],\n",
            "         [ -1.2632,  -1.3860,  -1.2948,  ...,  -2.2260,  -2.0828,  -1.9239]],\n",
            "\n",
            "        [[ -1.4790,  -1.7664,  -3.6801,  ...,  -1.6093,  -1.6482,  -1.0869],\n",
            "         [ -8.1097,  -5.1227,  -6.2452,  ...,  -6.8085,  -6.7320,  -5.2304],\n",
            "         [ -2.1973,  -2.9158,  -8.8128,  ...,  -6.5447,  -8.0643,  -8.1846],\n",
            "         ...,\n",
            "         [ -7.7548,  -5.5105,  -5.2913,  ...,  -4.7506,  -7.1546,  -3.6489],\n",
            "         [ -9.5600,  -7.0617,  -7.8709,  ...,  -7.4669,  -6.9974,  -8.2936],\n",
            "         [ -2.4393,  -3.0873,  -4.3725,  ...,  -4.7461,  -3.3761,  -2.3531]],\n",
            "\n",
            "        [[ -1.3246,  -1.6195,  -3.8653,  ...,  -1.8428,  -1.9773,  -0.8580],\n",
            "         [ -8.6036,  -5.4449,  -6.6643,  ...,  -7.1814,  -7.5529,  -5.6024],\n",
            "         [ -2.1954,  -3.0437,  -9.4978,  ...,  -7.1074,  -8.9313,  -8.8351],\n",
            "         ...,\n",
            "         [ -8.4355,  -5.7837,  -5.6690,  ...,  -5.0917,  -7.7150,  -4.2526],\n",
            "         [-10.2997,  -7.5921,  -8.5380,  ...,  -7.7753,  -7.1778,  -8.9159],\n",
            "         [ -2.3730,  -3.1682,  -4.8841,  ...,  -5.3717,  -3.4706,  -2.4626]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.2939,  -2.6095,  -4.5827,  ...,  -1.3312,  -1.4107,  -3.1668],\n",
            "         [ -7.7305,  -5.9041,  -6.8449,  ...,  -6.0701,  -4.4704,  -5.8254],\n",
            "         [ -2.6460,  -2.8666,  -8.5079,  ...,  -4.9168,  -7.0408,  -7.8740],\n",
            "         ...,\n",
            "         [ -6.7872,  -5.6013,  -5.2622,  ...,  -4.5648,  -7.6902,  -0.8976],\n",
            "         [ -8.8032,  -7.0162,  -7.4387,  ...,  -7.9953,  -8.1835,  -8.5912],\n",
            "         [ -1.5459,  -1.6893,  -1.9452,  ...,  -2.5649,  -2.5559,  -2.0673]],\n",
            "\n",
            "        [[ -2.4125,  -2.7796,  -4.8043,  ...,  -1.4050,  -1.5163,  -3.5560],\n",
            "         [ -7.8750,  -6.1593,  -7.2231,  ...,  -6.0225,  -4.3929,  -6.2226],\n",
            "         [ -2.7652,  -2.8542,  -8.7246,  ...,  -4.9163,  -7.0985,  -8.1929],\n",
            "         ...,\n",
            "         [ -6.8199,  -5.7819,  -5.4746,  ...,  -4.6333,  -7.9096,  -0.7415],\n",
            "         [ -8.9334,  -7.2975,  -7.6492,  ...,  -8.1621,  -8.4925,  -8.8863],\n",
            "         [ -1.3080,  -1.4230,  -1.6369,  ...,  -2.3736,  -2.3786,  -2.0606]],\n",
            "\n",
            "        [[ -2.3147,  -2.6276,  -4.4065,  ...,  -1.4073,  -1.4492,  -3.1796],\n",
            "         [ -7.3969,  -5.7222,  -6.5735,  ...,  -5.8201,  -4.2902,  -5.6578],\n",
            "         [ -2.6550,  -2.8238,  -8.0582,  ...,  -4.7376,  -6.6990,  -7.5130],\n",
            "         ...,\n",
            "         [ -6.4527,  -5.4350,  -5.0463,  ...,  -4.4607,  -7.3184,  -0.9260],\n",
            "         [ -8.3660,  -6.7760,  -7.0656,  ...,  -7.6008,  -7.8072,  -8.1586],\n",
            "         [ -1.5329,  -1.6678,  -1.8405,  ...,  -2.5090,  -2.4733,  -2.0584]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.3776, -0.0427, -0.9636,  ...,  1.1734,  0.7832,  1.2290],\n",
            "        [ 0.5024,  0.6379, -0.6257,  ...,  0.9380,  0.7297,  1.1804],\n",
            "        [ 2.5272,  2.3840,  0.6962,  ..., -1.7529,  0.7765,  1.9559],\n",
            "        ...,\n",
            "        [ 0.0797, -1.7790, -2.7965,  ...,  1.8050,  2.1609,  2.8286],\n",
            "        [ 2.1577,  2.0344,  0.6151,  ..., -1.4865,  0.6332,  1.6670],\n",
            "        [ 1.2098,  1.3984, -0.3032,  ...,  0.3350,  0.5692,  1.5252]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.3776, -0.0427, -0.9636,  ...,  1.1097,  0.7614, -0.4149],\n",
            "         [-2.3380, -1.9202, -2.0264,  ..., -1.0478, -0.6770, -1.4645],\n",
            "         [-0.2111,  0.2552, -2.2686,  ..., -0.5982, -1.8053, -2.1704],\n",
            "         ...,\n",
            "         [-1.5463, -0.9814, -1.2517,  ..., -0.8256, -2.0867,  1.8025],\n",
            "         [-2.5444, -2.4413, -2.1762,  ..., -2.0112, -2.3321, -2.3035],\n",
            "         [ 1.7832,  2.0251,  1.8782,  ...,  1.1734,  0.7832,  1.2290]],\n",
            "\n",
            "        [[ 0.5024,  0.6379, -0.6257,  ...,  1.7377,  1.4674,  0.1057],\n",
            "         [-3.5273, -1.8603, -2.4346,  ..., -1.7695, -0.7672, -1.8428],\n",
            "         [ 0.2080,  0.5863, -3.4725,  ..., -0.8596, -2.6610, -3.1451],\n",
            "         ...,\n",
            "         [-2.6049, -1.6278, -1.1522,  ..., -0.7914, -3.1480,  2.1499],\n",
            "         [-4.1970, -2.7389, -2.7206,  ..., -3.0608, -3.6191, -3.5980],\n",
            "         [ 1.3066,  1.5918,  1.6024,  ...,  0.9380,  0.7297,  1.1804]],\n",
            "\n",
            "        [[ 2.5272,  2.3840,  0.6962,  ...,  2.0071,  2.5880,  3.5794],\n",
            "         [-5.2781, -1.6891, -2.2590,  ..., -4.0057, -3.4528, -1.4508],\n",
            "         [ 1.7128,  0.9687, -5.4202,  ..., -3.8200, -4.9983, -4.9779],\n",
            "         ...,\n",
            "         [-5.0139, -2.0611, -1.2250,  ..., -1.5722, -3.8268,  0.1238],\n",
            "         [-7.1591, -4.0087, -4.3565,  ..., -4.7238, -3.4105, -5.0790],\n",
            "         [ 1.4490,  0.7647, -0.2141,  ..., -1.7529,  0.7765,  1.9559]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0797, -1.7790, -2.7965,  ...,  0.3808,  0.6537, -1.2538],\n",
            "         [-3.1797, -3.9770, -3.9498,  ..., -1.5095, -1.8633, -2.7018],\n",
            "         [-1.4024, -0.6884, -3.0642,  ..., -0.1504, -3.2792, -3.3770],\n",
            "         ...,\n",
            "         [-1.5793, -1.1214, -3.3263,  ..., -2.1743, -3.2266,  3.3106],\n",
            "         [-2.9057, -4.5844, -3.7629,  ..., -3.8387, -2.5710, -3.1656],\n",
            "         [ 4.3970,  5.5677,  4.5864,  ...,  1.8050,  2.1609,  2.8286]],\n",
            "\n",
            "        [[ 2.1577,  2.0344,  0.6151,  ...,  1.7357,  2.2173,  3.0301],\n",
            "         [-4.5211, -1.4371, -1.9670,  ..., -3.4005, -2.9532, -1.2353],\n",
            "         [ 1.4456,  0.8047, -4.5914,  ..., -3.2171, -4.2566, -4.2042],\n",
            "         ...,\n",
            "         [-4.2198, -1.7770, -1.0336,  ..., -1.3298, -3.2243,  0.1786],\n",
            "         [-6.0085, -3.4006, -3.6757,  ..., -3.9740, -2.8914, -4.2907],\n",
            "         [ 1.2446,  0.6494, -0.2272,  ..., -1.4865,  0.6332,  1.6670]],\n",
            "\n",
            "        [[ 1.2098,  1.3984, -0.3032,  ...,  2.5326,  2.5762,  1.3579],\n",
            "         [-5.0867, -2.0737, -2.5988,  ..., -3.0424, -1.6112, -1.9641],\n",
            "         [ 0.8132,  0.7956, -5.0443,  ..., -2.0116, -3.8904, -4.6856],\n",
            "         ...,\n",
            "         [-4.1673, -1.9368, -1.3352,  ..., -0.9236, -4.0973,  2.1084],\n",
            "         [-6.2554, -3.5408, -3.7296,  ..., -4.7195, -4.6173, -5.3248],\n",
            "         [ 1.1552,  1.1456,  1.0815,  ...,  0.3350,  0.5692,  1.5252]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.4791,  -3.2242,  -3.9054,  ...,  -2.1257,  -2.0266,  -3.4812],\n",
            "         [ -5.1947,  -5.1017,  -4.9682,  ...,  -4.2833,  -3.4649,  -4.5309],\n",
            "         [ -3.0679,  -2.9263,  -5.2104,  ...,  -3.8337,  -4.5932,  -5.2367],\n",
            "         ...,\n",
            "         [ -4.4031,  -4.1629,  -4.1935,  ...,  -4.0610,  -4.8746,  -1.2638],\n",
            "         [ -5.4011,  -5.6228,  -5.1180,  ...,  -5.2466,  -5.1200,  -5.3698],\n",
            "         [ -1.0735,  -1.1564,  -1.0637,  ...,  -2.0620,  -2.0047,  -1.8373]],\n",
            "\n",
            "        [[ -2.3800,  -2.6631,  -3.8960,  ...,  -1.6345,  -1.5776,  -3.1351],\n",
            "         [ -6.4098,  -5.1613,  -5.7048,  ...,  -5.1417,  -3.8122,  -5.0835],\n",
            "         [ -2.6745,  -2.7147,  -6.7428,  ...,  -4.2318,  -5.7060,  -6.3858],\n",
            "         ...,\n",
            "         [ -5.4874,  -4.9289,  -4.4224,  ...,  -4.1636,  -6.1930,  -1.0909],\n",
            "         [ -7.0794,  -6.0399,  -5.9909,  ...,  -6.4330,  -6.6640,  -6.8388],\n",
            "         [ -1.5759,  -1.7092,  -1.6679,  ...,  -2.4342,  -2.3153,  -2.0604]],\n",
            "\n",
            "        [[ -1.3398,  -1.6379,  -4.0904,  ...,  -1.6930,  -1.8503,  -0.8647],\n",
            "         [ -9.1451,  -5.7109,  -7.0456,  ...,  -7.7058,  -7.8911,  -5.8949],\n",
            "         [ -2.1542,  -3.0531, -10.2068,  ...,  -7.5201,  -9.4366,  -9.4219],\n",
            "         ...,\n",
            "         [ -8.8809,  -6.0830,  -6.0117,  ...,  -5.2724,  -8.2651,  -4.3203],\n",
            "         [-11.0261,  -8.0305,  -9.1431,  ...,  -8.4239,  -7.8488,  -9.5230],\n",
            "         [ -2.4180,  -3.2571,  -5.0007,  ...,  -5.4530,  -3.6618,  -2.4881]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -4.3968,  -7.3845,  -7.4953,  ...,  -2.9494,  -2.9567,  -5.3702],\n",
            "         [ -7.6562,  -9.5825,  -8.6486,  ...,  -4.8398,  -5.4737,  -6.8182],\n",
            "         [ -5.8789,  -6.2940,  -7.7630,  ...,  -3.4807,  -6.8895,  -7.4935],\n",
            "         ...,\n",
            "         [ -6.0558,  -6.7270,  -8.0251,  ...,  -5.5045,  -6.8369,  -0.8059],\n",
            "         [ -7.3822, -10.1899,  -8.4617,  ...,  -7.1690,  -6.1814,  -7.2821],\n",
            "         [ -0.0795,  -0.0378,  -0.1124,  ...,  -1.5253,  -1.4495,  -1.2878]],\n",
            "\n",
            "        [[ -1.4638,  -1.7121,  -3.6659,  ...,  -1.6939,  -1.7765,  -1.0227],\n",
            "         [ -8.1426,  -5.1836,  -6.2480,  ...,  -6.8301,  -6.9470,  -5.2881],\n",
            "         [ -2.1759,  -2.9418,  -8.8724,  ...,  -6.6467,  -8.2504,  -8.2570],\n",
            "         ...,\n",
            "         [ -7.8414,  -5.5235,  -5.3146,  ...,  -4.7594,  -7.2181,  -3.8742],\n",
            "         [ -9.6300,  -7.1471,  -7.9567,  ...,  -7.4035,  -6.8852,  -8.3435],\n",
            "         [ -2.3770,  -3.0971,  -4.5082,  ...,  -4.9161,  -3.3606,  -2.3858]],\n",
            "\n",
            "        [[ -2.0463,  -2.2544,  -4.3922,  ...,  -1.1176,  -1.1913,  -2.2129],\n",
            "         [ -8.3427,  -5.7265,  -6.6877,  ...,  -6.6926,  -5.3787,  -5.5349],\n",
            "         [ -2.4429,  -2.8572,  -9.1332,  ...,  -5.6618,  -7.6579,  -8.2564],\n",
            "         ...,\n",
            "         [ -7.4233,  -5.5896,  -5.4242,  ...,  -4.5739,  -7.8648,  -1.4624],\n",
            "         [ -9.5114,  -7.1936,  -7.8185,  ...,  -8.3697,  -8.3848,  -8.8956],\n",
            "         [ -2.1008,  -2.5072,  -3.0075,  ...,  -3.3153,  -3.1984,  -2.0456]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.4836,  0.6086, -0.6992,  ...,  1.0120,  0.8057,  1.2254],\n",
            "        [ 1.0418,  1.2475, -0.3392,  ...,  0.4315,  0.5303,  1.3782],\n",
            "        [ 0.6650,  0.9299, -0.8481,  ...,  1.1810,  1.0273,  1.5703],\n",
            "        ...,\n",
            "        [ 0.4949,  0.6670, -0.6443,  ...,  0.9649,  0.7561,  1.2093],\n",
            "        [ 0.4804,  0.5774, -1.0227,  ...,  1.3448,  1.1429,  1.6107],\n",
            "        [ 1.0628,  1.2333, -0.0692,  ...,  0.0593,  0.3317,  1.1958]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.4836,  0.6086, -0.6992,  ...,  1.7461,  1.4352,  0.0208],\n",
            "         [-3.5861, -1.9260, -2.5010,  ..., -1.7485, -0.7517, -1.8862],\n",
            "         [ 0.1669,  0.6141, -3.5312,  ..., -0.8397, -2.6833, -3.2059],\n",
            "         ...,\n",
            "         [-2.6308, -1.6553, -1.2293,  ..., -0.7960, -3.2079,  2.2294],\n",
            "         [-4.2447, -2.8328, -2.8071,  ..., -3.1147, -3.7137, -3.6638],\n",
            "         [ 1.3893,  1.6940,  1.7125,  ...,  1.0120,  0.8057,  1.2254]],\n",
            "\n",
            "        [[ 1.0418,  1.2475, -0.3392,  ...,  2.4029,  2.3706,  1.0912],\n",
            "         [-4.7213, -1.9801, -2.4683,  ..., -2.7771, -1.4265, -1.8533],\n",
            "         [ 0.6741,  0.7156, -4.6537,  ..., -1.7085, -3.5904, -4.3018],\n",
            "         ...,\n",
            "         [-3.7726, -1.8280, -1.2646,  ..., -0.8380, -3.8274,  2.0867],\n",
            "         [-5.7323, -3.2962, -3.4531,  ..., -4.3251, -4.3195, -4.8898],\n",
            "         [ 1.1115,  1.1154,  1.0842,  ...,  0.4315,  0.5303,  1.3782]],\n",
            "\n",
            "        [[ 0.6650,  0.9299, -0.8481,  ...,  2.3405,  2.0464,  0.2303],\n",
            "         [-4.8904, -2.5041, -3.2197,  ..., -2.4693, -0.9835, -2.4325],\n",
            "         [ 0.3518,  0.7468, -4.8807,  ..., -1.2704, -3.7028, -4.5347],\n",
            "         ...,\n",
            "         [-3.8343, -2.1626, -1.5589,  ..., -0.9232, -4.4533,  2.8374],\n",
            "         [-5.9861, -3.6728, -3.7818,  ..., -4.5910, -5.0080, -5.2794],\n",
            "         [ 1.6261,  2.0373,  2.1121,  ...,  1.1810,  1.0273,  1.5703]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.4949,  0.6670, -0.6443,  ...,  1.7941,  1.5048,  0.0983],\n",
            "         [-3.6410, -1.9127, -2.5005,  ..., -1.8130, -0.7827, -1.8809],\n",
            "         [ 0.2141,  0.6032, -3.5902,  ..., -0.8712, -2.7497, -3.2552],\n",
            "         ...,\n",
            "         [-2.6899, -1.6779, -1.1961,  ..., -0.7827, -3.2604,  2.2035],\n",
            "         [-4.3427, -2.8189, -2.8076,  ..., -3.1857, -3.7413, -3.7342],\n",
            "         [ 1.3288,  1.6242,  1.6485,  ...,  0.9649,  0.7561,  1.2093]],\n",
            "\n",
            "        [[ 0.4804,  0.5774, -1.0227,  ...,  1.9150,  1.5316, -0.1401],\n",
            "         [-4.2027, -2.4317, -3.1001,  ..., -1.9656, -0.8839, -2.3346],\n",
            "         [ 0.0454,  0.6770, -4.1885,  ..., -1.0020, -3.1506, -3.8884],\n",
            "         ...,\n",
            "         [-3.1544, -1.9111, -1.6313,  ..., -0.9091, -3.8701,  2.7333],\n",
            "         [-5.0245, -3.4664, -3.3944,  ..., -3.8655, -4.4416, -4.4618],\n",
            "         [ 1.8755,  2.3196,  2.3705,  ...,  1.3448,  1.1429,  1.6107]],\n",
            "\n",
            "        [[ 1.0628,  1.2333, -0.0692,  ...,  2.0619,  2.1072,  1.3125],\n",
            "         [-4.0222, -1.5329, -1.9435,  ..., -2.5490, -1.4997, -1.4312],\n",
            "         [ 0.7312,  0.6738, -3.9440,  ..., -1.7387, -3.1397, -3.6047],\n",
            "         ...,\n",
            "         [-3.2043, -1.5348, -1.0170,  ..., -0.7418, -3.0883,  1.4447],\n",
            "         [-4.8894, -2.7958, -2.9404,  ..., -3.5856, -3.4988, -4.0319],\n",
            "         [ 0.8473,  0.7325,  0.6047,  ...,  0.0593,  0.3317,  1.1958]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[-2.4065, -2.7155, -3.9982,  ..., -1.6459, -1.6216, -3.2530],\n",
            "         [-6.4762, -5.2501, -5.8000,  ..., -5.1405, -3.8084, -5.1600],\n",
            "         [-2.7232, -2.7100, -6.8302,  ..., -4.2317, -5.7401, -6.4797],\n",
            "         ...,\n",
            "         [-5.5210, -4.9794, -4.5283,  ..., -4.1880, -6.2646, -1.0444],\n",
            "         [-7.1348, -6.1569, -6.1061,  ..., -6.5067, -6.7705, -6.9376],\n",
            "         [-1.5008, -1.6301, -1.5865,  ..., -2.3800, -2.2511, -2.0484]],\n",
            "\n",
            "        [[-2.1240, -2.2902, -4.2194,  ..., -1.1579, -1.2178, -2.3766],\n",
            "         [-7.8870, -5.5178, -6.3485,  ..., -6.3379, -5.0149, -5.3211],\n",
            "         [-2.4916, -2.8221, -8.5339,  ..., -5.2693, -7.1788, -7.7696],\n",
            "         ...,\n",
            "         [-6.9384, -5.3656, -5.1448,  ..., -4.3989, -7.4158, -1.3811],\n",
            "         [-8.8980, -6.8339, -7.3332,  ..., -7.8859, -7.9079, -8.3576],\n",
            "         [-2.0543, -2.4223, -2.7960,  ..., -3.1293, -3.0582, -2.0896]],\n",
            "\n",
            "        [[-2.3965, -2.6744, -4.7801,  ..., -1.3164, -1.4660, -3.4189],\n",
            "         [-7.9519, -6.1084, -7.1517,  ..., -6.1262, -4.4959, -6.0817],\n",
            "         [-2.7097, -2.8575, -8.8126,  ..., -4.9273, -7.2152, -8.1839],\n",
            "         ...,\n",
            "         [-6.8958, -5.7669, -5.4909,  ..., -4.5801, -7.9657, -0.8118],\n",
            "         [-9.0476, -7.2771, -7.7137,  ..., -8.2479, -8.5204, -8.9286],\n",
            "         [-1.4353, -1.5669, -1.8199,  ..., -2.4759, -2.4851, -2.0789]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-2.3985, -2.6549, -3.9621,  ..., -1.5985, -1.5706, -3.1722],\n",
            "         [-6.5343, -5.2346, -5.8183,  ..., -5.2056, -3.8581, -5.1514],\n",
            "         [-2.6793, -2.7187, -6.9079,  ..., -4.2638, -5.8252, -6.5256],\n",
            "         ...,\n",
            "         [-5.5833, -4.9998, -4.5139,  ..., -4.1753, -6.3358, -1.0670],\n",
            "         [-7.2360, -6.1408, -6.1254,  ..., -6.5783, -6.8167, -7.0047],\n",
            "         [-1.5646, -1.6977, -1.6693,  ..., -2.4277, -2.3193, -2.0612]],\n",
            "\n",
            "        [[-2.5047, -2.9404, -4.6533,  ..., -1.6184, -1.7040, -3.6863],\n",
            "         [-7.1878, -5.9496, -6.7307,  ..., -5.4990, -4.1195, -5.8809],\n",
            "         [-2.9397, -2.8408, -7.8191,  ..., -4.5354, -6.3862, -7.4347],\n",
            "         ...,\n",
            "         [-6.1395, -5.4289, -5.2619,  ..., -4.4425, -7.1057, -0.8130],\n",
            "         [-8.0096, -6.9843, -7.0250,  ..., -7.3990, -7.6772, -8.0080],\n",
            "         [-1.1096, -1.1983, -1.2601,  ..., -2.1887, -2.0927, -1.9355]],\n",
            "\n",
            "        [[-2.0626, -2.1767, -3.6500,  ..., -1.3097, -1.2701, -2.0276],\n",
            "         [-7.1476, -4.9429, -5.5243,  ..., -5.9207, -4.8771, -4.7713],\n",
            "         [-2.3942, -2.7362, -7.5247,  ..., -5.1103, -6.5170, -6.9448],\n",
            "         ...,\n",
            "         [-6.3298, -4.9448, -4.5978,  ..., -4.1135, -6.4657, -1.8955],\n",
            "         [-8.0148, -6.2059, -6.5212,  ..., -6.9572, -6.8761, -7.3720],\n",
            "         [-2.2781, -2.6775, -2.9761,  ..., -3.3123, -3.0457, -2.1443]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.2651,  2.3152,  0.6468,  ..., -1.4203,  0.7371,  1.8687],\n",
            "        [ 1.7643,  1.9485,  0.4049,  ..., -0.7095,  0.5863,  1.5766],\n",
            "        [ 0.3859,  0.2311, -1.1082,  ...,  1.3608,  1.0751,  1.5641],\n",
            "        ...,\n",
            "        [ 1.3599,  1.5146,  0.2762,  ..., -0.4406,  0.3737,  1.2152],\n",
            "        [ 1.8482,  1.9661,  0.5030,  ..., -0.9421,  0.5862,  1.5753],\n",
            "        [ 0.9187,  1.1652, -0.3847,  ...,  0.5424,  0.5487,  1.3175]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.2651,  2.3152,  0.6468,  ...,  2.2252,  2.7002,  3.2091],\n",
            "         [-5.3137, -1.6388, -2.1994,  ..., -3.9013, -3.2150, -1.4884],\n",
            "         [ 1.6235,  0.9496, -5.4210,  ..., -3.6493, -4.7990, -5.0400],\n",
            "         ...,\n",
            "         [-4.8880, -2.0781, -1.1939,  ..., -1.3317, -3.8490,  0.2949],\n",
            "         [-7.1127, -3.9018, -4.2833,  ..., -4.8341, -3.6927, -5.2047],\n",
            "         [ 1.2891,  0.7694, -0.1164,  ..., -1.4203,  0.7371,  1.8687]],\n",
            "\n",
            "        [[ 1.7643,  1.9485,  0.4049,  ...,  2.3213,  2.6713,  2.4147],\n",
            "         [-5.0045, -1.5799, -2.1083,  ..., -3.4321, -2.5083, -1.4974],\n",
            "         [ 1.3431,  0.9400, -5.0448,  ..., -2.9824, -4.1547, -4.7318],\n",
            "         ...,\n",
            "         [-4.3452, -2.0145, -1.1259,  ..., -1.0259, -3.6670,  0.8139],\n",
            "         [-6.5045, -3.5093, -3.8197,  ..., -4.6331, -4.0088, -5.1180],\n",
            "         [ 0.9835,  0.7754,  0.1915,  ..., -0.7095,  0.5863,  1.5766]],\n",
            "\n",
            "        [[ 0.3859,  0.2311, -1.1082,  ...,  1.5208,  1.0432, -0.3537],\n",
            "         [-3.3175, -2.2635, -2.6744,  ..., -1.4822, -0.8490, -1.9913],\n",
            "         [-0.2217,  0.4381, -3.1842,  ..., -0.7917, -2.5010, -2.9968],\n",
            "         ...,\n",
            "         [-2.3502, -1.4187, -1.5946,  ..., -0.8784, -3.0218,  2.3265],\n",
            "         [-3.7588, -3.1225, -2.8568,  ..., -2.9725, -3.4262, -3.4503],\n",
            "         [ 1.9966,  2.3595,  2.3456,  ...,  1.3608,  1.0751,  1.5641]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.3599,  1.5146,  0.2762,  ...,  1.9520,  2.1817,  1.8222],\n",
            "         [-4.0060, -1.3088, -1.7337,  ..., -2.7412, -1.9478, -1.2204],\n",
            "         [ 0.9951,  0.7563, -3.9785,  ..., -2.2408, -3.2786, -3.6887],\n",
            "         ...,\n",
            "         [-3.3431, -1.6364, -0.9125,  ..., -0.8114, -2.9012,  0.8159],\n",
            "         [-5.0515, -2.7914, -3.0080,  ..., -3.6019, -3.2747, -4.0140],\n",
            "         [ 0.7842,  0.6027,  0.1931,  ..., -0.4406,  0.3737,  1.2152]],\n",
            "\n",
            "        [[ 1.8482,  1.9661,  0.5030,  ...,  2.1472,  2.5130,  2.5646],\n",
            "         [-4.7999, -1.4573, -2.0241,  ..., -3.3761, -2.6309, -1.3768],\n",
            "         [ 1.3649,  0.8679, -4.8278,  ..., -3.0348, -4.1137, -4.5079],\n",
            "         ...,\n",
            "         [-4.2317, -1.9057, -1.0655,  ..., -1.0711, -3.4425,  0.5585],\n",
            "         [-6.2553, -3.3963, -3.7217,  ..., -4.3667, -3.5800, -4.7622],\n",
            "         [ 1.0229,  0.7050,  0.0082,  ..., -0.9421,  0.5862,  1.5753]],\n",
            "\n",
            "        [[ 0.9187,  1.1652, -0.3847,  ...,  2.3195,  2.2175,  0.8577],\n",
            "         [-4.5029, -1.9707, -2.4267,  ..., -2.5870, -1.2830, -1.8244],\n",
            "         [ 0.5800,  0.6623, -4.4236,  ..., -1.4952, -3.4255, -4.0785],\n",
            "         ...,\n",
            "         [-3.5375, -1.7829, -1.2118,  ..., -0.7959, -3.7185,  2.1050],\n",
            "         [-5.4534, -3.1917, -3.3085,  ..., -4.0908, -4.1798, -4.6555],\n",
            "         [ 1.1205,  1.1618,  1.1472,  ...,  0.5424,  0.5487,  1.3175]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.4992,  -1.6730,  -4.0421,  ...,  -1.4537,  -1.6456,  -1.0516],\n",
            "         [ -9.0781,  -5.6270,  -6.8883,  ...,  -7.5801,  -7.5608,  -5.7491],\n",
            "         [ -2.1409,  -3.0386, -10.1100,  ...,  -7.3281,  -9.1448,  -9.3007],\n",
            "         ...,\n",
            "         [ -8.6523,  -6.0664,  -5.8828,  ...,  -5.0105,  -8.1948,  -3.9658],\n",
            "         [-10.8771,  -7.8900,  -8.9723,  ...,  -8.5129,  -8.0385,  -9.4654],\n",
            "         [ -2.4752,  -3.2189,  -4.8053,  ...,  -5.0991,  -3.6087,  -2.3920]],\n",
            "\n",
            "        [[ -1.7457,  -1.8565,  -3.8709,  ...,  -1.2584,  -1.3188,  -1.4096],\n",
            "         [ -8.5145,  -5.3849,  -6.3841,  ...,  -7.0117,  -6.4984,  -5.3216],\n",
            "         [ -2.1669,  -2.8650,  -9.3206,  ...,  -6.5620,  -8.1448,  -8.5560],\n",
            "         ...,\n",
            "         [ -7.8553,  -5.8195,  -5.4017,  ...,  -4.6055,  -7.6571,  -3.0103],\n",
            "         [-10.0145,  -7.3143,  -8.0955,  ...,  -8.2127,  -7.9989,  -8.9422],\n",
            "         [ -2.5265,  -3.0295,  -4.0843,  ...,  -4.2892,  -3.4038,  -2.2477]],\n",
            "\n",
            "        [[ -2.5427,  -3.1373,  -4.3983,  ...,  -1.8619,  -1.9265,  -3.6638],\n",
            "         [ -6.2462,  -5.6319,  -5.9645,  ...,  -4.8650,  -3.8187,  -5.3014],\n",
            "         [ -3.1504,  -2.9303,  -6.4743,  ...,  -4.1744,  -5.4707,  -6.3069],\n",
            "         ...,\n",
            "         [ -5.2788,  -4.7871,  -4.8847,  ...,  -4.2612,  -5.9915,  -0.9836],\n",
            "         [ -6.6875,  -6.4909,  -6.1469,  ...,  -6.3552,  -6.3959,  -6.7604],\n",
            "         [ -0.9321,  -1.0089,  -0.9445,  ...,  -2.0220,  -1.8946,  -1.7460]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.8927,  -1.9790,  -3.4202,  ...,  -1.3722,  -1.3104,  -1.6450],\n",
            "         [ -7.2586,  -4.8023,  -5.4301,  ...,  -6.0654,  -5.4399,  -4.6876],\n",
            "         [ -2.2575,  -2.7372,  -7.6749,  ...,  -5.5650,  -6.7706,  -7.1559],\n",
            "         ...,\n",
            "         [ -6.5957,  -5.1299,  -4.6089,  ...,  -4.1356,  -6.3933,  -2.6513],\n",
            "         [ -8.3041,  -6.2849,  -6.7044,  ...,  -6.9261,  -6.7668,  -7.4812],\n",
            "         [ -2.4684,  -2.8908,  -3.5033,  ...,  -3.7648,  -3.1183,  -2.2520]],\n",
            "\n",
            "        [[ -1.6738,  -1.7975,  -3.7363,  ...,  -1.3610,  -1.4384,  -1.3005],\n",
            "         [ -8.3220,  -5.2209,  -6.2634,  ...,  -6.8843,  -6.5823,  -5.2419],\n",
            "         [ -2.1571,  -2.8957,  -9.0671,  ...,  -6.5430,  -8.0651,  -8.3730],\n",
            "         ...,\n",
            "         [ -7.7537,  -5.6693,  -5.3048,  ...,  -4.5793,  -7.3939,  -3.3066],\n",
            "         [ -9.7773,  -7.1599,  -7.9610,  ...,  -7.8749,  -7.5314,  -8.6273],\n",
            "         [ -2.4992,  -3.0586,  -4.2311,  ...,  -4.4503,  -3.3652,  -2.2898]],\n",
            "\n",
            "        [[ -2.1828,  -2.3065,  -4.1410,  ...,  -1.1923,  -1.2584,  -2.5492],\n",
            "         [ -7.6044,  -5.4423,  -6.1829,  ...,  -6.0988,  -4.7589,  -5.2313],\n",
            "         [ -2.5215,  -2.8094,  -8.1798,  ...,  -5.0070,  -6.9013,  -7.4854],\n",
            "         ...,\n",
            "         [ -6.6390,  -5.2546,  -4.9681,  ...,  -4.3077,  -7.1944,  -1.3019],\n",
            "         [ -8.5549,  -6.6634,  -7.0647,  ...,  -7.6026,  -7.6557,  -8.0624],\n",
            "         [ -1.9810,  -2.3099,  -2.6091,  ...,  -2.9694,  -2.9272,  -2.0894]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.1159,  2.2321,  0.6187,  ..., -1.2975,  0.6835,  1.7738],\n",
            "        [ 1.5761,  1.8223,  0.3154,  ..., -0.4990,  0.5102,  1.4697],\n",
            "        [ 2.0470,  2.2083,  0.5874,  ..., -1.1545,  0.6786,  1.7505],\n",
            "        ...,\n",
            "        [ 1.4740,  1.6310,  0.3829,  ..., -0.6638,  0.4155,  1.2683],\n",
            "        [ 0.5269,  0.7369, -0.5165,  ...,  0.8127,  0.6277,  1.0798],\n",
            "        [ 1.8202,  1.9554,  0.5271,  ..., -0.9976,  0.5591,  1.5465]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.1159,  2.2321,  0.6187,  ...,  2.1729,  2.6075,  2.9959],\n",
            "         [-5.0914, -1.5668, -2.0838,  ..., -3.7227, -3.0450, -1.4223],\n",
            "         [ 1.5239,  0.8928, -5.1754,  ..., -3.4636, -4.5634, -4.8132],\n",
            "         ...,\n",
            "         [-4.6272, -1.9941, -1.1059,  ..., -1.2210, -3.6741,  0.3094],\n",
            "         [-6.7637, -3.7146, -4.0785,  ..., -4.6191, -3.5634, -4.9751],\n",
            "         [ 1.2139,  0.7242, -0.1173,  ..., -1.2975,  0.6835,  1.7738]],\n",
            "\n",
            "        [[ 1.5761,  1.8223,  0.3154,  ...,  2.2888,  2.5895,  2.1194],\n",
            "         [-4.7762, -1.5634, -2.0011,  ..., -3.2441, -2.2568, -1.4644],\n",
            "         [ 1.2089,  0.9055, -4.8062,  ..., -2.7240, -3.8908, -4.5093],\n",
            "         ...,\n",
            "         [-4.0664, -1.9358, -1.0610,  ..., -0.8994, -3.5365,  0.9268],\n",
            "         [-6.1429, -3.3333, -3.6069,  ..., -4.4316, -3.9742, -4.9372],\n",
            "         [ 0.9061,  0.7477,  0.2745,  ..., -0.4990,  0.5102,  1.4697]],\n",
            "\n",
            "        [[ 2.0470,  2.2083,  0.5874,  ...,  2.2623,  2.6818,  2.8810],\n",
            "         [-5.1653, -1.5677, -2.1240,  ..., -3.6965, -2.9493, -1.4621],\n",
            "         [ 1.5037,  0.9100, -5.2364,  ..., -3.4054, -4.5191, -4.8950],\n",
            "         ...,\n",
            "         [-4.6382, -2.0312, -1.1178,  ..., -1.1661, -3.7341,  0.4373],\n",
            "         [-6.8199, -3.7058, -4.0771,  ..., -4.7284, -3.7488, -5.1147],\n",
            "         [ 1.1461,  0.7487, -0.0567,  ..., -1.1545,  0.6786,  1.7505]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.4740,  1.6310,  0.3829,  ...,  1.8932,  2.1419,  2.0261],\n",
            "         [-4.0167, -1.2562, -1.7041,  ..., -2.8125, -2.1467, -1.1599],\n",
            "         [ 1.0602,  0.7222, -3.9862,  ..., -2.4119, -3.3980, -3.6833],\n",
            "         ...,\n",
            "         [-3.4048, -1.6212, -0.8720,  ..., -0.8672, -2.8497,  0.5939],\n",
            "         [-5.1061, -2.8251, -3.0681,  ..., -3.5651, -3.0631, -3.9142],\n",
            "         [ 0.8385,  0.5607,  0.0323,  ..., -0.6638,  0.4155,  1.2683]],\n",
            "\n",
            "        [[ 0.5269,  0.7369, -0.5165,  ...,  1.7545,  1.5019,  0.1908],\n",
            "         [-3.4292, -1.7297, -2.2381,  ..., -1.7881, -0.8202, -1.6497],\n",
            "         [ 0.2456,  0.5333, -3.3561,  ..., -0.8371, -2.6387, -3.0156],\n",
            "         ...,\n",
            "         [-2.5148, -1.5598, -1.0452,  ..., -0.7072, -3.0214,  1.9430],\n",
            "         [-4.0888, -2.6022, -2.6004,  ..., -2.9706, -3.4227, -3.4751],\n",
            "         [ 1.1246,  1.3408,  1.3557,  ...,  0.8127,  0.6277,  1.0798]],\n",
            "\n",
            "        [[ 1.8202,  1.9554,  0.5271,  ...,  2.0471,  2.4038,  2.5382],\n",
            "         [-4.6113, -1.3979, -1.9203,  ..., -3.2968, -2.6207, -1.3015],\n",
            "         [ 1.3238,  0.8087, -4.6354,  ..., -2.9909, -4.0133, -4.3172],\n",
            "         ...,\n",
            "         [-4.0757, -1.8184, -0.9944,  ..., -1.0363, -3.2881,  0.4414],\n",
            "         [-6.0005, -3.2860, -3.6074,  ..., -4.1571, -3.3334, -4.5077],\n",
            "         [ 1.0277,  0.6542, -0.0658,  ..., -0.9976,  0.5591,  1.5465]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.5659,  -1.6709,  -3.9046,  ...,  -1.4245,  -1.5952,  -1.1353],\n",
            "         [ -8.7732,  -5.4698,  -6.6072,  ...,  -7.3202,  -7.2477,  -5.5536],\n",
            "         [ -2.1579,  -3.0101,  -9.6988,  ...,  -7.0611,  -8.7661,  -8.9445],\n",
            "         ...,\n",
            "         [ -8.3090,  -5.8971,  -5.6293,  ...,  -4.8184,  -7.8769,  -3.8219],\n",
            "         [-10.4455,  -7.6175,  -8.6018,  ...,  -8.2165,  -7.7661,  -9.1064],\n",
            "         [ -2.4679,  -3.1788,  -4.6406,  ...,  -4.8949,  -3.5193,  -2.3575]],\n",
            "\n",
            "        [[ -1.8425,  -1.8958,  -3.7815,  ...,  -1.2314,  -1.2548,  -1.5659],\n",
            "         [ -8.1948,  -5.2815,  -6.0980,  ...,  -6.7642,  -6.1011,  -5.1496],\n",
            "         [ -2.2097,  -2.8126,  -8.9031,  ...,  -6.2441,  -7.7351,  -8.1946],\n",
            "         ...,\n",
            "         [ -7.4850,  -5.6539,  -5.1579,  ...,  -4.4195,  -7.3808,  -2.7585],\n",
            "         [ -9.5615,  -7.0513,  -7.7038,  ...,  -7.9517,  -7.8185,  -8.6225],\n",
            "         [ -2.5125,  -2.9704,  -3.8224,  ...,  -4.0191,  -3.3341,  -2.2155]],\n",
            "\n",
            "        [[ -1.6091,  -1.6992,  -3.9261,  ...,  -1.3549,  -1.5077,  -1.1966],\n",
            "         [ -8.8214,  -5.4752,  -6.6375,  ...,  -7.3137,  -7.1388,  -5.5397],\n",
            "         [ -2.1524,  -2.9975,  -9.7499,  ...,  -7.0226,  -8.7086,  -8.9727],\n",
            "         ...,\n",
            "         [ -8.2943,  -5.9387,  -5.6313,  ...,  -4.7833,  -7.9235,  -3.6403],\n",
            "         [-10.4761,  -7.6133,  -8.5906,  ...,  -8.3456,  -7.9382,  -9.1923],\n",
            "         [ -2.5101,  -3.1588,  -4.5702,  ...,  -4.7717,  -3.5108,  -2.3272]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.8284,  -1.8855,  -3.3788,  ...,  -1.4130,  -1.3969,  -1.5212],\n",
            "         [ -7.3191,  -4.7728,  -5.4658,  ...,  -6.1187,  -5.6855,  -4.7071],\n",
            "         [ -2.2422,  -2.7943,  -7.7479,  ...,  -5.7181,  -6.9368,  -7.2305],\n",
            "         ...,\n",
            "         [ -6.7072,  -5.1377,  -4.6337,  ...,  -4.1734,  -6.3885,  -2.9534],\n",
            "         [ -8.4085,  -6.3417,  -6.8298,  ...,  -6.8714,  -6.6019,  -7.4614],\n",
            "         [ -2.4639,  -2.9559,  -3.7294,  ...,  -3.9700,  -3.1233,  -2.2790]],\n",
            "\n",
            "        [[ -2.3539,  -2.5190,  -3.7376,  ...,  -1.5795,  -1.5281,  -2.9848],\n",
            "         [ -6.3100,  -4.9856,  -5.4593,  ...,  -5.1222,  -3.8502,  -4.8254],\n",
            "         [ -2.6352,  -2.7226,  -6.5773,  ...,  -4.1711,  -5.6687,  -6.1913],\n",
            "         ...,\n",
            "         [ -5.3956,  -4.8157,  -4.2664,  ...,  -4.0412,  -6.0514,  -1.2327],\n",
            "         [ -6.9697,  -5.8582,  -5.8216,  ...,  -6.3046,  -6.4527,  -6.6507],\n",
            "         [ -1.7562,  -1.9152,  -1.8655,  ...,  -2.5213,  -2.4023,  -2.0958]],\n",
            "\n",
            "        [[ -1.6800,  -1.7609,  -3.6351,  ...,  -1.4013,  -1.4834,  -1.3036],\n",
            "         [ -8.1115,  -5.1143,  -6.0825,  ...,  -6.7451,  -6.5078,  -5.1433],\n",
            "         [ -2.1764,  -2.9076,  -8.7976,  ...,  -6.4393,  -7.9004,  -8.1590],\n",
            "         ...,\n",
            "         [ -7.5758,  -5.5348,  -5.1565,  ...,  -4.4846,  -7.1752,  -3.4004],\n",
            "         [ -9.5006,  -7.0023,  -7.7696,  ...,  -7.6054,  -7.2205,  -8.3495],\n",
            "         [ -2.4724,  -3.0622,  -4.2280,  ...,  -4.4459,  -3.3281,  -2.2953]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.3776,  0.0685, -1.1823,  ...,  1.3702,  1.0376,  1.5336],\n",
            "        [ 1.5891,  1.8114,  0.4062,  ..., -0.6948,  0.5024,  1.4082],\n",
            "        [ 1.7885,  1.8731,  0.5431,  ..., -1.1326,  0.5143,  1.4794],\n",
            "        ...,\n",
            "        [ 2.0767,  2.1697,  0.6228,  ..., -1.3819,  0.6505,  1.7217],\n",
            "        [ 1.6702,  1.8558,  0.4627,  ..., -0.8316,  0.5147,  1.4538],\n",
            "        [ 1.9342,  2.1261,  0.5560,  ..., -1.0625,  0.6368,  1.6778]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 0.3776,  0.0685, -1.1823,  ...,  1.3622,  0.9061, -0.4436],\n",
            "         [-2.9861, -2.2612, -2.5352,  ..., -1.2995, -0.8165, -1.8189],\n",
            "         [-0.2948,  0.3086, -2.8957,  ..., -0.6712, -2.2805, -2.7583],\n",
            "         ...,\n",
            "         [-2.0777, -1.2502, -1.5495,  ..., -0.8696, -2.7024,  2.1587],\n",
            "         [-3.3215, -2.9826, -2.6759,  ..., -2.6945, -3.0295, -3.0678],\n",
            "         [ 2.0658,  2.4177,  2.3216,  ...,  1.3702,  1.0376,  1.5336]],\n",
            "\n",
            "        [[ 1.5891,  1.8114,  0.4062,  ...,  2.0965,  2.3727,  2.2006],\n",
            "         [-4.4461, -1.3914, -1.8389,  ..., -3.0907, -2.3299, -1.2874],\n",
            "         [ 1.1626,  0.7914, -4.4424,  ..., -2.6882, -3.7427, -4.1311],\n",
            "         ...,\n",
            "         [-3.7964, -1.7972, -0.9409,  ..., -0.9154, -3.1938,  0.6379],\n",
            "         [-5.7183, -3.1264, -3.4002,  ..., -4.0212, -3.4469, -4.4155],\n",
            "         [ 0.9007,  0.6327,  0.0607,  ..., -0.6948,  0.5024,  1.4082]],\n",
            "\n",
            "        [[ 1.7885,  1.8731,  0.5431,  ...,  1.7835,  2.1333,  2.5305],\n",
            "         [-4.1867, -1.3217, -1.7147,  ..., -3.1193, -2.6006, -1.1377],\n",
            "         [ 1.2396,  0.7069, -4.2100,  ..., -2.8760, -3.8189, -3.8652],\n",
            "         ...,\n",
            "         [-3.7373, -1.6485, -0.8777,  ..., -1.0364, -2.9570,  0.2272],\n",
            "         [-5.4514, -3.0782, -3.3478,  ..., -3.6679, -2.7986, -3.9541],\n",
            "         [ 1.0879,  0.5668, -0.1785,  ..., -1.1326,  0.5143,  1.4794]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.0767,  2.1697,  0.6228,  ...,  1.9736,  2.3995,  2.9739],\n",
            "         [-4.7705, -1.5276, -1.9118,  ..., -3.5894, -3.0195, -1.2985],\n",
            "         [ 1.4530,  0.8166, -4.8528,  ..., -3.3731, -4.4194, -4.4684],\n",
            "         ...,\n",
            "         [-4.3612, -1.8743, -1.0061,  ..., -1.2169, -3.4259,  0.1524],\n",
            "         [-6.3521, -3.5643, -3.8782,  ..., -4.2476, -3.1728, -4.5677],\n",
            "         [ 1.2697,  0.6581, -0.1920,  ..., -1.3819,  0.6505,  1.7217]],\n",
            "\n",
            "        [[ 1.6702,  1.8558,  0.4627,  ...,  2.0368,  2.3423,  2.3233],\n",
            "         [-4.4367, -1.3664, -1.8321,  ..., -3.1379, -2.4352, -1.2640],\n",
            "         [ 1.2087,  0.7713, -4.4405,  ..., -2.7915, -3.8049, -4.1304],\n",
            "         ...,\n",
            "         [-3.8452, -1.7711, -0.9350,  ..., -0.9471, -3.1652,  0.5159],\n",
            "         [-5.7253, -3.1405, -3.4322,  ..., -3.9927, -3.3025, -4.3533],\n",
            "         [ 0.9538,  0.6244, -0.0206,  ..., -0.8316,  0.5147,  1.4538]],\n",
            "\n",
            "        [[ 1.9342,  2.1261,  0.5560,  ...,  2.2074,  2.5908,  2.7227],\n",
            "         [-4.9618, -1.5128, -2.0195,  ..., -3.5490, -2.8121, -1.4027],\n",
            "         [ 1.4079,  0.8534, -5.0146,  ..., -3.2534, -4.3255, -4.6845],\n",
            "         ...,\n",
            "         [-4.4119, -1.9591, -1.0456,  ..., -1.0859, -3.5734,  0.4356],\n",
            "         [-6.5130, -3.5494, -3.9001,  ..., -4.5235, -3.6116, -4.8979],\n",
            "         [ 1.0995,  0.7095, -0.0640,  ..., -1.0625,  0.6368,  1.6778]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.5574,  -3.2725,  -4.3741,  ...,  -1.9612,  -2.0019,  -3.6789],\n",
            "         [ -5.9211,  -5.6021,  -5.7270,  ...,  -4.6230,  -3.7246,  -5.0542],\n",
            "         [ -3.2299,  -3.0324,  -6.0876,  ...,  -3.9946,  -5.1886,  -5.9936],\n",
            "         ...,\n",
            "         [ -5.0127,  -4.5912,  -4.7414,  ...,  -4.1930,  -5.6105,  -1.0766],\n",
            "         [ -6.2565,  -6.3236,  -5.8677,  ...,  -6.0179,  -5.9376,  -6.3031],\n",
            "         [ -0.8692,  -0.9233,  -0.8703,  ...,  -1.9532,  -1.8704,  -1.7017]],\n",
            "\n",
            "        [[ -1.8038,  -1.8285,  -3.5743,  ...,  -1.3174,  -1.3561,  -1.4733],\n",
            "         [ -7.8390,  -5.0313,  -5.8193,  ...,  -6.5046,  -6.0587,  -4.9613],\n",
            "         [ -2.2303,  -2.8485,  -8.4228,  ...,  -6.1021,  -7.4716,  -7.8050],\n",
            "         ...,\n",
            "         [ -7.1893,  -5.4371,  -4.9214,  ...,  -4.3292,  -6.9227,  -3.0360],\n",
            "         [ -9.1112,  -6.7663,  -7.3806,  ...,  -7.4351,  -7.1757,  -8.0894],\n",
            "         [ -2.4922,  -3.0072,  -3.9198,  ...,  -4.1087,  -3.2264,  -2.2657]],\n",
            "\n",
            "        [[ -1.6699,  -1.7427,  -3.4465,  ...,  -1.5344,  -1.6118,  -1.2673],\n",
            "         [ -7.6451,  -4.9375,  -5.7043,  ...,  -6.4372,  -6.3456,  -4.9355],\n",
            "         [ -2.2188,  -2.9089,  -8.1996,  ...,  -6.1939,  -7.5640,  -7.6631],\n",
            "         ...,\n",
            "         [ -7.1957,  -5.2643,  -4.8672,  ...,  -4.3543,  -6.7020,  -3.5706],\n",
            "         [ -8.9099,  -6.6940,  -7.3374,  ...,  -6.9857,  -6.5437,  -7.7519],\n",
            "         [ -2.3705,  -3.0490,  -4.1681,  ...,  -4.4505,  -3.2308,  -2.3184]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -1.5684,  -1.6484,  -3.7516,  ...,  -1.5159,  -1.6854,  -1.1179],\n",
            "         [ -8.4156,  -5.3457,  -6.2861,  ...,  -7.0789,  -7.1045,  -5.3902],\n",
            "         [ -2.1921,  -3.0015,  -9.2271,  ...,  -6.8626,  -8.5044,  -8.5601],\n",
            "         ...,\n",
            "         [ -8.0063,  -5.6924,  -5.3804,  ...,  -4.7064,  -7.5109,  -3.9394],\n",
            "         [ -9.9972,  -7.3824,  -8.2526,  ...,  -7.7371,  -7.2578,  -8.6595],\n",
            "         [ -2.3754,  -3.1600,  -4.5663,  ...,  -4.8713,  -3.4345,  -2.3701]],\n",
            "\n",
            "        [[ -1.7552,  -1.7947,  -3.5546,  ...,  -1.3643,  -1.4211,  -1.4036],\n",
            "         [ -7.8620,  -5.0169,  -5.8494,  ...,  -6.5390,  -6.1987,  -4.9908],\n",
            "         [ -2.2167,  -2.8793,  -8.4579,  ...,  -6.1926,  -7.5683,  -7.8573],\n",
            "         ...,\n",
            "         [ -7.2705,  -5.4217,  -4.9524,  ...,  -4.3483,  -6.9287,  -3.2110],\n",
            "         [ -9.1506,  -6.7910,  -7.4496,  ...,  -7.3938,  -7.0659,  -8.0801],\n",
            "         [ -2.4716,  -3.0261,  -4.0380,  ...,  -4.2327,  -3.2487,  -2.2731]],\n",
            "\n",
            "        [[ -1.6576,  -1.7091,  -3.8132,  ...,  -1.3409,  -1.4782,  -1.2572],\n",
            "         [ -8.5537,  -5.3479,  -6.3887,  ...,  -7.0973,  -6.8812,  -5.3826],\n",
            "         [ -2.1840,  -2.9818,  -9.3838,  ...,  -6.8017,  -8.3946,  -8.6645],\n",
            "         ...,\n",
            "         [ -8.0038,  -5.7943,  -5.4149,  ...,  -4.6342,  -7.6424,  -3.5443],\n",
            "         [-10.1049,  -7.3845,  -8.2693,  ...,  -8.0718,  -7.6806,  -8.8778],\n",
            "         [ -2.4924,  -3.1257,  -4.4332,  ...,  -4.6108,  -3.4323,  -2.3021]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 2.1028,  2.3327,  0.6175,  ..., -1.2221,  0.7406,  1.8495],\n",
            "        [ 0.6052,  0.9474, -0.7287,  ...,  1.0738,  0.9048,  1.4117],\n",
            "        [ 1.0325,  1.4109, -0.4479,  ...,  0.6111,  0.6673,  1.5313],\n",
            "        ...,\n",
            "        [ 0.4788,  0.7382, -0.7247,  ...,  1.0764,  0.8653,  1.3034],\n",
            "        [ 1.8211,  1.9678,  0.5466,  ..., -1.0921,  0.5662,  1.5600],\n",
            "        [ 0.4016,  0.5476, -1.5670,  ...,  1.8290,  1.6509,  2.2661]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 2.1028e+00,  2.3327e+00,  6.1749e-01,  ...,  2.3572e+00,\n",
            "           2.7858e+00,  2.9970e+00],\n",
            "         [-5.3479e+00, -1.6389e+00, -2.1284e+00,  ..., -3.8703e+00,\n",
            "          -3.1002e+00, -1.5109e+00],\n",
            "         [ 1.5235e+00,  8.7823e-01, -5.4424e+00,  ..., -3.6108e+00,\n",
            "          -4.7240e+00, -5.0926e+00],\n",
            "         ...,\n",
            "         [-4.8226e+00, -2.0831e+00, -1.1106e+00,  ..., -1.1654e+00,\n",
            "          -3.8884e+00,  3.5701e-01],\n",
            "         [-7.0991e+00, -3.8664e+00, -4.2583e+00,  ..., -4.9147e+00,\n",
            "          -3.8437e+00, -5.2920e+00],\n",
            "         [ 1.2178e+00,  7.7085e-01, -9.3330e-02,  ..., -1.2221e+00,\n",
            "           7.4060e-01,  1.8495e+00]],\n",
            "\n",
            "        [[ 6.0520e-01,  9.4742e-01, -7.2868e-01,  ...,  2.1884e+00,\n",
            "           1.8645e+00,  1.7898e-01],\n",
            "         [-4.4062e+00, -2.2306e+00, -2.8489e+00,  ..., -2.2392e+00,\n",
            "          -9.0884e-01, -2.1129e+00],\n",
            "         [ 2.7765e-01,  6.5226e-01, -4.3716e+00,  ..., -1.0940e+00,\n",
            "          -3.3658e+00, -4.0066e+00],\n",
            "         ...,\n",
            "         [-3.3619e+00, -1.9525e+00, -1.3367e+00,  ..., -7.8130e-01,\n",
            "          -3.9723e+00,  2.4757e+00],\n",
            "         [-5.3499e+00, -3.3142e+00, -3.3875e+00,  ..., -4.0520e+00,\n",
            "          -4.4708e+00, -4.6717e+00],\n",
            "         [ 1.3939e+00,  1.7239e+00,  1.7879e+00,  ...,  1.0738e+00,\n",
            "           9.0483e-01,  1.4117e+00]],\n",
            "\n",
            "        [[ 1.0325e+00,  1.4109e+00, -4.4795e-01,  ...,  2.6838e+00,\n",
            "           2.5712e+00,  9.8589e-01],\n",
            "         [-5.2083e+00, -2.2401e+00, -2.6898e+00,  ..., -2.9837e+00,\n",
            "          -1.4317e+00, -2.0429e+00],\n",
            "         [ 6.4166e-01,  7.3063e-01, -5.1492e+00,  ..., -1.7809e+00,\n",
            "          -3.9401e+00, -4.7720e+00],\n",
            "         ...,\n",
            "         [-4.1245e+00, -2.0154e+00, -1.3352e+00,  ..., -8.0456e-01,\n",
            "          -4.3065e+00,  2.3425e+00],\n",
            "         [-6.3465e+00, -3.6562e+00, -3.8260e+00,  ..., -4.8386e+00,\n",
            "          -4.8444e+00, -5.4744e+00],\n",
            "         [ 1.2082e+00,  1.2523e+00,  1.2599e+00,  ...,  6.1113e-01,\n",
            "           6.6730e-01,  1.5313e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 4.7877e-01,  7.3816e-01, -7.2471e-01,  ...,  1.8749e+00,\n",
            "           1.5152e+00,  1.1872e-03],\n",
            "         [-3.8085e+00, -2.0161e+00, -2.6175e+00,  ..., -1.8417e+00,\n",
            "          -7.5718e-01, -1.9415e+00],\n",
            "         [ 1.5134e-01,  6.2840e-01, -3.7624e+00,  ..., -8.5644e-01,\n",
            "          -2.8663e+00, -3.4084e+00],\n",
            "         ...,\n",
            "         [-2.7924e+00, -1.7421e+00, -1.2448e+00,  ..., -7.4979e-01,\n",
            "          -3.4229e+00,  2.2885e+00],\n",
            "         [-4.5290e+00, -2.9810e+00, -2.9711e+00,  ..., -3.3578e+00,\n",
            "          -3.9470e+00, -3.9245e+00],\n",
            "         [ 1.3815e+00,  1.7016e+00,  1.7416e+00,  ...,  1.0764e+00,\n",
            "           8.6528e-01,  1.3034e+00]],\n",
            "\n",
            "        [[ 1.8211e+00,  1.9678e+00,  5.4655e-01,  ...,  1.9685e+00,\n",
            "           2.3169e+00,  2.5752e+00],\n",
            "         [-4.4792e+00, -1.3930e+00, -1.8065e+00,  ..., -3.2948e+00,\n",
            "          -2.6786e+00, -1.2454e+00],\n",
            "         [ 1.2814e+00,  7.3010e-01, -4.5135e+00,  ..., -3.0313e+00,\n",
            "          -4.0077e+00, -4.1790e+00],\n",
            "         ...,\n",
            "         [-3.9847e+00, -1.7487e+00, -9.2695e-01,  ..., -1.0242e+00,\n",
            "          -3.1877e+00,  2.8419e-01],\n",
            "         [-5.8541e+00, -3.2562e+00, -3.5628e+00,  ..., -3.9928e+00,\n",
            "          -3.1074e+00, -4.3027e+00],\n",
            "         [ 1.0936e+00,  6.1659e-01, -1.3886e-01,  ..., -1.0921e+00,\n",
            "           5.6615e-01,  1.5600e+00]],\n",
            "\n",
            "        [[ 4.0164e-01,  5.4760e-01, -1.5670e+00,  ...,  2.1434e+00,\n",
            "           1.5748e+00, -3.8303e-01],\n",
            "         [-4.9714e+00, -3.1246e+00, -3.9074e+00,  ..., -2.1867e+00,\n",
            "          -1.0824e+00, -2.9071e+00],\n",
            "         [-2.8104e-01,  6.1684e-01, -4.8977e+00,  ..., -1.1130e+00,\n",
            "          -3.7557e+00, -4.6244e+00],\n",
            "         ...,\n",
            "         [-3.7321e+00, -2.1699e+00, -2.2228e+00,  ..., -1.0048e+00,\n",
            "          -4.6460e+00,  3.2813e+00],\n",
            "         [-5.9049e+00, -4.3562e+00, -4.1140e+00,  ..., -4.8153e+00,\n",
            "          -5.2447e+00, -5.4525e+00],\n",
            "         [ 2.5715e+00,  3.1958e+00,  3.3248e+00,  ...,  1.8290e+00,\n",
            "           1.6509e+00,  2.2661e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -1.6179,  -1.6513,  -4.0188,  ...,  -1.3126,  -1.5187,  -1.1865],\n",
            "         [ -9.0686,  -5.6230,  -6.7646,  ...,  -7.5401,  -7.4046,  -5.6945],\n",
            "         [ -2.1972,  -3.1058, -10.0787,  ...,  -7.2806,  -9.0284,  -9.2762],\n",
            "         ...,\n",
            "         [ -8.5434,  -6.0671,  -5.7468,  ...,  -4.8351,  -8.1928,  -3.8266],\n",
            "         [-10.8198,  -7.8505,  -8.8946,  ...,  -8.5845,  -8.1481,  -9.4756],\n",
            "         [ -2.5029,  -3.2132,  -4.7296,  ...,  -4.8918,  -3.5638,  -2.3341]],\n",
            "\n",
            "        [[ -2.3837,  -2.5158,  -4.3956,  ...,  -1.3454,  -1.4614,  -3.2712],\n",
            "         [ -7.3950,  -5.6938,  -6.5158,  ...,  -5.7730,  -4.2348,  -5.5631],\n",
            "         [ -2.7112,  -2.8109,  -8.0385,  ...,  -4.6278,  -6.6918,  -7.4569],\n",
            "         ...,\n",
            "         [ -6.3507,  -5.4157,  -5.0036,  ...,  -4.3151,  -7.2983,  -0.9745],\n",
            "         [ -8.3388,  -6.7773,  -7.0544,  ...,  -7.5858,  -7.7968,  -8.1219],\n",
            "         [ -1.5950,  -1.7393,  -1.8790,  ...,  -2.4600,  -2.4212,  -2.0385]],\n",
            "\n",
            "        [[ -2.1937,  -2.2422,  -4.5672,  ...,  -1.0066,  -1.1827,  -2.6046],\n",
            "         [ -8.4345,  -5.8932,  -6.8090,  ...,  -6.6741,  -5.1856,  -5.6334],\n",
            "         [ -2.5845,  -2.9225,  -9.2684,  ...,  -5.4713,  -7.6940,  -8.3625],\n",
            "         ...,\n",
            "         [ -7.3507,  -5.6685,  -5.4544,  ...,  -4.4950,  -8.0605,  -1.2479],\n",
            "         [ -9.5727,  -7.3093,  -7.9453,  ...,  -8.5290,  -8.5983,  -9.0649],\n",
            "         [ -2.0180,  -2.4007,  -2.8594,  ...,  -3.0793,  -3.0866,  -2.0592]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.4296,  -2.6179,  -4.1084,  ...,  -1.5529,  -1.5933,  -3.3171],\n",
            "         [ -6.7169,  -5.3721,  -6.0012,  ...,  -5.2695,  -3.8657,  -5.2598],\n",
            "         [ -2.7571,  -2.7276,  -7.1461,  ...,  -4.2843,  -5.9748,  -6.7267],\n",
            "         ...,\n",
            "         [ -5.7008,  -5.0981,  -4.6285,  ...,  -4.1776,  -6.5314,  -1.0298],\n",
            "         [ -7.4374,  -6.3370,  -6.3548,  ...,  -6.7857,  -7.0555,  -7.2428],\n",
            "         [ -1.5269,  -1.6544,  -1.6421,  ...,  -2.3514,  -2.2432,  -2.0149]],\n",
            "\n",
            "        [[ -1.6846,  -1.7277,  -3.5780,  ...,  -1.4346,  -1.5455,  -1.2883],\n",
            "         [ -7.9849,  -5.0885,  -5.9310,  ...,  -6.6979,  -6.5410,  -5.1089],\n",
            "         [ -2.2243,  -2.9655,  -8.6380,  ...,  -6.4344,  -7.8701,  -8.0424],\n",
            "         ...,\n",
            "         [ -7.4904,  -5.4443,  -5.0515,  ...,  -4.4273,  -7.0501,  -3.5793],\n",
            "         [ -9.3598,  -6.9518,  -7.6873,  ...,  -7.3960,  -6.9698,  -8.1661],\n",
            "         [ -2.4121,  -3.0790,  -4.2634,  ...,  -4.4953,  -3.2962,  -2.3035]],\n",
            "\n",
            "        [[ -2.8208,  -3.3269,  -5.6995,  ...,  -1.5722,  -1.8864,  -4.3338],\n",
            "         [ -8.1938,  -6.9991,  -8.0400,  ...,  -5.9023,  -4.5436,  -6.8579],\n",
            "         [ -3.5034,  -3.2577,  -9.0302,  ...,  -4.8286,  -7.2170,  -8.5752],\n",
            "         ...,\n",
            "         [ -6.9545,  -6.0445,  -6.3554,  ...,  -4.7204,  -8.1073,  -0.6695],\n",
            "         [ -9.1273,  -8.2307,  -8.2465,  ...,  -8.5309,  -8.7060,  -9.4033],\n",
            "         [ -0.6509,  -0.6787,  -0.8077,  ...,  -1.8866,  -1.8104,  -1.6847]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 0.4045,  0.4567, -0.9875,  ...,  1.2862,  1.0341,  1.5107],\n",
            "        [ 1.1099,  1.5000, -0.4005,  ...,  0.5381,  0.6730,  1.5960],\n",
            "        [ 0.6278,  1.1245, -1.1252,  ...,  1.6205,  1.4327,  1.9834],\n",
            "        ...,\n",
            "        [ 0.3806,  0.3548, -1.4197,  ...,  1.6449,  1.4272,  2.0059],\n",
            "        [ 1.8243,  2.0693,  0.5242,  ..., -0.9200,  0.6391,  1.6406],\n",
            "        [ 1.6680,  1.9016,  0.4657,  ..., -0.7984,  0.5595,  1.4985]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 4.0448e-01,  4.5672e-01, -9.8750e-01,  ...,  1.6723e+00,\n",
            "           1.1331e+00, -2.6556e-01],\n",
            "         [-3.4755e+00, -2.1628e+00, -2.6415e+00,  ..., -1.5804e+00,\n",
            "          -8.0028e-01, -1.9465e+00],\n",
            "         [-1.3253e-01,  5.0847e-01, -3.3648e+00,  ..., -7.6084e-01,\n",
            "          -2.6324e+00, -3.0947e+00],\n",
            "         ...,\n",
            "         [-2.4864e+00, -1.5324e+00, -1.4648e+00,  ..., -7.7996e-01,\n",
            "          -3.1535e+00,  2.2559e+00],\n",
            "         [-3.9945e+00, -3.0926e+00, -2.9072e+00,  ..., -3.0707e+00,\n",
            "          -3.6036e+00, -3.5849e+00],\n",
            "         [ 1.7745e+00,  2.1061e+00,  2.1594e+00,  ...,  1.2862e+00,\n",
            "           1.0341e+00,  1.5107e+00]],\n",
            "\n",
            "        [[ 1.1099e+00,  1.5000e+00, -4.0048e-01,  ...,  2.7875e+00,\n",
            "           2.6750e+00,  1.1337e+00],\n",
            "         [-5.3668e+00, -2.2502e+00, -2.6889e+00,  ..., -3.1294e+00,\n",
            "          -1.5430e+00, -2.0477e+00],\n",
            "         [ 6.9867e-01,  7.6377e-01, -5.3195e+00,  ..., -1.9631e+00,\n",
            "          -4.0824e+00, -4.9366e+00],\n",
            "         ...,\n",
            "         [-4.2897e+00, -2.0376e+00, -1.3501e+00,  ..., -8.0577e-01,\n",
            "          -4.3876e+00,  2.2707e+00],\n",
            "         [-6.5703e+00, -3.7437e+00, -3.9355e+00,  ..., -5.0134e+00,\n",
            "          -4.9465e+00, -5.6489e+00],\n",
            "         [ 1.1876e+00,  1.1913e+00,  1.1863e+00,  ...,  5.3812e-01,\n",
            "           6.7303e-01,  1.5960e+00]],\n",
            "\n",
            "        [[ 6.2779e-01,  1.1245e+00, -1.1252e+00,  ...,  2.6961e+00,\n",
            "           2.2243e+00, -1.0920e-02],\n",
            "         [-5.7585e+00, -3.0220e+00, -3.9237e+00,  ..., -2.7150e+00,\n",
            "          -9.6356e-01, -2.9335e+00],\n",
            "         [ 2.1119e-01,  9.1532e-01, -5.7911e+00,  ..., -1.3539e+00,\n",
            "          -4.3424e+00, -5.3989e+00],\n",
            "         ...,\n",
            "         [-4.4421e+00, -2.5579e+00, -1.8752e+00,  ..., -8.9355e-01,\n",
            "          -5.3726e+00,  3.4287e+00],\n",
            "         [-7.0619e+00, -4.3866e+00, -4.4944e+00,  ..., -5.5244e+00,\n",
            "          -6.0513e+00, -6.2945e+00],\n",
            "         [ 1.9888e+00,  2.5279e+00,  2.7202e+00,  ...,  1.6205e+00,\n",
            "           1.4327e+00,  1.9834e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 3.8061e-01,  3.5476e-01, -1.4197e+00,  ...,  1.8235e+00,\n",
            "           1.2250e+00, -4.1944e-01],\n",
            "         [-4.0940e+00, -2.7292e+00, -3.3340e+00,  ..., -1.7907e+00,\n",
            "          -9.6960e-01, -2.4441e+00],\n",
            "         [-3.4898e-01,  4.6740e-01, -3.9562e+00,  ..., -8.9038e-01,\n",
            "          -3.1010e+00, -3.7441e+00],\n",
            "         ...,\n",
            "         [-2.9907e+00, -1.7491e+00, -1.9763e+00,  ..., -9.3901e-01,\n",
            "          -3.7912e+00,  2.7579e+00],\n",
            "         [-4.7119e+00, -3.7923e+00, -3.4961e+00,  ..., -3.8488e+00,\n",
            "          -4.2721e+00, -4.3937e+00],\n",
            "         [ 2.3759e+00,  2.8889e+00,  2.9354e+00,  ...,  1.6449e+00,\n",
            "           1.4272e+00,  2.0059e+00]],\n",
            "\n",
            "        [[ 1.8243e+00,  2.0693e+00,  5.2418e-01,  ...,  2.2707e+00,\n",
            "           2.6068e+00,  2.5546e+00],\n",
            "         [-4.9361e+00, -1.5208e+00, -1.9670e+00,  ..., -3.4993e+00,\n",
            "          -2.6979e+00, -1.4110e+00],\n",
            "         [ 1.3340e+00,  8.1167e-01, -4.9755e+00,  ..., -3.1820e+00,\n",
            "          -4.2418e+00, -4.6588e+00],\n",
            "         ...,\n",
            "         [-4.3231e+00, -1.9366e+00, -1.0035e+00,  ..., -9.9255e-01,\n",
            "          -3.5582e+00,  4.9012e-01],\n",
            "         [-6.4446e+00, -3.5040e+00, -3.8397e+00,  ..., -4.5167e+00,\n",
            "          -3.6839e+00, -4.9107e+00],\n",
            "         [ 1.0593e+00,  7.0976e-01, -1.9860e-02,  ..., -9.1999e-01,\n",
            "           6.3906e-01,  1.6406e+00]],\n",
            "\n",
            "        [[ 1.6680e+00,  1.9016e+00,  4.6573e-01,  ...,  2.1473e+00,\n",
            "           2.4349e+00,  2.3231e+00],\n",
            "         [-4.5804e+00, -1.4254e+00, -1.8434e+00,  ..., -3.2374e+00,\n",
            "          -2.4748e+00, -1.3154e+00],\n",
            "         [ 1.2049e+00,  7.5736e-01, -4.5926e+00,  ..., -2.8880e+00,\n",
            "          -3.9133e+00, -4.2825e+00],\n",
            "         ...,\n",
            "         [-3.9551e+00, -1.8100e+00, -9.3517e-01,  ..., -9.1872e-01,\n",
            "          -3.2877e+00,  5.2288e-01],\n",
            "         [-5.9234e+00, -3.2423e+00, -3.5404e+00,  ..., -4.1514e+00,\n",
            "          -3.4522e+00, -4.5273e+00],\n",
            "         [ 9.7293e-01,  6.4943e-01, -6.2473e-04,  ..., -7.9838e-01,\n",
            "           5.5946e-01,  1.4985e+00]]], grad_fn=<ViewBackward>)\n",
            "output tensor([[[ -2.4902,  -2.8695,  -4.2661,  ...,  -1.7201,  -1.8456,  -3.5540],\n",
            "         [ -6.3701,  -5.4890,  -5.9200,  ...,  -4.9729,  -3.7790,  -5.2350],\n",
            "         [ -3.0272,  -2.8178,  -6.6434,  ...,  -4.1533,  -5.6111,  -6.3831],\n",
            "         ...,\n",
            "         [ -5.3811,  -4.8587,  -4.7433,  ...,  -4.1724,  -6.1322,  -1.0325],\n",
            "         [ -6.8892,  -6.4188,  -6.1858,  ...,  -6.4631,  -6.5824,  -6.8733],\n",
            "         [ -1.1202,  -1.2201,  -1.1191,  ...,  -2.1062,  -1.9446,  -1.7777]],\n",
            "\n",
            "        [[ -2.1701,  -2.2122,  -4.6067,  ...,  -0.9487,  -1.1583,  -2.4966],\n",
            "         [ -8.6468,  -5.9624,  -6.8952,  ...,  -6.8657,  -5.3762,  -5.6779],\n",
            "         [ -2.5813,  -2.9484,  -9.5257,  ...,  -5.6993,  -7.9156,  -8.5669],\n",
            "         ...,\n",
            "         [ -7.5696,  -5.7498,  -5.5563,  ...,  -4.5420,  -8.2208,  -1.3595],\n",
            "         [ -9.8503,  -7.4559,  -8.1417,  ...,  -8.7496,  -8.7798,  -9.2792],\n",
            "         [ -2.0924,  -2.5209,  -3.0199,  ...,  -3.1981,  -3.1602,  -2.0343]],\n",
            "\n",
            "        [[ -2.5608,  -2.7320,  -5.5101,  ...,  -1.1893,  -1.5453,  -4.0574],\n",
            "         [ -8.9471,  -6.8785,  -8.3086,  ...,  -6.6004,  -4.7332,  -6.9800],\n",
            "         [ -2.9774,  -2.9411, -10.1760,  ...,  -5.2393,  -8.1121,  -9.4454],\n",
            "         ...,\n",
            "         [ -7.6307,  -6.4144,  -6.2600,  ...,  -4.7789,  -9.1423,  -0.6178],\n",
            "         [-10.2505,  -8.2430,  -8.8793,  ...,  -9.4097,  -9.8209, -10.3410],\n",
            "         [ -1.1997,  -1.3286,  -1.6647,  ...,  -2.2648,  -2.3369,  -2.0631]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ -2.7024,  -3.2733,  -5.1180,  ...,  -1.7035,  -1.9555,  -4.0209],\n",
            "         [ -7.1771,  -6.3573,  -7.0323,  ...,  -5.3177,  -4.1502,  -6.0455],\n",
            "         [ -3.4320,  -3.1607,  -7.6545,  ...,  -4.4174,  -6.2816,  -7.3455],\n",
            "         ...,\n",
            "         [ -6.0737,  -5.3772,  -5.6746,  ...,  -4.4660,  -6.9718,  -0.8436],\n",
            "         [ -7.7949,  -7.4204,  -7.1944,  ...,  -7.3758,  -7.4527,  -7.9951],\n",
            "         [ -0.7072,  -0.7392,  -0.7629,  ...,  -1.8821,  -1.7534,  -1.5955]],\n",
            "\n",
            "        [[ -1.7294,  -1.7432,  -3.7703,  ...,  -1.2639,  -1.4066,  -1.3611],\n",
            "         [ -8.4898,  -5.3332,  -6.2615,  ...,  -7.0340,  -6.7114,  -5.3267],\n",
            "         [ -2.2196,  -3.0008,  -9.2700,  ...,  -6.7166,  -8.2553,  -8.5745],\n",
            "         ...,\n",
            "         [ -7.8768,  -5.7491,  -5.2980,  ...,  -4.5272,  -7.5717,  -3.4256],\n",
            "         [ -9.9983,  -7.3164,  -8.1342,  ...,  -8.0514,  -7.6974,  -8.8264],\n",
            "         [ -2.4944,  -3.1027,  -4.3143,  ...,  -4.4547,  -3.3744,  -2.2751]],\n",
            "\n",
            "        [[ -1.7818,  -1.7908,  -3.6074,  ...,  -1.2918,  -1.3833,  -1.4390],\n",
            "         [ -8.0301,  -5.1178,  -5.9166,  ...,  -6.6765,  -6.2929,  -5.0775],\n",
            "         [ -2.2449,  -2.9350,  -8.6658,  ...,  -6.3270,  -7.7315,  -8.0446],\n",
            "         ...,\n",
            "         [ -7.4049,  -5.5023,  -5.0084,  ...,  -4.3578,  -7.1058,  -3.2392],\n",
            "         [ -9.3731,  -6.9346,  -7.6136,  ...,  -7.5905,  -7.2704,  -8.2894],\n",
            "         [ -2.4768,  -3.0429,  -4.0738,  ...,  -4.2374,  -3.2587,  -2.2636]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "decoder tensor([[ 1.7927,  1.9771,  0.5392,  ..., -1.0165,  0.6043,  1.5697],\n",
            "        [ 1.8055,  1.9891,  0.5431,  ..., -1.0301,  0.6101,  1.5798],\n",
            "        [ 1.7947,  1.9781,  0.5399,  ..., -1.0199,  0.6048,  1.5707],\n",
            "        ...,\n",
            "        [ 1.7829,  1.9740,  0.5355,  ..., -0.9962,  0.6031,  1.5660],\n",
            "        [ 1.7963,  1.9829,  0.5400,  ..., -1.0163,  0.6072,  1.5741],\n",
            "        [ 1.7813,  1.9754,  0.5347,  ..., -0.9898,  0.6040,  1.5667]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "before softmax tensor([[[ 1.7927,  1.9771,  0.5392,  ...,  2.0509,  2.3615,  2.4992],\n",
            "         [-4.5137, -1.4072, -1.7863,  ..., -3.3139, -2.6451, -1.2725],\n",
            "         [ 1.2433,  0.6976, -4.5464,  ..., -3.0496, -4.0077, -4.2225],\n",
            "         ...,\n",
            "         [-3.9896, -1.7460, -0.9109,  ..., -0.9451, -3.2220,  0.2865],\n",
            "         [-5.8836, -3.2667, -3.5767,  ..., -4.0436, -3.1734, -4.3553],\n",
            "         [ 1.0787,  0.6281, -0.1192,  ..., -1.0165,  0.6043,  1.5697]],\n",
            "\n",
            "        [[ 1.8055,  1.9891,  0.5431,  ...,  2.0553,  2.3693,  2.5193],\n",
            "         [-4.5338, -1.4160, -1.7918,  ..., -3.3331, -2.6643, -1.2776],\n",
            "         [ 1.2520,  0.7011, -4.5693,  ..., -3.0708, -4.0326, -4.2430],\n",
            "         ...,\n",
            "         [-4.0130, -1.7535, -0.9151,  ..., -0.9535, -3.2383,  0.2793],\n",
            "         [-5.9168, -3.2862, -3.5972,  ..., -4.0624, -3.1823, -4.3748],\n",
            "         [ 1.0886,  0.6310, -0.1210,  ..., -1.0301,  0.6101,  1.5798]],\n",
            "\n",
            "        [[ 1.7947,  1.9781,  0.5399,  ...,  2.0492,  2.3603,  2.5025],\n",
            "         [-4.5134, -1.4081, -1.7856,  ..., -3.3156, -2.6480, -1.2721],\n",
            "         [ 1.2443,  0.6977, -4.5466,  ..., -3.0519, -4.0102, -4.2220],\n",
            "         ...,\n",
            "         [-3.9906, -1.7459, -0.9109,  ..., -0.9468, -3.2218,  0.2836],\n",
            "         [-5.8846, -3.2683, -3.5779,  ..., -4.0424, -3.1705, -4.3538],\n",
            "         [ 1.0809,  0.6279, -0.1201,  ..., -1.0199,  0.6048,  1.5707]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.7829,  1.9740,  0.5355,  ...,  2.0651,  2.3730,  2.4823],\n",
            "         [-4.5230, -1.4037, -1.7932,  ..., -3.3083, -2.6305, -1.2775],\n",
            "         [ 1.2392,  0.6987, -4.5539,  ..., -3.0402, -3.9988, -4.2337],\n",
            "         ...,\n",
            "         [-3.9902, -1.7500, -0.9128,  ..., -0.9355, -3.2296,  0.3048],\n",
            "         [-5.8882, -3.2626, -3.5754,  ..., -4.0589, -3.1979, -4.3728],\n",
            "         [ 1.0657,  0.6311, -0.1129,  ..., -0.9962,  0.6031,  1.5660]],\n",
            "\n",
            "        [[ 1.7963,  1.9829,  0.5400,  ...,  2.0592,  2.3707,  2.5042],\n",
            "         [-4.5294, -1.4110, -1.7924,  ..., -3.3230, -2.6505, -1.2775],\n",
            "         [ 1.2468,  0.7001, -4.5630,  ..., -3.0583, -4.0188, -4.2392],\n",
            "         ...,\n",
            "         [-4.0037, -1.7521, -0.9142,  ..., -0.9462, -3.2347,  0.2897],\n",
            "         [-5.9051, -3.2766, -3.5883,  ..., -4.0609, -3.1886, -4.3739],\n",
            "         [ 1.0792,  0.6310, -0.1177,  ..., -1.0163,  0.6072,  1.5741]],\n",
            "\n",
            "        [[ 1.7813,  1.9754,  0.5347,  ...,  2.0729,  2.3804,  2.4790],\n",
            "         [-4.5324, -1.4042, -1.7979,  ..., -3.3103, -2.6282, -1.2812],\n",
            "         [ 1.2394,  0.7000, -4.5630,  ..., -3.0409, -4.0005, -4.2440],\n",
            "         ...,\n",
            "         [-3.9962, -1.7537, -0.9147,  ..., -0.9330, -3.2372,  0.3119],\n",
            "         [-5.8985, -3.2654, -3.5798,  ..., -4.0708, -3.2118, -4.3860],\n",
            "         [ 1.0619,  0.6332, -0.1103,  ..., -0.9898,  0.6040,  1.5667]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "output tensor([[[-1.7069, -1.7247, -3.5773,  ..., -1.3610, -1.4967, -1.3517],\n",
            "         [-8.0133, -5.1090, -5.9028,  ..., -6.7258, -6.5033, -5.1233],\n",
            "         [-2.2563, -3.0042, -8.6629,  ..., -6.4615, -7.8659, -8.0733],\n",
            "         ...,\n",
            "         [-7.4892, -5.4478, -5.0274,  ..., -4.3570, -7.0802, -3.5644],\n",
            "         [-9.3832, -6.9685, -7.6932,  ..., -7.4555, -7.0316, -8.2061],\n",
            "         [-2.4209, -3.0737, -4.2357,  ..., -4.4284, -3.2539, -2.2812]],\n",
            "\n",
            "        [[-1.7019, -1.7203, -3.5882,  ..., -1.3620, -1.5021, -1.3439],\n",
            "         [-8.0413, -5.1254, -5.9231,  ..., -6.7504, -6.5356, -5.1408],\n",
            "         [-2.2554, -3.0083, -8.7005,  ..., -6.4882, -7.9039, -8.1063],\n",
            "         ...,\n",
            "         [-7.5205, -5.4630, -5.0464,  ..., -4.3708, -7.1096, -3.5839],\n",
            "         [-9.4242, -6.9957, -7.7284,  ..., -7.4797, -7.0536, -8.2380],\n",
            "         [-2.4189, -3.0784, -4.2523,  ..., -4.4475, -3.2613, -2.2835]],\n",
            "\n",
            "        [[-1.7059, -1.7240, -3.5775,  ..., -1.3625, -1.4988, -1.3500],\n",
            "         [-8.0139, -5.1102, -5.9030,  ..., -6.7273, -6.5072, -5.1245],\n",
            "         [-2.2562, -3.0045, -8.6640,  ..., -6.4636, -7.8693, -8.0744],\n",
            "         ...,\n",
            "         [-7.4911, -5.4480, -5.0283,  ..., -4.3585, -7.0809, -3.5688],\n",
            "         [-9.3851, -6.9704, -7.6953,  ..., -7.4541, -7.0296, -8.2063],\n",
            "         [-2.4196, -3.0743, -4.2376,  ..., -4.4317, -3.2544, -2.2818]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.7128, -1.7280, -3.5793,  ..., -1.3504, -1.4833, -1.3613],\n",
            "         [-8.0187, -5.1057, -5.9080,  ..., -6.7238, -6.4868, -5.1211],\n",
            "         [-2.2564, -3.0033, -8.6687,  ..., -6.4557, -7.8550, -8.0772],\n",
            "         ...,\n",
            "         [-7.4859, -5.4520, -5.0276,  ..., -4.3510, -7.0859, -3.5387],\n",
            "         [-9.3839, -6.9646, -7.6902,  ..., -7.4744, -7.0542, -8.2164],\n",
            "         [-2.4300, -3.0709, -4.2277,  ..., -4.4117, -3.2531, -2.2776]],\n",
            "\n",
            "        [[-1.7063, -1.7235, -3.5845,  ..., -1.3573, -1.4944, -1.3510],\n",
            "         [-8.0320, -5.1174, -5.9169,  ..., -6.7395, -6.5157, -5.1327],\n",
            "         [-2.2558, -3.0063, -8.6874,  ..., -6.4749, -7.8839, -8.0943],\n",
            "         ...,\n",
            "         [-7.5063, -5.4585, -5.0386,  ..., -4.3627, -7.0998, -3.5655],\n",
            "         [-9.4077, -6.9830, -7.7127,  ..., -7.4774, -7.0537, -8.2291],\n",
            "         [-2.4234, -3.0754, -4.2422,  ..., -4.4328, -3.2579, -2.2810]],\n",
            "\n",
            "        [[-1.7144, -1.7285, -3.5829,  ..., -1.3456, -1.4782, -1.3640],\n",
            "         [-8.0281, -5.1082, -5.9155,  ..., -6.7288, -6.4867, -5.1242],\n",
            "         [-2.2563, -3.0040, -8.6806,  ..., -6.4595, -7.8591, -8.0871],\n",
            "         ...,\n",
            "         [-7.4919, -5.4577, -5.0323,  ..., -4.3516, -7.0957, -3.5311],\n",
            "         [-9.3942, -6.9694, -7.6974,  ..., -7.4894, -7.0704, -8.2291],\n",
            "         [-2.4338, -3.0708, -4.2279,  ..., -4.4083, -3.2546, -2.2764]]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n",
            "\u001b[95mEPOCH 000 \u001b[94mRL=523.7321 \u001b[92mKL=13.5709 \u001b[96m|rho|=0.6542\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtZ1jzp3cTEg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model_dict = torch.load('trained.model.pth')\n",
        "\n",
        "plt.figure(figsize=(18,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(\"Loss statistics\")\n",
        "ax1 = plt.gca()\n",
        "ax2 = ax1.twinx()\n",
        "ax1.set_xlabel('EPOCH', c='C3')\n",
        "ax1.tick_params(axis='x', labelcolor='C3')\n",
        "ax1.set_ylabel('Reconstruction Loss (RL)', c='C0')\n",
        "ax1.tick_params(axis='y', labelcolor='C0')\n",
        "ax1.plot(model_dict['stats']['rl'], lw=2, c='C0')\n",
        "ax2.set_ylabel('Kullback-Leibler divergence loss (KL)', c='C2')\n",
        "ax2.tick_params(axis='y', labelcolor='C2')\n",
        "ax2.plot(model_dict['stats']['kl'], lw=2, c='C2')\n",
        "ax2.grid(False)\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title(r\"$|Spearman\\ \\rho|$ correlation to experimental data\")\n",
        "plt.xlabel('EPOCH', c='C3')\n",
        "plt.tick_params(axis='x', labelcolor='C3')\n",
        "plt.plot(model_dict['stats']['cor'], lw=2, c='C9', label=\"Our result\")\n",
        "plt.tick_params(axis='y', labelcolor='C9')\n",
        "plt.axhline(y=0.74388, c='C6', lw=2, label=f'Paper result (without ensambling) ' + rf'$|\\rho|={round(0.74388, 4)}$')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(\"Latent space\")\n",
        "mask = df['label'].isin(df['label'].value_counts()[:5].index) # We limit to top 5 classes only\n",
        "vae = VAE(**model_dict['args'])\n",
        "vae.load_state_dict(model_dict['state_dict'])\n",
        "vae.eval()\n",
        "_, mu, logvar = vae(dataloader.dataset[mask], rep=False)\n",
        "columns = [str(i+1) for i in range(mu.shape[1])] + ['label']\n",
        "dfp = pd.DataFrame(data=np.c_[mu.detach().numpy(), df[mask]['label']], columns=columns)\n",
        "dfp = dfp.set_index('1').groupby('label')['2']\n",
        "dfp.plot(style='.', ms=2, alpha=0.5, legend=True);\n",
        "plt.tight_layout()\n",
        "None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-q1vFSds0iv"
      },
      "source": [
        "# vae in Pyro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOXUFSXIs-cJ",
        "outputId": "e62787b2-6756-4dfb-9f3d-70f1f90f0a63"
      },
      "source": [
        "!pip install pyro-ppl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/7a/fbab572fd385154a0c07b0fa138683aa52e14603bb83d37b198e5f9269b1/pyro_ppl-1.6.0-py3-none-any.whl (634kB)\n",
            "\r\u001b[K     |▌                               | 10kB 13.5MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 17.5MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 11.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 10.0MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 7.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 143kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 174kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 225kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 256kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 286kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 307kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 348kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 368kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 399kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 419kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 430kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 450kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 460kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 481kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 491kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 501kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 512kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 522kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 532kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 542kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 563kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 573kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 593kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 604kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 614kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 624kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl) (4.41.1)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/81/957ae78e6398460a7230b0eb9b8f1cb954c5e913e868e48d89324c68cec7/pyro_api-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.0->pyro-ppl) (3.7.4.3)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG6HZYrPs5lP"
      },
      "source": [
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "import pyro.contrib.examples.util  # patches torchvision\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "from torch.nn.functional import softplus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BD1g5yZ6hE_"
      },
      "source": [
        "import torch\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, latent_size):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "\n",
        "    self.fc11 = torch.nn.Linear(input_size, hidden_size)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "    # Latent space `mu` and `var`\n",
        "    self.fc21 = torch.nn.Linear(hidden_size, latent_size)\n",
        "    self.fc22 = torch.nn.Linear(hidden_size, latent_size)\n",
        "\n",
        "    self.softplus = torch.nn.Softplus()\n",
        "\n",
        "  def forward(self, x, rep=True):\n",
        "    x = x.view(-1, self.input_size)                    # flatten\n",
        "\n",
        "    x = self.fc11(x)                                \n",
        "    x = self.relu(x)  \n",
        "\n",
        "    # branch mu, var\n",
        "    mu, logvar = self.fc21(x), self.fc22(x)    \n",
        "\n",
        "    \n",
        "    if rep:                                            # reparameterize\n",
        "        x = mu + torch.randn_like(mu) * (0.5*logvar).exp() \n",
        "    else:                                              # or don't \n",
        "        x = mu\n",
        "    \n",
        "   \n",
        "    return mu, logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NMzsnIb6hOH"
      },
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, latent_size, alphabet_size, seq_len):\n",
        "    super().__init__()\n",
        "    self.alphabet_size = alphabet_size\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "    self.fc31 = torch.nn.Linear(latent_size, hidden_size)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.fc32 = torch.nn.Linear(hidden_size, input_size)\n",
        "\n",
        "  def forward(self, z):\n",
        "    x = self.fc31(z)                                \n",
        "    x = self.relu(x)\n",
        "    x = self.fc32(x)\n",
        "    x = x.view(-1, self.alphabet_size, self.seq_len)   # squeeze back\n",
        "    x = x.log_softmax(dim=1) \n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdTp75sBtOBw"
      },
      "source": [
        "# This VAE is as vanilla as it can be.\n",
        "\n",
        "def loss(self, x_hat, true_x, mu, logvar, beta=0.5):\n",
        "  RL = -(x_hat*true_x).sum(-1).sum(-1)                    # reconst. loss\n",
        "  KL = -0.5 * (1 + logvar - mu**2 - logvar.exp()).sum(-1) # KL loss\n",
        "  return RL + beta*KL, RL, KL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUrirKLIFUNi"
      },
      "source": [
        "class VAE(torch.nn.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(VAE, self).__init__()\n",
        "    self.hidden_size   = 64\n",
        "    self.latent_size   = 2\n",
        "    self.alphabet_size = kwargs['alphabet_size']\n",
        "    self.seq_len       = kwargs['seq_len']\n",
        "    self.input_size    = self.alphabet_size * self.seq_len\n",
        "\n",
        "    # create the encoder and decoder networks\n",
        "    self.encoder = Encoder(self.input_size, self.hidden_size, self.latent_size)\n",
        "    self.decoder = Decoder(self.input_size, self.hidden_size, self.latent_size, self.alphabet_size, self.seq_len)\n",
        "\n",
        "  def model(self, x):\n",
        "    # Encoder\n",
        "    priors_encoder = {} # Priors for the neural model\n",
        "    for name, par in self.encoder.named_parameters():     # Loop over all neural network parameters\n",
        "        if \"weight\" in name:\n",
        "          mean = torch.normal(mean=torch.zeros(1), std=((2/(par.shape[0]+par.shape[1]))**(1/2))*torch.ones(1))\n",
        "          logvar = -5\n",
        "          priors_encoder[name] = dist.Normal(mean*torch.ones(*par.shape), (0.5*logvar*torch.ones(*par.shape)).exp()) \n",
        "        else:\n",
        "          logvar = -10\n",
        "          priors_encoder[name] = dist.Normal(torch.zeros(*par.shape), (0.5*logvar*torch.ones(*par.shape)).exp())\n",
        "\n",
        "    bayesian_model_enc = pyro.random_module('bayesian_model_enc', self.encoder, priors_encoder) # Make this model and these priors a Pyro model\n",
        "    sampled_model_enc = bayesian_model_enc()\n",
        "\n",
        "    # Decoder\n",
        "    priors_decoder = {} # Priors for the neural model\n",
        "    for name, par in self.decoder.named_parameters():     # Loop over all neural network parameters\n",
        "        if \"weight\" in name:\n",
        "          mean = torch.normal(mean=torch.zeros(1), std=((2/(par.shape[0]+par.shape[1]))**(1/2))*torch.ones(1))\n",
        "          logvar = -5\n",
        "          priors_encoder[name] = dist.Normal(mean*torch.ones(*par.shape), (0.5*logvar*torch.ones(*par.shape)).exp()) #.to_event(0) \n",
        "        else:\n",
        "          logvar = -10\n",
        "          priors_encoder[name] = dist.Normal(torch.zeros(*par.shape), (0.5*logvar*torch.ones(*par.shape)).exp())\n",
        "    \n",
        "    bayesian_model_dec = pyro.random_module('bayesian_model_dec', self.decoder, priors_decoder) # Make this model and these priors a Pyro model\n",
        "    sampled_model_dec = bayesian_model_dec()\n",
        "\n",
        "    #with pyro.plate(\"data\", self.input_size):\n",
        "      # use the encoder to get the parameters used to define q(z|x)\n",
        "    z_loc, logvar = sampled_model_enc(x)\n",
        "    z_scale = softplus((0.5*logvar).exp())\n",
        "\n",
        "    # sample the latent code z\n",
        "    z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale))\n",
        "\n",
        "    # decode the latent code z\n",
        "    loc = sampled_model_dec(z)\n",
        "\n",
        "    pyro.sample(\"obs\", dist.Categorical(logits=loc), obs=x) \n",
        "\n",
        "  def vr(name, *shape):\n",
        "    return pyro.param(name, torch.autograd.Variable(torch.randn(*shape), requires_grad=True))\n",
        "\n",
        "  def guide(self, x):\n",
        "    wr1 = self.encoder.fc11.weight.shape[0]\n",
        "    wc1 = self.encoder.fc11.weight.shape[1]\n",
        "    wr2 = self.encoder.fc21.weight.shape[0]\n",
        "    wc2 = self.encoder.fc21.weight.shape[1]\n",
        "\n",
        "    priors_encoder = {\n",
        "        'fc11.weight': dist.Normal(VAE.vr('fc11w_mu', wr1, wc1), F.softplus(VAE.vr(\"fc11w_sigma\", wr1, wc1))),\n",
        "        'fc11.bias': dist.Normal(VAE.vr('fc11b_mu', wr1), F.softplus(VAE.vr(\"fc11b_sigma\", wr1))),\n",
        "        'fc21.weight': dist.Normal(VAE.vr('fc21w_mu', wr2, wc2), F.softplus(VAE.vr(\"fc21w_sigma\", wr2, wc2))),\n",
        "        'fc21.bias': dist.Normal(VAE.vr('fc21b_mu', wr2), F.softplus(VAE.vr(\"fc21b_sigma\", wr2))),\n",
        "        'fc22.weight': dist.Normal(VAE.vr('fc22w_mu', wr2, wc2), F.softplus(VAE.vr(\"fc22w_sigma\", wr2, wc2))),\n",
        "        'fc22.bias': dist.Normal(VAE.vr('fc22b_mu', wr2), F.softplus(VAE.vr(\"fc21b_sigma\", wr2)))\n",
        "    }\n",
        "\n",
        "    bayesian_model_enc = pyro.random_module('bayesian_model_enc', self.encoder, priors_encoder) # Make this model and these priors a Pyro model\n",
        "    sampled_model_enc = bayesian_model_enc()\n",
        "\n",
        "    wr1 = self.decoder.fc31.weight.shape[0]\n",
        "    wc1 = self.decoder.fc31.weight.shape[1]\n",
        "    wr2 = self.decoder.fc32.weight.shape[0]\n",
        "    wc2 = self.decoder.fc32.weight.shape[1]\n",
        "\n",
        "    priors_decoder = {\n",
        "        'fc31.weight': dist.Normal(VAE.vr('fc31w_mu', wr1, wc1), F.softplus(VAE.vr(\"fc31w_sigma\", wr1, wc1))),\n",
        "        'fc31.bias': dist.Normal(VAE.vr('fc31b_mu', wr1), F.softplus(VAE.vr(\"fc31b_sigma\", wr1))),\n",
        "        'fc32.weight': dist.Normal(VAE.vr('fc32w_mu', wr2, wc2), F.softplus(VAE.vr(\"fc32w_sigma\", wr2, wc2))),\n",
        "        'fc32.bias': dist.Normal(VAE.vr('fc32b_mu', wr2), F.softplus(VAE.vr(\"fc32b_sigma\", wr2)))\n",
        "    }\n",
        "\n",
        "    bayesian_model_dec = pyro.random_module('bayesian_model_dec', self.decoder, priors_decoder) # Make this model and these priors a Pyro model\n",
        "    sampled_model_dec = bayesian_model_dec()\n",
        "\n",
        "    #with pyro.plate(\"data\", x.shape[0]):\n",
        "      # use the encoder to get the parameters used to define q(z|x)\n",
        "    z_loc, logvar = sampled_model_enc(x)\n",
        "    z_scale = softplus((0.5*logvar).exp())\n",
        "    \n",
        "    # sample the latent code z\n",
        "    pyro.sample(\"latent\", dist.Normal(z_loc, z_scale))\n",
        "\n",
        "    return sampled_model_enc, sampled_model_dec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEmZjVCdEPxB"
      },
      "source": [
        "# train in Pyro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVJ1lDCaER16",
        "outputId": "230cadf3-28c6-49ab-96e1-b8c14133d9b2"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "#from misc import data, c\n",
        "from torch import optim\n",
        "from scipy.stats import spearmanr\n",
        "#from vae import VAE\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataloader, df, mutants_tensor, mutants_df = data(batch_size = 64)\n",
        "\n",
        "wildtype   = dataloader.dataset[0] # one-hot-encoded wildtype \n",
        "eval_batch = torch.cat([wildtype.unsqueeze(0), mutants_tensor])\n",
        "\n",
        "args = {\n",
        "    'alphabet_size': dataloader.dataset[0].shape[0],\n",
        "    'seq_len':       dataloader.dataset[0].shape[1]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing fasta '/content/gdrive/MyDrive/data/BLAT_ECOLX_hmmerbit_plmc_n5_m30_f50_t0.2_r24-286_id100_b105.a2m'\n",
            "Parsing labels '/content/gdrive/MyDrive/data/BLAT_ECOLX_hmmerbit_plmc_n5_m30_f50_t0.2_r24-286_id100_b105_LABELS.a2m'\n",
            "Generating 8403 1-hot encodings\n",
            "Generating 8403 1-hot encodings. Took 0.989s torch.Size([8403, 23, 253])\n",
            "Generating 4807 1-hot encodings\n",
            "Generating 4807 1-hot encodings. Took 0.434s torch.Size([4807, 23, 253])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPGplkv7T-Um"
      },
      "source": [
        "#from pyro.contrib.autoguide import AutoDiagonalNormal\n",
        "vae   = VAE(**args)\n",
        "opt   = Adam({\"lr\": 0.000000001})\n",
        "svi = SVI(vae.model, vae.guide, opt, loss=Trace_ELBO())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7O2bh-0MOqr"
      },
      "source": [
        "def train(svi, train_loader):\n",
        "    # initialize loss accumulator\n",
        "    epoch_loss = 0.\n",
        "    # do a training epoch over each mini-batch x returned\n",
        "    # by the data loader\n",
        "    for batch in train_loader:\n",
        "        # do ELBO gradient and accumulate loss\n",
        "        epoch_loss += svi.step(batch)\n",
        "\n",
        "    # return epoch loss\n",
        "    normalizer_train = len(train_loader.dataset)\n",
        "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
        "    return total_epoch_loss_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjL3n1suMe6I"
      },
      "source": [
        "def evaluate(svi, eval_batch):\n",
        "    # compute ELBO estimate and accumulate loss\n",
        "    test_loss = svi.evaluate_loss(eval_batch)\n",
        "    return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "TaucsgGaE3Bi",
        "outputId": "4bbb458f-9c3e-4d51-aa85-29d2a8550385"
      },
      "source": [
        "train_elbo = []\n",
        "test_elbo = []\n",
        "# training loop\n",
        "for epoch in range(1):\n",
        "    total_epoch_loss_train = train(svi, dataloader)\n",
        "    train_elbo.append(-total_epoch_loss_train)\n",
        "\n",
        "    # report test diagnostics\n",
        "    total_epoch_loss_test = evaluate(svi, eval_batch)\n",
        "    test_elbo.append(-total_epoch_loss_test)\n",
        "\n",
        "    to_print = [\n",
        "        f\"{c.HEADER}EPOCH %03d\" % epoch,\n",
        "        f\"{c.OKBLUE}TRAIN LOSS=%4.4f\" % total_epoch_loss_train,\n",
        "        f\"{c.OKGREEN}TEST LOSS=%4.4f\" % total_epoch_loss_test\n",
        "    ]\n",
        "    print(\" \".join(to_print))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyro/primitives.py:451: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/poutine/messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-208-08288c5cd857>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/distributions/distribution.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The parameter logits has invalid values",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-210-d4faf349b840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtotal_epoch_loss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_elbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtotal_epoch_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-83bd568b4688>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(svi, train_loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# do ELBO gradient and accumulate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# return epoch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[1;32m     57\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m---> 58\u001b[0;31m             \"flat\", self.max_plate_nesting, model, guide, args, kwargs)\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[0;32m---> 48\u001b[0;31m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mcheck_model_guide_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"{}\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_RETURN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_RETURN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"return\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/poutine/messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_context_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-208-08288c5cd857>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_model_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mvr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyro/distributions/distribution.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The parameter logits has invalid values\n                        Trace Shapes:             \n                         Param Sites:             \n     bayesian_model_dec$$$fc31.weight      64    2\n       bayesian_model_dec$$$fc31.bias           64\n     bayesian_model_dec$$$fc32.weight    5819   64\n       bayesian_model_dec$$$fc32.bias         5819\n                        Sample Sites:             \nbayesian_model_enc$$$fc11.weight dist 64 5819    |\n                                value 64 5819    |\n  bayesian_model_enc$$$fc11.bias dist      64    |\n                                value      64    |\nbayesian_model_enc$$$fc21.weight dist  2   64    |\n                                value  2   64    |\n  bayesian_model_enc$$$fc21.bias dist       2    |\n                                value       2    |\nbayesian_model_enc$$$fc22.weight dist  2   64    |\n                                value  2   64    |\n  bayesian_model_enc$$$fc22.bias dist       2    |\n                                value       2    |\n                          latent dist 64    2    |\n                                value 64    2    |"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpRHIzS7Qs2K"
      },
      "source": [
        "class VAE(torch.nn.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(VAE, self).__init__()\n",
        "    self.hidden_size   = 64\n",
        "    self.latent_size   = 2\n",
        "    self.alphabet_size = kwargs['alphabet_size']\n",
        "    self.seq_len       = kwargs['seq_len']\n",
        "    self.input_size    = self.alphabet_size * self.seq_len\n",
        "\n",
        "    # create the encoder and decoder networks\n",
        "    self.encoder = Encoder(self.input_size, self.hidden_size, self.latent_size)\n",
        "    self.decoder = Decoder(self.input_size, self.hidden_size, self.latent_size, self.alphabet_size, self.seq_len)\n",
        "\n",
        "  def model(self, x):\n",
        "    priors_decoder = {} # Priors for the neural model\n",
        "    for name, par in self.decoder.named_parameters():     # Loop over all neural network parameters\n",
        "        priors_decoder[name] = dist.Normal(torch.zeros(*par.shape), torch.ones(*par.shape)).to_event() # Each parameter has a N(0, 1) prior\n",
        "    \n",
        "    bayesian_model_dec = pyro.random_module('bayesian_model_dec', self.decoder, priors_decoder) # Make this model and these priors a Pyro model\n",
        "    sampled_model_dec = bayesian_model_dec()\n",
        "\n",
        "    with pyro.plate(\"data\", x.shape[0]):\n",
        "      # setup hyperparameters for prior p(z)\n",
        "      z_loc = x.new_zeros(torch.Size((x.shape[0], self.latent_size)))\n",
        "      z_scale = x.new_ones(torch.Size((x.shape[0], self.latent_size)))\n",
        "      # sample from prior (value will be sampled by guide when computing the ELBO)\n",
        "      z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
        "\n",
        "      # decode the latent code z\n",
        "      loc = sampled_model_dec(z)\n",
        "\n",
        "      pyro.sample(\"obs\", dist.Bernoulli(loc.reshape(-1, self.input_size)).to_event(1), obs=x.reshape(-1, self.input_size))  \n",
        "\n",
        "  def guide(self, x):\n",
        "    priors_encoder = {} # Priors for the neural model\n",
        "\n",
        "    # Encoder weight distribution priors\n",
        "    fc11w_mu = torch.randn_like(self.encoder.fc11.weight)\n",
        "    fc11w_sigma = torch.randn_like(self.encoder.fc11.weight)\n",
        "    fc11w_mu_param = pyro.param(\"fc11w_mu\", fc11w_mu)\n",
        "    fc11w_sigma_param = softplus(pyro.param(\"fc11w_sigma\", fc11w_sigma))\n",
        "    fc11w_prior = dist.Normal(loc=fc11w_mu_param, scale=fc11w_sigma_param)\n",
        "    # Encoder bias distribution priors\n",
        "    fc11b_mu = torch.randn_like(self.encoder.fc11.bias)\n",
        "    fc11b_sigma = torch.randn_like(self.encoder.fc11.bias)\n",
        "    fc11b_mu_param = pyro.param(\"fc11b_mu\", fc11b_mu)\n",
        "    fc11b_sigma_param = softplus(pyro.param(\"fc11b_sigma\", fc11b_sigma))\n",
        "    fc11b_prior = dist.Normal(loc=fc11b_mu_param, scale=fc11b_sigma_param)\n",
        "\n",
        "    # Latent state weight distribution priors\n",
        "    ## 1\n",
        "    fc21w_mu = torch.randn_like(self.encoder.fc21.weight)\n",
        "    fc21w_sigma = torch.randn_like(self.encoder.fc21.weight)\n",
        "    fc21w_mu_param = pyro.param(\"fc21w_mu\", fc21w_mu)\n",
        "    fc21w_sigma_param = softplus(pyro.param(\"fc21w_sigma\", fc21w_sigma))\n",
        "    fc21w_prior = dist.Normal(loc=fc21w_mu_param, scale=fc21w_sigma_param)\n",
        "    ## 2\n",
        "    fc22w_mu = torch.randn_like(self.encoder.fc22.weight)\n",
        "    fc22w_sigma = torch.randn_like(self.encoder.fc22.weight)\n",
        "    fc22w_mu_param = pyro.param(\"fc22w_mu\", fc22w_mu)\n",
        "    fc22w_sigma_param = softplus(pyro.param(\"fc22w_sigma\", fc22w_sigma))\n",
        "    fc22w_prior = dist.Normal(loc=fc22w_mu_param, scale=fc22w_sigma_param)\n",
        "    # Latent state bias distribution priors\n",
        "    ## 1\n",
        "    fc21b_mu = torch.randn_like(self.encoder.fc21.bias)\n",
        "    fc21b_sigma = torch.randn_like(self.encoder.fc21.bias)\n",
        "    fc21b_mu_param = pyro.param(\"fc21b_mu\", fc21b_mu)\n",
        "    fc21b_sigma_param = softplus(pyro.param(\"fc21b_sigma\", fc21b_sigma))\n",
        "    fc21b_prior = dist.Normal(loc=fc21b_mu_param, scale=fc21b_sigma_param)\n",
        "    ## 2\n",
        "    fc22b_mu = torch.randn_like(self.encoder.fc22.bias)\n",
        "    fc22b_sigma = torch.randn_like(self.encoder.fc22.bias)\n",
        "    fc22b_mu_param = pyro.param(\"fc22b_mu\", fc22b_mu)\n",
        "    fc22b_sigma_param = softplus(pyro.param(\"fc22b_sigma\", fc22b_sigma))\n",
        "    fc22b_prior = dist.Normal(loc=fc22b_mu_param, scale=fc22b_sigma_param)\n",
        "\n",
        "    priors_encoder = {'fc11.weight': fc11w_prior, 'fc11.bias': fc11b_prior, 'fc21.weight': fc21w_prior, 'fc21.bias': fc21b_prior, 'fc22.weight': fc22w_prior, 'fc22.bias': fc22b_prior}\n",
        "    \n",
        "    bayesian_model_enc = pyro.random_module('bayesian_model_enc', self.encoder, priors_encoder) # Make this model and these priors a Pyro model\n",
        "    sampled_model_enc = bayesian_model_enc()\n",
        "    \n",
        "    with pyro.plate(\"data\", x.shape[0]):\n",
        "      # use the encoder to get the parameters used to define q(z|x)\n",
        "      z_loc, logvar = sampled_model_enc(x)\n",
        "      z_scale = torch.exp(logvar)\n",
        "      l = torch.zeros((x.shape[0], self.latent_size))\n",
        "      print(\"------------------------------------------------------\")\n",
        "      # sample the latent code z\n",
        "      pyro.sample(\"latent\", dist.Normal(l, z_scale).to_event(1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}